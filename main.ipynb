{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in c:\\users\\abhis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (8.3.79)\n",
      "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (3.9.2)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\abhis\\appdata\\roaming\\python\\python311\\site-packages (from ultralytics) (4.7.0.72)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (9.5.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\abhis\\appdata\\roaming\\python\\python311\\site-packages (from ultralytics) (1.10.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (2.4.1)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (0.19.1+cpu)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (4.66.5)\n",
      "Requirement already satisfied: psutil in c:\\users\\abhis\\appdata\\roaming\\python\\python311\\site-packages (from ultralytics) (6.0.0)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\abhis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (2.2.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (2.0.14)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.23.0->ultralytics) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
      "Requirement already satisfied: filelock in c:\\users\\abhis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\abhis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.13.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\abhis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\abhis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\abhis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\abhis\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 10 persons, 19 cars, 6 motorcycles, 2 buss, 365.2ms\n",
      "Speed: 21.4ms preprocess, 365.2ms inference, 31.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 2 persons, 1 car, 2 trucks, 438.7ms\n",
      "Speed: 17.8ms preprocess, 438.7ms inference, 31.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 car, 2 trucks, 286.4ms\n",
      "Speed: 6.5ms preprocess, 286.4ms inference, 3.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 cars, 2 trucks, 346.0ms\n",
      "Speed: 5.5ms preprocess, 346.0ms inference, 8.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 cars, 2 trucks, 315.1ms\n",
      "Speed: 5.1ms preprocess, 315.1ms inference, 4.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 2 cars, 2 trucks, 286.1ms\n",
      "Speed: 6.1ms preprocess, 286.1ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 cars, 2 trucks, 258.5ms\n",
      "Speed: 4.7ms preprocess, 258.5ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 2 cars, 2 trucks, 263.5ms\n",
      "Speed: 4.3ms preprocess, 263.5ms inference, 4.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 2 cars, 1 bus, 2 trucks, 1 parking meter, 267.2ms\n",
      "Speed: 5.5ms preprocess, 267.2ms inference, 3.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 2 cars, 1 truck, 258.9ms\n",
      "Speed: 4.0ms preprocess, 258.9ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 2 cars, 1 truck, 233.3ms\n",
      "Speed: 3.5ms preprocess, 233.3ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 2 cars, 1 truck, 223.5ms\n",
      "Speed: 4.4ms preprocess, 223.5ms inference, 4.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 3 cars, 1 truck, 221.8ms\n",
      "Speed: 3.7ms preprocess, 221.8ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 2 cars, 1 truck, 192.7ms\n",
      "Speed: 2.5ms preprocess, 192.7ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 2 cars, 219.4ms\n",
      "Speed: 3.5ms preprocess, 219.4ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 2 cars, 201.5ms\n",
      "Speed: 3.3ms preprocess, 201.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 2 cars, 219.6ms\n",
      "Speed: 3.7ms preprocess, 219.6ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 2 cars, 185.7ms\n",
      "Speed: 4.6ms preprocess, 185.7ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 2 cars, 1 handbag, 1 bottle, 220.1ms\n",
      "Speed: 2.9ms preprocess, 220.1ms inference, 8.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 3 cars, 1 handbag, 197.1ms\n",
      "Speed: 3.1ms preprocess, 197.1ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 12 persons, 3 cars, 1 handbag, 191.6ms\n",
      "Speed: 3.4ms preprocess, 191.6ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 12 persons, 3 cars, 2 motorcycles, 192.8ms\n",
      "Speed: 3.8ms preprocess, 192.8ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 13 persons, 3 cars, 2 motorcycles, 167.7ms\n",
      "Speed: 2.9ms preprocess, 167.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 13 persons, 3 cars, 2 motorcycles, 163.9ms\n",
      "Speed: 2.8ms preprocess, 163.9ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 12 persons, 3 cars, 1 motorcycle, 171.7ms\n",
      "Speed: 2.4ms preprocess, 171.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 3 cars, 1 motorcycle, 179.8ms\n",
      "Speed: 3.0ms preprocess, 179.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 3 cars, 2 motorcycles, 1 handbag, 1 suitcase, 176.0ms\n",
      "Speed: 2.5ms preprocess, 176.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 12 persons, 3 cars, 2 motorcycles, 172.8ms\n",
      "Speed: 3.2ms preprocess, 172.8ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 3 cars, 191.4ms\n",
      "Speed: 3.6ms preprocess, 191.4ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 3 cars, 1 truck, 201.5ms\n",
      "Speed: 4.6ms preprocess, 201.5ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 3 cars, 1 truck, 197.5ms\n",
      "Speed: 3.2ms preprocess, 197.5ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 3 cars, 1 truck, 184.0ms\n",
      "Speed: 4.3ms preprocess, 184.0ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 3 cars, 1 truck, 220.4ms\n",
      "Speed: 4.8ms preprocess, 220.4ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 2 cars, 1 truck, 182.5ms\n",
      "Speed: 3.5ms preprocess, 182.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 2 cars, 1 truck, 159.0ms\n",
      "Speed: 2.0ms preprocess, 159.0ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 2 cars, 1 truck, 174.7ms\n",
      "Speed: 3.3ms preprocess, 174.7ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 2 cars, 1 truck, 195.9ms\n",
      "Speed: 3.2ms preprocess, 195.9ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 2 cars, 1 truck, 162.9ms\n",
      "Speed: 5.8ms preprocess, 162.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "import threading\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "from PIL import Image, ImageTk\n",
    "from ultralytics import YOLO\n",
    "\n",
    "class TrafficManagementSystem:\n",
    "    def __init__(self, video_sources):\n",
    "        # Initialize video sources (paths or camera indices)\n",
    "        self.video_sources = video_sources\n",
    "        self.lane_count = len(video_sources)\n",
    "        \n",
    "        # Initialize video captures\n",
    "        self.captures = [cv2.VideoCapture(src) for src in video_sources]\n",
    "        \n",
    "        # Load YOLOv8 model\n",
    "       # Priority scores for different vehicle types (without emergency vehicles)\n",
    "        self.priority_scores = {\n",
    "         'car': 3,\n",
    "         'motorcycle': 1,  # Bikes\n",
    "         'truck': 2,\n",
    "         'bus': 2  # Buses can be treated similar to trucks\n",
    "}\n",
    "\n",
    "# Class mapping for YOLOv8 (COCO dataset) to our categories\n",
    "        self.class_mapping = {\n",
    "         2: 'car',         # car\n",
    "         3: 'motorcycle',  # motorcycle \n",
    "         5: 'bus',         # bus\n",
    "         7: 'truck'        # truck\n",
    "}\n",
    "        \n",
    "        \n",
    "        # Class mapping for YOLO detection to our categories\n",
    "       \n",
    "        # Load YOLOv8 model - add this line after initializing captures\n",
    "        self.model = YOLO('yolov8n.pt')  # Using nano model for performance\n",
    "        # Initialize lane priorities\n",
    "        self.lane_priorities = [0] * self.lane_count\n",
    "        self.lane_vehicle_counts = [{} for _ in range(self.lane_count)]\n",
    "        \n",
    "        # Traffic light states\n",
    "        self.traffic_states = ['red'] * self.lane_count\n",
    "        self.current_green_lane = None\n",
    "        self.green_time = 15  # Default green time in seconds\n",
    "        self.yellow_time = 3  # Yellow time in seconds\n",
    "        \n",
    "        # Create GUI\n",
    "        self.root = tk.Tk()\n",
    "        self.root.title(\"AI-Powered Traffic Management System\")\n",
    "        self.root.geometry(\"1200x800\")\n",
    "        \n",
    "        self.setup_gui()\n",
    "        \n",
    "        # Start processing threads\n",
    "        self.is_running = True\n",
    "        self.processing_thread = threading.Thread(target=self.process_videos)\n",
    "        self.traffic_control_thread = threading.Thread(target=self.control_traffic_lights)\n",
    "        \n",
    "        self.processing_thread.daemon = True\n",
    "        self.traffic_control_thread.daemon = True\n",
    "        \n",
    "    def setup_gui(self):\n",
    "        # Create frames for video displays\n",
    "        self.video_frames = []\n",
    "        self.video_labels = []\n",
    "        \n",
    "        # Create traffic light indicators\n",
    "        self.traffic_indicators = []\n",
    "        \n",
    "        # Create priority displays\n",
    "        self.priority_labels = []\n",
    "        self.vehicle_count_labels = []\n",
    "        \n",
    "        # Create main frame\n",
    "        main_frame = ttk.Frame(self.root)\n",
    "        main_frame.pack(padx=10, pady=10, fill=tk.BOTH, expand=True)\n",
    "        \n",
    "        # Create video grid\n",
    "        video_grid = ttk.Frame(main_frame)\n",
    "        video_grid.pack(padx=10, pady=10, fill=tk.BOTH, expand=True)\n",
    "        \n",
    "        # Create video displays\n",
    "        for i in range(self.lane_count):\n",
    "            # Create frame for each lane\n",
    "            lane_frame = ttk.LabelFrame(video_grid, text=f\"Lane {i+1}\")\n",
    "            lane_frame.grid(row=i//2, column=i%2, padx=10, pady=10, sticky=\"nsew\")\n",
    "            \n",
    "            # Create video display\n",
    "            video_frame = ttk.Frame(lane_frame)\n",
    "            video_frame.pack(pady=5)\n",
    "            video_label = ttk.Label(video_frame)\n",
    "            video_label.pack()\n",
    "            \n",
    "            self.video_frames.append(video_frame)\n",
    "            self.video_labels.append(video_label)\n",
    "            \n",
    "            # Create traffic light indicator\n",
    "            indicator_frame = ttk.Frame(lane_frame)\n",
    "            indicator_frame.pack(pady=5)\n",
    "            \n",
    "            traffic_indicator = ttk.Label(indicator_frame, text=\"RED\", background=\"red\", foreground=\"white\", width=10)\n",
    "            traffic_indicator.pack(side=tk.LEFT, padx=5)\n",
    "            self.traffic_indicators.append(traffic_indicator)\n",
    "            \n",
    "            # Create priority display\n",
    "            priority_frame = ttk.Frame(lane_frame)\n",
    "            priority_frame.pack(pady=5)\n",
    "            \n",
    "            ttk.Label(priority_frame, text=\"Priority:\").pack(side=tk.LEFT, padx=5)\n",
    "            priority_label = ttk.Label(priority_frame, text=\"0\")\n",
    "            priority_label.pack(side=tk.LEFT, padx=5)\n",
    "            self.priority_labels.append(priority_label)\n",
    "            \n",
    "            # Create vehicle count display\n",
    "            vehicle_count_frame = ttk.Frame(lane_frame)\n",
    "            vehicle_count_frame.pack(pady=5)\n",
    "            \n",
    "            vehicle_count_label = ttk.Label(vehicle_count_frame, text=\"No vehicles\")\n",
    "            vehicle_count_label.pack(side=tk.LEFT, padx=5)\n",
    "            self.vehicle_count_labels.append(vehicle_count_label)\n",
    "        \n",
    "        # Configure grid weights\n",
    "        for i in range(2):\n",
    "            video_grid.grid_columnconfigure(i, weight=1)\n",
    "            video_grid.grid_rowconfigure(i, weight=1)\n",
    "        \n",
    "        # Create control panel\n",
    "        control_frame = ttk.LabelFrame(main_frame, text=\"Control Panel\")\n",
    "        control_frame.pack(padx=10, pady=10, fill=tk.X)\n",
    "        \n",
    "        # Green time slider\n",
    "        ttk.Label(control_frame, text=\"Green Light Duration (sec):\").grid(row=0, column=0, padx=5, pady=5)\n",
    "        green_slider = ttk.Scale(control_frame, from_=5, to=60, orient=tk.HORIZONTAL, length=200)\n",
    "        green_slider.set(self.green_time)\n",
    "        green_slider.grid(row=0, column=1, padx=5, pady=5)\n",
    "        green_slider.bind(\"<ButtonRelease-1>\", lambda e: self.set_green_time(int(green_slider.get())))\n",
    "        \n",
    "        # Start/Stop button\n",
    "        self.start_stop_button = ttk.Button(control_frame, text=\"Start System\", command=self.toggle_system)\n",
    "        self.start_stop_button.grid(row=0, column=2, padx=20, pady=5)\n",
    "        \n",
    "        # Status label\n",
    "        self.status_label = ttk.Label(control_frame, text=\"System Ready\")\n",
    "        self.status_label.grid(row=0, column=3, padx=5, pady=5)\n",
    "    \n",
    "    def set_green_time(self, time):\n",
    "        self.green_time = time\n",
    "    \n",
    "    def toggle_system(self):\n",
    "        if self.is_running:\n",
    "            self.is_running = False\n",
    "            self.start_stop_button.config(text=\"Start System\")\n",
    "            self.status_label.config(text=\"System Stopped\")\n",
    "        else:\n",
    "            self.is_running = True\n",
    "            self.start_stop_button.config(text=\"Stop System\")\n",
    "            self.status_label.config(text=\"System Running\")\n",
    "            \n",
    "            # Restart threads if they're not alive\n",
    "            if not self.processing_thread.is_alive():\n",
    "                self.processing_thread = threading.Thread(target=self.process_videos)\n",
    "                self.processing_thread.daemon = True\n",
    "                self.processing_thread.start()\n",
    "            \n",
    "            if not self.traffic_control_thread.is_alive():\n",
    "                self.traffic_control_thread = threading.Thread(target=self.control_traffic_lights)\n",
    "                self.traffic_control_thread.daemon = True\n",
    "                self.traffic_control_thread.start()\n",
    "    \n",
    "    def process_videos(self):\n",
    "        while self.is_running:\n",
    "            for lane_idx, cap in enumerate(self.captures):\n",
    "                if not cap.isOpened():\n",
    "                    continue\n",
    "                \n",
    "                # Read frame\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    # If end of video, loop back\n",
    "                    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "                    continue\n",
    "                \n",
    "                # Resize frame for faster processing\n",
    "                frame = cv2.resize(frame, (640, 480))\n",
    "                \n",
    "                # Process with YOLOv8\n",
    "                if lane_idx == 0:  # Only process one lane at a time for better performance\n",
    "                    results = self.model(frame)\n",
    "                    detections = results[0]\n",
    "                    \n",
    "                    # Reset vehicle counts\n",
    "                    vehicle_counts = {}\n",
    "                    \n",
    "                    # Process detected objects\n",
    "                    boxes = detections.boxes.cpu().numpy()\n",
    "                    for box in boxes:\n",
    "                        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                        conf = box.conf[0]\n",
    "                        cls = int(box.cls[0])\n",
    "                        \n",
    "                        # Only process if confidence is high enough\n",
    "                        if conf > 0.5 and cls in self.class_mapping:\n",
    "                            vehicle_type = self.class_mapping[cls]\n",
    "                            \n",
    "                            # Draw bounding box\n",
    "                            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                            \n",
    "                            # Add text label\n",
    "                            text = f\"{vehicle_type}: {conf:.2f}\"\n",
    "                            cv2.putText(frame, text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "                            \n",
    "                            # Update vehicle count\n",
    "                            if vehicle_type in vehicle_counts:\n",
    "                                vehicle_counts[vehicle_type] += 1\n",
    "                            else:\n",
    "                                vehicle_counts[vehicle_type] = 1\n",
    "                    \n",
    "                    # Update lane vehicle counts\n",
    "                    self.lane_vehicle_counts[lane_idx] = vehicle_counts\n",
    "                    \n",
    "                    # Calculate lane priority\n",
    "                    priority = 0\n",
    "                    for vehicle_type, count in vehicle_counts.items():\n",
    "                        priority += count * self.priority_scores.get(vehicle_type, 0)\n",
    "                    \n",
    "                    self.lane_priorities[lane_idx] = priority\n",
    "                    \n",
    "                    # Update GUI\n",
    "                    self.update_lane_displays(lane_idx, frame, priority, vehicle_counts)\n",
    "            \n",
    "            # Process remaining frames with a simple resize\n",
    "            for lane_idx in range(1, self.lane_count):\n",
    "                ret, frame = self.captures[lane_idx].read()\n",
    "                if not ret:\n",
    "                    self.captures[lane_idx].set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "                    continue\n",
    "                \n",
    "                frame = cv2.resize(frame, (640, 480))\n",
    "                self.update_lane_displays(lane_idx, frame, self.lane_priorities[lane_idx], \n",
    "                                         self.lane_vehicle_counts[lane_idx])\n",
    "            \n",
    "            # Wait a bit to reduce CPU usage\n",
    "            time.sleep(0.03)\n",
    "    \n",
    "    def update_lane_displays(self, lane_idx, frame, priority, vehicle_counts):\n",
    "        # Convert frame to TkInter format\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        img = Image.fromarray(rgb_frame)\n",
    "        img = ImageTk.PhotoImage(image=img)\n",
    "        \n",
    "        # Update image\n",
    "        self.video_labels[lane_idx].config(image=img)\n",
    "        self.video_labels[lane_idx].image = img\n",
    "        \n",
    "        # Update priority label\n",
    "        self.priority_labels[lane_idx].config(text=str(priority))\n",
    "        \n",
    "        # Update vehicle count label\n",
    "        count_text = \", \".join([f\"{v_type}: {count}\" for v_type, count in vehicle_counts.items()])\n",
    "        if not count_text:\n",
    "            count_text = \"No vehicles\"\n",
    "        self.vehicle_count_labels[lane_idx].config(text=count_text)\n",
    "\n",
    "    def control_traffic_lights(self):\n",
    "        while self.is_running:\n",
    "            # Find lane with highest priority\n",
    "            highest_priority_lane = np.argmax(self.lane_priorities)\n",
    "            highest_priority = self.lane_priorities[highest_priority_lane]\n",
    "            \n",
    "            # If priority is very low, use round-robin\n",
    "            if highest_priority < 3:\n",
    "                if self.current_green_lane is None:\n",
    "                    highest_priority_lane = 0\n",
    "                else:\n",
    "                    highest_priority_lane = (self.current_green_lane + 1) % self.lane_count\n",
    "            \n",
    "            # Switch to new lane\n",
    "            if self.current_green_lane != highest_priority_lane:\n",
    "                # If there was a previous green lane, make it yellow first\n",
    "                if self.current_green_lane is not None:\n",
    "                    self.traffic_states[self.current_green_lane] = 'yellow'\n",
    "                    self.update_traffic_indicators()\n",
    "                    # Wait for yellow time\n",
    "                    time.sleep(self.yellow_time)\n",
    "                    \n",
    "                # Make all lanes red\n",
    "                self.traffic_states = ['red'] * self.lane_count\n",
    "                self.update_traffic_indicators()\n",
    "                \n",
    "                # Make new lane green\n",
    "                self.traffic_states[highest_priority_lane] = 'green'\n",
    "                self.current_green_lane = highest_priority_lane\n",
    "                self.update_traffic_indicators()\n",
    "                \n",
    "                # Wait for green time\n",
    "                time.sleep(self.green_time)\n",
    "            else:\n",
    "                # Continue with the same green lane\n",
    "                time.sleep(1)  # Check again after 1 second\n",
    "    \n",
    "    def update_traffic_indicators(self):\n",
    "        for lane, state in enumerate(self.traffic_states):\n",
    "            indicator = self.traffic_indicators[lane]\n",
    "            if state == 'red':\n",
    "                indicator.config(text=\"RED\", background=\"red\", foreground=\"white\")\n",
    "            elif state == 'yellow':\n",
    "                indicator.config(text=\"YELLOW\", background=\"yellow\", foreground=\"black\")\n",
    "            else:  # green\n",
    "                indicator.config(text=\"GREEN\", background=\"green\", foreground=\"white\")\n",
    "\n",
    "    def run(self):\n",
    "        # Start processing threads\n",
    "        self.processing_thread.start()\n",
    "        self.traffic_control_thread.start()\n",
    "        \n",
    "        # Start GUI main loop\n",
    "        self.root.mainloop()\n",
    "        \n",
    "        # Clean up\n",
    "        self.is_running = False\n",
    "        for cap in self.captures:\n",
    "            cap.release()\n",
    "\n",
    "def main():\n",
    "    # Replace with your video sources\n",
    "    # Could be camera indices (0, 1, 2, 3) or video file paths\n",
    "    video_sources = [\n",
    "        'static/videos/udaipur-india-november-24-2012-traffic-on-indian-street-in-udaipur-SBV-347557199-preview.mp4',\n",
    "        'static/videos/27260-362770008_small.mp4',  # Replace with actual video paths or camera indices\n",
    "        'static/videos/agra-india-november-17-2012-traffic-on-indian-street-in-agra-india-17-nov-2012-SBV-347430175-preview.mp4',\n",
    "        'static/videos/traffic-congestion-and-street-life-in-the-city-of-jaipur-pink-gate-city-walls--SBV-300214180-preview.mp4'\n",
    "        \n",
    "    ]\n",
    "    \n",
    "    # Create and run the system\n",
    "    system = TrafficManagementSystem(video_sources)\n",
    "    system.run()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TrafficManagementSystem' object has no attribute 'lane_count'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 684\u001b[0m\n\u001b[0;32m    681\u001b[0m     system\u001b[38;5;241m.\u001b[39mrun()\n\u001b[0;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 684\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 680\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    672\u001b[0m video_sources \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    673\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatic/videos/udaipur-india-november-24-2012-traffic-on-indian-street-in-udaipur-SBV-347557199-preview.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    674\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatic/videos/27260-362770008_small.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatic/videos/agra-india-november-17-2012-traffic-on-indian-street-in-agra-india-17-nov-2012-SBV-347430175-preview.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatic/videos/traffic-congestion-and-street-life-in-the-city-of-jaipur-pink-gate-city-walls--SBV-300214180-preview.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    677\u001b[0m ]\n\u001b[0;32m    679\u001b[0m \u001b[38;5;66;03m# Create and run the system\u001b[39;00m\n\u001b[1;32m--> 680\u001b[0m system \u001b[38;5;241m=\u001b[39m \u001b[43mTrafficManagementSystem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_sources\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    681\u001b[0m system\u001b[38;5;241m.\u001b[39mrun()\n",
      "Cell \u001b[1;32mIn[4], line 108\u001b[0m, in \u001b[0;36mTrafficManagementSystem.__init__\u001b[1;34m(self, video_sources)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, video_sources):\n\u001b[0;32m    105\u001b[0m \u001b[38;5;66;03m# Existing initialization code...\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \n\u001b[0;32m    107\u001b[0m \u001b[38;5;66;03m# Add wait time tracking\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlane_wait_times \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlane_count\u001b[49m\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_green_time \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlane_count\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpriority_history \u001b[38;5;241m=\u001b[39m [[] \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlane_count)]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'TrafficManagementSystem' object has no attribute 'lane_count'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "import threading\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "from PIL import Image, ImageTk\n",
    "from ultralytics import YOLO\n",
    "import random\n",
    "import os\n",
    "from collections import deque\n",
    "\n",
    "class TrafficManagementSystem:\n",
    "    def __init__(self, video_sources):\n",
    "        # Initialize video sources (paths or camera indices)\n",
    "        self.video_sources = video_sources\n",
    "        self.lane_count = len(video_sources)\n",
    "        \n",
    "        # Initialize video captures\n",
    "        self.captures = [cv2.VideoCapture(src) for src in video_sources]\n",
    "        \n",
    "        # Priority scores for different vehicle types\n",
    "        self.priority_scores = {\n",
    "            'car': 3,\n",
    "            'motorcycle': 1,\n",
    "            'truck': 5,\n",
    "            'bus': 4\n",
    "        }\n",
    "\n",
    "        # Class mapping for YOLOv8 (COCO dataset) to our categories\n",
    "        self.class_mapping = {\n",
    "            2: 'car',         # car\n",
    "            3: 'motorcycle',  # motorcycle \n",
    "            5: 'bus',         # bus\n",
    "            7: 'truck'        # truck\n",
    "        }\n",
    "        \n",
    "        # Load YOLOv8 model\n",
    "        self.model = YOLO('yolov8n.pt')  # Using nano model for performance\n",
    "        \n",
    "        # Initialize lane priorities\n",
    "        self.lane_priorities = [0] * self.lane_count\n",
    "        self.lane_vehicle_counts = [{} for _ in range(self.lane_count)]\n",
    "        \n",
    "        # Traffic light states\n",
    "        self.traffic_states = ['red'] * self.lane_count\n",
    "        self.current_green_lane = None\n",
    "        self.green_time = 15  # Default green time in seconds\n",
    "        self.yellow_time = 3  # Yellow time in seconds\n",
    "        \n",
    "        # Create directories for frame storage\n",
    "        self.frame_dirs = []\n",
    "        for i in range(self.lane_count):\n",
    "            dir_path = f\"lane_{i}_frames\"\n",
    "            os.makedirs(dir_path, exist_ok=True)\n",
    "            self.frame_dirs.append(dir_path)\n",
    "        \n",
    "        # Frame processing parameters\n",
    "        self.chunk_size = 5  # seconds\n",
    "        self.frame_rate = 1  # 1 frame per second\n",
    "        \n",
    "        # Pre-processed frames for each lane\n",
    "        self.processed_frames = [deque() for _ in range(self.lane_count)]\n",
    "        self.latest_frames = [None] * self.lane_count\n",
    "        \n",
    "        # Create GUI\n",
    "        self.root = tk.Tk()\n",
    "        self.root.title(\"AI-Powered Traffic Management System\")\n",
    "        self.root.geometry(\"1200x800\")\n",
    "        \n",
    "        self.setup_gui()\n",
    "        \n",
    "        # Start processing threads\n",
    "        self.is_running = True\n",
    "        self.preprocess_threads = []\n",
    "        for i in range(self.lane_count):\n",
    "            thread = threading.Thread(target=self.preprocess_video, args=(i,))\n",
    "            thread.daemon = True\n",
    "            self.preprocess_threads.append(thread)\n",
    "        \n",
    "        self.detection_thread = threading.Thread(target=self.process_frames)\n",
    "        self.detection_thread.daemon = True\n",
    "        \n",
    "        self.traffic_control_thread = threading.Thread(target=self.control_traffic_lights)\n",
    "        self.traffic_control_thread.daemon = True\n",
    "        \n",
    "        self.display_thread = threading.Thread(target=self.update_display)\n",
    "        self.display_thread.daemon = True\n",
    "    def calculate_green_time(self, lane_idx):\n",
    "        \n",
    "        base_time = 10  # Minimum green time in seconds\n",
    "    \n",
    "    # Calculate additional time based on vehicle count and types\n",
    "        vehicle_count = sum(self.lane_vehicle_counts[lane_idx].values())\n",
    "        priority = self.lane_priorities[lane_idx]\n",
    "    \n",
    "    # Logarithmic scaling to prevent excessively long green times\n",
    "        additional_time = min(30, 5 * np.log2(priority + 1))\n",
    "    \n",
    "        return base_time + additional_time\n",
    "    \n",
    "    \n",
    "    def __init__(self, video_sources):\n",
    "    # Existing initialization code...\n",
    "    \n",
    "    # Add wait time tracking\n",
    "        self.lane_wait_times = [0] * self.lane_count\n",
    "        self.last_green_time = [0] * self.lane_count\n",
    "        self.priority_history = [[] for _ in range(self.lane_count)]\n",
    "        self.trend_window = 10  # \n",
    "\n",
    "    def update_wait_times(self):\n",
    "        current_time = time.time()\n",
    "        for i in range(self.lane_count):\n",
    "            if self.traffic_states[i] != 'green':\n",
    "                self.lane_wait_times[i] = current_time - self.last_green_time[i]\n",
    "            else:\n",
    "                self.lane_wait_times[i] = 0\n",
    "                self.last_green_time[i] = current_time\n",
    "\n",
    "    def calculate_lane_priority(self, lane_idx):\n",
    "        base_priority = self.lane_priorities[lane_idx]\n",
    "        wait_factor = min(3, self.lane_wait_times[lane_idx] / 30)  # Cap at 3x multiplier after 90 seconds\n",
    "    \n",
    "        return base_priority * (1 + wait_factor)\n",
    "    def update_priority_history(self):\n",
    "        for i in range(self.lane_count):\n",
    "            if len(self.priority_history[i]) >= self.trend_window:\n",
    "                self.priority_history[i].pop(0)\n",
    "            self.priority_history[i].append(self.lane_priorities[i])\n",
    "\n",
    "    def calculate_trend(self, lane_idx):\n",
    "        if len(self.priority_history[lane_idx]) < self.trend_window:\n",
    "            return 0\n",
    "    \n",
    "    # Simple linear regression to detect trend\n",
    "        x = np.array(range(len(self.priority_history[lane_idx])))\n",
    "        y = np.array(self.priority_history[lane_idx])\n",
    "        slope, _ = np.polyfit(x, y, 1)\n",
    "    \n",
    "        return slope\n",
    "    \n",
    "    def detect_system_congestion(self):\n",
    "        avg_priority = sum(self.lane_priorities) / self.lane_count\n",
    "        max_priority = max(self.lane_priorities)\n",
    "    \n",
    "    # System is congested if average priority is high\n",
    "        system_congested = avg_priority > 20\n",
    "    \n",
    "    # Check for severe imbalance\n",
    "        severe_imbalance = max_priority > 3 * avg_priority\n",
    "    \n",
    "        return system_congested, severe_imbalance\n",
    "    \n",
    "    \n",
    "\n",
    "    def manage_congestion(self):\n",
    "        system_congested, severe_imbalance = self.detect_system_congestion()\n",
    "    \n",
    "        if system_congested:\n",
    "        # Reduce green times slightly to cycle through lanes faster\n",
    "            self.green_time_factor = 0.8\n",
    "        else:\n",
    "            self.green_time_factor = 1.0\n",
    "    \n",
    "        if severe_imbalance:\n",
    "        # Prioritize the most congested lane with longer green time\n",
    "            self.green_time_factor = 1.2\n",
    "            \n",
    "    def get_time_of_day_pattern(self):\n",
    "        current_hour = datetime.datetime.now().hour\n",
    "    \n",
    "        if 7 <= current_hour < 10:  # Morning rush\n",
    "            return 'morning_rush'\n",
    "        elif 16 <= current_hour < 19:  # Evening rush\n",
    "            return 'evening_rush'\n",
    "        elif 22 <= current_hour or current_hour < 5:  # Night\n",
    "            return 'night'\n",
    "        else:  # Normal daytime\n",
    "            return 'normal'\n",
    "\n",
    "    def apply_time_pattern(self):\n",
    "        pattern = self.get_time_of_day_pattern()\n",
    "    \n",
    "        if pattern == 'morning_rush':\n",
    "        # Adjust weights for incoming lanes to city\n",
    "            for i in range(self.lane_count):\n",
    "                if i in [0, 3]:  # Assuming lanes 0 and 3 are incoming\n",
    "                    self.lane_priorities[i] *= 1.3\n",
    "        elif pattern == 'evening_rush':\n",
    "        # Adjust weights for outgoing lanes from city\n",
    "            for i in range(self.lane_count):\n",
    "                if i in [1, 2]:  # Assuming lanes 1 and 2 are outgoing\n",
    "                    self.lane_priorities[i] *= 1.3\n",
    "        elif pattern == 'night':\n",
    "        # Equal priority, shorter cycles at night\n",
    "            self.green_time = min(self.green_time, 15)\n",
    "        \n",
    "    def setup_gui(self):\n",
    "        # Create frames for video displays\n",
    "        self.video_frames = []\n",
    "        self.video_labels = []\n",
    "        \n",
    "        # Create two main sections: video grid and traffic control panel\n",
    "        main_frame = ttk.Frame(self.root)\n",
    "        main_frame.pack(fill=tk.BOTH, expand=True)\n",
    "        \n",
    "        left_frame = ttk.Frame(main_frame)\n",
    "        left_frame.pack(side=tk.LEFT, fill=tk.BOTH, expand=True, padx=10, pady=10)\n",
    "        \n",
    "        right_frame = ttk.Frame(main_frame)\n",
    "        right_frame.pack(side=tk.RIGHT, fill=tk.Y, padx=10, pady=10)\n",
    "        \n",
    "        # Create video grid\n",
    "        video_grid = ttk.Frame(left_frame)\n",
    "        video_grid.pack(fill=tk.BOTH, expand=True)\n",
    "        \n",
    "        # Create traffic control panel\n",
    "        traffic_panel = ttk.LabelFrame(right_frame, text=\"Traffic Control\")\n",
    "        traffic_panel.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)\n",
    "        \n",
    "        # Create traffic light indicators and priority displays\n",
    "        self.traffic_indicators = []\n",
    "        self.priority_labels = []\n",
    "        self.vehicle_count_labels = []\n",
    "        \n",
    "        for i in range(self.lane_count):\n",
    "            # Create lane frame in traffic panel\n",
    "            lane_frame = ttk.LabelFrame(traffic_panel, text=f\"Lane {i+1}\")\n",
    "            lane_frame.pack(fill=tk.X, padx=5, pady=5)\n",
    "            \n",
    "            # Create traffic light indicator\n",
    "            indicator_frame = ttk.Frame(lane_frame)\n",
    "            indicator_frame.pack(fill=tk.X, pady=5)\n",
    "            \n",
    "            ttk.Label(indicator_frame, text=\"Signal:\").pack(side=tk.LEFT, padx=5)\n",
    "            traffic_indicator = ttk.Label(indicator_frame, text=\"RED\", background=\"red\", foreground=\"white\", width=10)\n",
    "            traffic_indicator.pack(side=tk.LEFT, padx=5)\n",
    "            self.traffic_indicators.append(traffic_indicator)\n",
    "            \n",
    "            # Create priority display\n",
    "            priority_frame = ttk.Frame(lane_frame)\n",
    "            priority_frame.pack(fill=tk.X, pady=5)\n",
    "            \n",
    "            ttk.Label(priority_frame, text=\"Priority:\").pack(side=tk.LEFT, padx=5)\n",
    "            priority_label = ttk.Label(priority_frame, text=\"0\")\n",
    "            priority_label.pack(side=tk.LEFT, padx=5)\n",
    "            self.priority_labels.append(priority_label)\n",
    "            \n",
    "            # Create vehicle count display\n",
    "            vehicle_count_frame = ttk.Frame(lane_frame)\n",
    "            vehicle_count_frame.pack(fill=tk.X, pady=5)\n",
    "            \n",
    "            ttk.Label(vehicle_count_frame, text=\"Vehicles:\").pack(side=tk.LEFT, padx=5)\n",
    "            vehicle_count_label = ttk.Label(vehicle_count_frame, text=\"No vehicles\")\n",
    "            vehicle_count_label.pack(side=tk.LEFT, padx=5)\n",
    "            self.vehicle_count_labels.append(vehicle_count_label)\n",
    "        \n",
    "        # Create video displays in grid\n",
    "        for i in range(self.lane_count):\n",
    "            # Create frame for each lane\n",
    "            row, col = i // 2, i % 2\n",
    "            lane_frame = ttk.LabelFrame(video_grid, text=f\"Lane {i+1}\")\n",
    "            lane_frame.grid(row=row, column=col, padx=5, pady=5, sticky=\"nsew\")\n",
    "            \n",
    "            # Create video display\n",
    "            video_frame = ttk.Frame(lane_frame)\n",
    "            video_frame.pack(pady=5, fill=tk.BOTH, expand=True)\n",
    "            video_label = ttk.Label(video_frame)\n",
    "            video_label.pack(fill=tk.BOTH, expand=True)\n",
    "            \n",
    "            self.video_frames.append(video_frame)\n",
    "            self.video_labels.append(video_label)\n",
    "        \n",
    "        # Configure grid weights\n",
    "        for i in range(2):\n",
    "            video_grid.grid_columnconfigure(i, weight=1)\n",
    "            video_grid.grid_rowconfigure(i, weight=1)\n",
    "        \n",
    "        # Create control panel\n",
    "        control_frame = ttk.LabelFrame(right_frame, text=\"System Control\")\n",
    "        control_frame.pack(fill=tk.X, padx=5, pady=5)\n",
    "        \n",
    "        # Green time slider\n",
    "        ttk.Label(control_frame, text=\"Green Light Duration (sec):\").pack(anchor=tk.W, padx=5, pady=5)\n",
    "        green_slider = ttk.Scale(control_frame, from_=5, to=60, orient=tk.HORIZONTAL)\n",
    "        green_slider.set(self.green_time)\n",
    "        green_slider.pack(fill=tk.X, padx=5, pady=5)\n",
    "        green_slider.bind(\"<ButtonRelease-1>\", lambda e: self.set_green_time(int(green_slider.get())))\n",
    "        \n",
    "        # Yellow time slider\n",
    "        ttk.Label(control_frame, text=\"Yellow Light Duration (sec):\").pack(anchor=tk.W, padx=5, pady=5)\n",
    "        yellow_slider = ttk.Scale(control_frame, from_=1, to=10, orient=tk.HORIZONTAL)\n",
    "        yellow_slider.set(self.yellow_time)\n",
    "        yellow_slider.pack(fill=tk.X, padx=5, pady=5)\n",
    "        yellow_slider.bind(\"<ButtonRelease-1>\", lambda e: self.set_yellow_time(int(yellow_slider.get())))\n",
    "        \n",
    "        # Start/Stop button\n",
    "        self.start_stop_button = ttk.Button(control_frame, text=\"Start System\", command=self.toggle_system)\n",
    "        self.start_stop_button.pack(fill=tk.X, padx=5, pady=5)\n",
    "        \n",
    "        # Status label\n",
    "        self.status_label = ttk.Label(control_frame, text=\"System Ready\")\n",
    "        self.status_label.pack(fill=tk.X, padx=5, pady=5)\n",
    "        \n",
    "    def set_green_time(self, time):\n",
    "        self.green_time = time\n",
    "    \n",
    "    def set_yellow_time(self, time):\n",
    "        self.yellow_time = time\n",
    "    \n",
    "    def toggle_system(self):\n",
    "        if self.is_running:\n",
    "            self.is_running = False\n",
    "            self.start_stop_button.config(text=\"Start System\")\n",
    "            self.status_label.config(text=\"System Stopped\")\n",
    "        else:\n",
    "            self.is_running = True\n",
    "            self.start_stop_button.config(text=\"Stop System\")\n",
    "            self.status_label.config(text=\"System Running\")\n",
    "            \n",
    "            # Start all threads\n",
    "            for i, thread in enumerate(self.preprocess_threads):\n",
    "                if not thread.is_alive():\n",
    "                    self.preprocess_threads[i] = threading.Thread(target=self.preprocess_video, args=(i,))\n",
    "                    self.preprocess_threads[i].daemon = True\n",
    "                    self.preprocess_threads[i].start()\n",
    "            \n",
    "            if not self.detection_thread.is_alive():\n",
    "                self.detection_thread = threading.Thread(target=self.process_frames)\n",
    "                self.detection_thread.daemon = True\n",
    "                self.detection_thread.start()\n",
    "            \n",
    "            if not self.traffic_control_thread.is_alive():\n",
    "                self.traffic_control_thread = threading.Thread(target=self.control_traffic_lights)\n",
    "                self.traffic_control_thread.daemon = True\n",
    "                self.traffic_control_thread.start()\n",
    "                \n",
    "            if not self.display_thread.is_alive():\n",
    "                self.display_thread = threading.Thread(target=self.update_display)\n",
    "                self.display_thread.daemon = True\n",
    "                self.display_thread.start()\n",
    "                \n",
    "    def control_traffic_lights(self):\n",
    "        \"\"\"Control traffic lights based on improved logic\"\"\"\n",
    "        while self.is_running:\n",
    "        # Update wait times\n",
    "            self.update_wait_times()\n",
    "        \n",
    "        # Update priority history for trend analysis\n",
    "            self.update_priority_history()\n",
    "        \n",
    "        # Apply time-of-day adjustments\n",
    "            self.apply_time_pattern()\n",
    "        \n",
    "        # Manage congestion\n",
    "            self.manage_congestion()\n",
    "        \n",
    "        # Calculate adjusted priorities including wait times and trends\n",
    "            adjusted_priorities = []\n",
    "            for i in range(self.lane_count):\n",
    "                base_priority = self.lane_priorities[i]\n",
    "                wait_factor = min(3, self.lane_wait_times[i] / 30) \n",
    "                trend = self.calculate_trend(i)\n",
    "            \n",
    "            # Combined priority score\n",
    "                adjusted_priority = base_priority * (1 + wait_factor) + (trend * 5)\n",
    "                adjusted_priorities.append(adjusted_priority)\n",
    "        \n",
    "        # Find lane with highest adjusted priority\n",
    "            highest_priority_lane = np.argmax(adjusted_priorities)\n",
    "            highest_priority = adjusted_priorities[highest_priority_lane]\n",
    "        \n",
    "        # Check for emergency vehicles in any lane\n",
    "            emergency_detected = False\n",
    "            emergency_lane = None\n",
    "            for i in range(self.lane_count):\n",
    "                if 'emergency' in self.lane_vehicle_counts[i] and self.lane_vehicle_counts[i]['emergency'] > 0:\n",
    "                    emergency_detected = True\n",
    "                    emergency_lane = i\n",
    "                    break\n",
    "        \n",
    "            if emergency_detected:\n",
    "                highest_priority_lane = emergency_lane\n",
    "        \n",
    "        # Switch to new lane if needed\n",
    "            if self.current_green_lane != highest_priority_lane:\n",
    "            # Yellow transition for current green lane\n",
    "                if self.current_green_lane is not None:\n",
    "                    self.traffic_states[self.current_green_lane] = 'yellow'\n",
    "                    self.update_traffic_indicator(self.current_green_lane)\n",
    "                    time.sleep(self.yellow_time)\n",
    "            \n",
    "            # All red safety period\n",
    "                self.traffic_states = ['red'] * self.lane_count\n",
    "                for i in range(self.lane_count):\n",
    "                    self.update_traffic_indicator(i)\n",
    "                time.sleep(1)\n",
    "            \n",
    "            # Calculate dynamic green time for new lane\n",
    "                dynamic_green_time = self.calculate_green_time(highest_priority_lane)\n",
    "                dynamic_green_time *= self.green_time_factor  # Apply congestion factor\n",
    "            \n",
    "            # Make new lane green\n",
    "                self.traffic_states[highest_priority_lane] = 'green'\n",
    "                self.current_green_lane = highest_priority_lane\n",
    "                self.update_traffic_indicator(highest_priority_lane)\n",
    "            \n",
    "            # Log lane switch with dynamic time\n",
    "                print(f\"Switching to Lane {highest_priority_lane + 1} with priority {highest_priority:.2f}\")\n",
    "                print(f\"Dynamic green time: {dynamic_green_time:.1f} seconds\")\n",
    "            \n",
    "            # Wait for calculated green time\n",
    "                time.sleep(dynamic_green_time)\n",
    "            else:\n",
    "            # Continue with same green lane\n",
    "                time.sleep(1)\n",
    "    \n",
    "    def preprocess_video(self, lane_idx):\n",
    "        \"\"\"Preprocess video for a specific lane by extracting frames at regular intervals\"\"\"\n",
    "        cap = self.captures[lane_idx]\n",
    "        \n",
    "        while self.is_running:\n",
    "            if not cap.isOpened():\n",
    "                time.sleep(1)\n",
    "                continue\n",
    "            \n",
    "            # Get video properties\n",
    "            fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "            frame_interval = int(fps / self.frame_rate)\n",
    "            chunk_frames = int(fps * self.chunk_size)\n",
    "            \n",
    "            # Process chunk by chunk\n",
    "            start_frame = 0\n",
    "            \n",
    "            while self.is_running:\n",
    "                # Set video position to start of chunk\n",
    "                cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "                \n",
    "                # Extract frames from chunk\n",
    "                chunk_images = []\n",
    "                for i in range(chunk_frames):\n",
    "                    # Only capture frames at specified interval\n",
    "                    if i % frame_interval == 0:\n",
    "                        ret, frame = cap.read()\n",
    "                        if not ret:\n",
    "                            break\n",
    "                        chunk_images.append(frame)\n",
    "                \n",
    "                # If we reached the end of video, loop back\n",
    "                if len(chunk_images) == 0:\n",
    "                    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "                    start_frame = 0\n",
    "                    continue\n",
    "                \n",
    "                # Select a random frame from the chunk\n",
    "                if chunk_images:\n",
    "                    selected_frame = random.choice(chunk_images)\n",
    "                    selected_frame = cv2.resize(selected_frame, (640, 480))\n",
    "                    \n",
    "                    # Add to processing queue\n",
    "                    if len(self.processed_frames[lane_idx]) >= 5:\n",
    "                        self.processed_frames[lane_idx].popleft()\n",
    "                    self.processed_frames[lane_idx].append(selected_frame)\n",
    "                    \n",
    "                    # Update latest frame\n",
    "                    self.latest_frames[lane_idx] = selected_frame.copy()\n",
    "                \n",
    "                # Move to next chunk\n",
    "                start_frame += chunk_frames\n",
    "                \n",
    "                # If we've processed this chunk, wait before processing next chunk\n",
    "                time.sleep(0.1)\n",
    "    \n",
    "    def process_frames(self):\n",
    "        \"\"\"Process frames from all lanes simultaneously\"\"\"\n",
    "        while self.is_running:\n",
    "            for lane_idx in range(self.lane_count):\n",
    "                # Skip if no frames available\n",
    "                if not self.processed_frames[lane_idx]:\n",
    "                    continue\n",
    "                \n",
    "                # Get a frame from the queue\n",
    "                frame = self.processed_frames[lane_idx].popleft()\n",
    "                \n",
    "                # Process with YOLOv8\n",
    "                results = self.model(frame)\n",
    "                detections = results[0]\n",
    "                \n",
    "                # Reset vehicle counts for this lane\n",
    "                vehicle_counts = {}\n",
    "                \n",
    "                # Process detected objects\n",
    "                boxes = detections.boxes.cpu().numpy()\n",
    "                for box in boxes:\n",
    "                    x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                    conf = box.conf[0]\n",
    "                    cls = int(box.cls[0])\n",
    "                    \n",
    "                    # Only process if confidence is high enough and class is in our mapping\n",
    "                    if conf > 0.5 and cls in self.class_mapping:\n",
    "                        vehicle_type = self.class_mapping[cls]\n",
    "                        \n",
    "                        # Draw bounding box\n",
    "                        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                        \n",
    "                        # Add text label\n",
    "                        text = f\"{vehicle_type}: {conf:.2f}\"\n",
    "                        cv2.putText(frame, text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "                        \n",
    "                        # Update vehicle count\n",
    "                        if vehicle_type in vehicle_counts:\n",
    "                            vehicle_counts[vehicle_type] += 1\n",
    "                        else:\n",
    "                            vehicle_counts[vehicle_type] = 1\n",
    "                \n",
    "                # Update lane vehicle counts\n",
    "                self.lane_vehicle_counts[lane_idx] = vehicle_counts\n",
    "                \n",
    "                # Calculate lane priority\n",
    "                priority = 0\n",
    "                for vehicle_type, count in vehicle_counts.items():\n",
    "                    priority += count * self.priority_scores.get(vehicle_type, 0)\n",
    "                \n",
    "                self.lane_priorities[lane_idx] = priority\n",
    "                \n",
    "                # Update latest frame with detection results\n",
    "                self.latest_frames[lane_idx] = frame\n",
    "            \n",
    "            # Sleep to reduce CPU usage\n",
    "            time.sleep(0.1)\n",
    "            \n",
    "    \n",
    "    \n",
    "    def update_display(self):\n",
    "        \"\"\"Update the GUI display with the latest frames and information\"\"\"\n",
    "        while self.is_running:\n",
    "            # Update all lane displays\n",
    "            for lane_idx in range(self.lane_count):\n",
    "                # Skip if no frame available\n",
    "                if self.latest_frames[lane_idx] is None:\n",
    "                    continue\n",
    "                \n",
    "                # Get current frame\n",
    "                frame = self.latest_frames[lane_idx].copy()\n",
    "                \n",
    "                # Add traffic light status overlay to frame\n",
    "                status = self.traffic_states[lane_idx].upper()\n",
    "                color = (0, 0, 255)  # Red\n",
    "                if status == \"GREEN\":\n",
    "                    color = (0, 255, 0)  # Green\n",
    "                elif status == \"YELLOW\":\n",
    "                    color = (0, 255, 255)  # Yellow\n",
    "                \n",
    "                # Draw signal status on the frame\n",
    "                cv2.rectangle(frame, (10, 10), (150, 50), (0, 0, 0), -1)\n",
    "                cv2.putText(frame, f\"Signal: {status}\", (15, 35), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                            0.7, color, 2)\n",
    "                \n",
    "                # Draw priority score on the frame\n",
    "                priority = self.lane_priorities[lane_idx]\n",
    "                cv2.rectangle(frame, (10, 60), (150, 100), (0, 0, 0), -1)\n",
    "                cv2.putText(frame, f\"Priority: {priority}\", (15, 85), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                            0.7, (255, 255, 255), 2)\n",
    "                \n",
    "                # Convert frame to TkInter format\n",
    "                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                img = Image.fromarray(rgb_frame)\n",
    "                img = ImageTk.PhotoImage(image=img)\n",
    "                \n",
    "                # Update image\n",
    "                self.video_labels[lane_idx].config(image=img)\n",
    "                self.video_labels[lane_idx].image = img\n",
    "                \n",
    "                # Update priority label\n",
    "                self.priority_labels[lane_idx].config(text=str(priority))\n",
    "                \n",
    "                # Update vehicle count label\n",
    "                vehicle_counts = self.lane_vehicle_counts[lane_idx]\n",
    "                count_text = \", \".join([f\"{v_type}: {count}\" for v_type, count in vehicle_counts.items()])\n",
    "                if not count_text:\n",
    "                    count_text = \"No vehicles\"\n",
    "                self.vehicle_count_labels[lane_idx].config(text=count_text)\n",
    "                \n",
    "                # Update traffic light indicator\n",
    "                self.update_traffic_indicator(lane_idx)\n",
    "            \n",
    "            # Update GUI periodically\n",
    "            time.sleep(0.1)\n",
    "    \n",
    "    def update_traffic_indicator(self, lane_idx):\n",
    "        \"\"\"Update traffic light indicator for a specific lane\"\"\"\n",
    "        state = self.traffic_states[lane_idx]\n",
    "        indicator = self.traffic_indicators[lane_idx]\n",
    "        \n",
    "        if state == 'red':\n",
    "            indicator.config(text=\"RED\", background=\"red\", foreground=\"white\")\n",
    "        elif state == 'yellow':\n",
    "            indicator.config(text=\"YELLOW\", background=\"yellow\", foreground=\"black\")\n",
    "        else:  # green\n",
    "            indicator.config(text=\"GREEN\", background=\"green\", foreground=\"white\")\n",
    "    \n",
    "    def control_traffic_lights(self):\n",
    "        \"\"\"Control traffic lights based on lane priorities\"\"\"\n",
    "        while self.is_running:\n",
    "            # Find lane with highest priority\n",
    "            highest_priority_lane = np.argmax(self.lane_priorities)\n",
    "            highest_priority = self.lane_priorities[highest_priority_lane]\n",
    "            \n",
    "            # If priority is very low, use round-robin\n",
    "            if highest_priority < 3:\n",
    "                if self.current_green_lane is None:\n",
    "                    highest_priority_lane = 0\n",
    "                else:\n",
    "                    highest_priority_lane = (self.current_green_lane + 1) % self.lane_count\n",
    "            \n",
    "            # Switch to new lane if needed\n",
    "            if self.current_green_lane != highest_priority_lane:\n",
    "                # If there was a previous green lane, make it yellow first\n",
    "                if self.current_green_lane is not None:\n",
    "                    self.traffic_states[self.current_green_lane] = 'yellow'\n",
    "                    self.update_traffic_indicator(self.current_green_lane)\n",
    "                    \n",
    "                    # Wait for yellow time\n",
    "                    time.sleep(self.yellow_time)\n",
    "                \n",
    "                # Make all lanes red\n",
    "                self.traffic_states = ['red'] * self.lane_count\n",
    "                for i in range(self.lane_count):\n",
    "                    self.update_traffic_indicator(i)\n",
    "                \n",
    "                # Short safety delay\n",
    "                time.sleep(1)\n",
    "                \n",
    "                # Make new lane green\n",
    "                self.traffic_states[highest_priority_lane] = 'green'\n",
    "                self.current_green_lane = highest_priority_lane\n",
    "                self.update_traffic_indicator(highest_priority_lane)\n",
    "                \n",
    "                # Log lane switch\n",
    "                print(f\"Switching to Lane {highest_priority_lane + 1} with priority {highest_priority}\")\n",
    "                \n",
    "                # Wait for green time\n",
    "                time.sleep(self.green_time)\n",
    "            else:\n",
    "                # Continue with the same green lane\n",
    "                time.sleep(1)  # Check again after 1 second\n",
    "    \n",
    "    def run(self):\n",
    "        \"\"\"Run the traffic management system\"\"\"\n",
    "        # Start processing threads\n",
    "        for thread in self.preprocess_threads:\n",
    "            thread.start()\n",
    "        \n",
    "        self.detection_thread.start()\n",
    "        self.traffic_control_thread.start()\n",
    "        self.display_thread.start()\n",
    "        \n",
    "        # Start GUI main loop\n",
    "        self.root.mainloop()\n",
    "        \n",
    "        # Clean up\n",
    "        self.is_running = False\n",
    "        for cap in self.captures:\n",
    "            cap.release()\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Replace with your video sources\n",
    "    # Could be camera indices (0, 1, 2, 3) or video file paths\n",
    "    video_sources = [\n",
    "        'static/videos/udaipur-india-november-24-2012-traffic-on-indian-street-in-udaipur-SBV-347557199-preview.mp4',\n",
    "        'static/videos/27260-362770008_small.mp4',\n",
    "        'static/videos/agra-india-november-17-2012-traffic-on-indian-street-in-agra-india-17-nov-2012-SBV-347430175-preview.mp4',\n",
    "        'static/videos/traffic-congestion-and-street-life-in-the-city-of-jaipur-pink-gate-city-walls--SBV-300214180-preview.mp4'\n",
    "    ]\n",
    "    \n",
    "    # Create and run the system\n",
    "    system = TrafficManagementSystem(video_sources)\n",
    "    system.run()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhis\\AppData\\Local\\Temp\\ipykernel_6740\\3398990579.py:264: UserWarning: frames=None which we can infer the length of, did not pass an explicit *save_count* and passed cache_frame_data=True.  To avoid a possibly unbounded cache, frame data caching has been disabled. To suppress this warning either pass `cache_frame_data=False` or `save_count=MAX_FRAMES`.\n",
      "  ani = FuncAnimation(fig, update, interval=500)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhis\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\animation.py:872: UserWarning: Animation was deleted without rendering anything. This is most likely not intended. To prevent deletion, assign the Animation to a variable, e.g. `anim`, that exists until you output the Animation using `plt.show()` or `anim.save()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 4 trucks, 1029.6ms\n",
      "Speed: 27.1ms preprocess, 1029.6ms inference, 50.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3 trucks, 2267.3ms\n",
      "Speed: 13.4ms preprocess, 2267.3ms inference, 25.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3 trucks, 563.7ms\n",
      "Speed: 13.9ms preprocess, 563.7ms inference, 7.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 4 trucks, 1007.3ms\n",
      "Speed: 10.7ms preprocess, 1007.3ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4 trucks, 588.7ms\n",
      "Speed: 25.4ms preprocess, 588.7ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 4 trucks, 828.2ms\n",
      "Speed: 7.6ms preprocess, 828.2ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 4 trucks, 329.0ms\n",
      "Speed: 6.8ms preprocess, 329.0ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 3 trucks, 426.3ms\n",
      "Speed: 22.1ms preprocess, 426.3ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 3 trucks, 643.2ms\n",
      "Speed: 6.4ms preprocess, 643.2ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 4 trucks, 1074.6ms\n",
      "Speed: 14.7ms preprocess, 1074.6ms inference, 15.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 3 trucks, 901.8ms\n",
      "Speed: 24.9ms preprocess, 901.8ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 4 trucks, 629.0ms\n",
      "Speed: 17.9ms preprocess, 629.0ms inference, 7.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 4 trucks, 484.8ms\n",
      "Speed: 23.6ms preprocess, 484.8ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 3 trucks, 469.6ms\n",
      "Speed: 9.1ms preprocess, 469.6ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 1 bus, 4 trucks, 378.8ms\n",
      "Speed: 7.3ms preprocess, 378.8ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 2 cars, 4 trucks, 355.5ms\n",
      "Speed: 8.1ms preprocess, 355.5ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bus, 4 trucks, 309.8ms\n",
      "Speed: 8.0ms preprocess, 309.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bus, 3 trucks, 332.4ms\n",
      "Speed: 8.3ms preprocess, 332.4ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 3 trucks, 275.1ms\n",
      "Speed: 7.9ms preprocess, 275.1ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 4 trucks, 328.4ms\n",
      "Speed: 9.0ms preprocess, 328.4ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bus, 3 trucks, 445.1ms\n",
      "Speed: 11.6ms preprocess, 445.1ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 1 bus, 3 trucks, 814.6ms\n",
      "Speed: 16.7ms preprocess, 814.6ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 2 cars, 1 bus, 2 trucks, 362.9ms\n",
      "Speed: 11.4ms preprocess, 362.9ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 bus, 4 trucks, 383.5ms\n",
      "Speed: 9.1ms preprocess, 383.5ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 car, 1 bus, 3 trucks, 360.0ms\n",
      "Speed: 10.8ms preprocess, 360.0ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 car, 4 trucks, 400.5ms\n",
      "Speed: 13.0ms preprocess, 400.5ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 4 trucks, 360.5ms\n",
      "Speed: 23.6ms preprocess, 360.5ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 bus, 2 trucks, 595.7ms\n",
      "Speed: 7.9ms preprocess, 595.7ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 4 trucks, 369.2ms\n",
      "Speed: 9.2ms preprocess, 369.2ms inference, 7.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 4 trucks, 890.6ms\n",
      "Speed: 6.5ms preprocess, 890.6ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 3 trucks, 418.7ms\n",
      "Speed: 8.6ms preprocess, 418.7ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 3 trucks, 373.2ms\n",
      "Speed: 7.5ms preprocess, 373.2ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 3 trucks, 397.0ms\n",
      "Speed: 9.3ms preprocess, 397.0ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4 trucks, 547.1ms\n",
      "Speed: 11.9ms preprocess, 547.1ms inference, 15.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 4 trucks, 362.3ms\n",
      "Speed: 72.6ms preprocess, 362.3ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 4 trucks, 341.0ms\n",
      "Speed: 10.1ms preprocess, 341.0ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 2 cars, 4 trucks, 396.6ms\n",
      "Speed: 11.5ms preprocess, 396.6ms inference, 8.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 4 trucks, 536.3ms\n",
      "Speed: 18.0ms preprocess, 536.3ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 car, 4 trucks, 606.8ms\n",
      "Speed: 8.9ms preprocess, 606.8ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 5 trucks, 426.4ms\n",
      "Speed: 7.1ms preprocess, 426.4ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 cars, 5 trucks, 391.7ms\n",
      "Speed: 11.8ms preprocess, 391.7ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 3 cars, 5 trucks, 483.6ms\n",
      "Speed: 8.2ms preprocess, 483.6ms inference, 11.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 5 trucks, 467.4ms\n",
      "Speed: 17.4ms preprocess, 467.4ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 3 cars, 1 bus, 5 trucks, 2016.7ms\n",
      "Speed: 7.4ms preprocess, 2016.7ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 1 bus, 5 trucks, 533.6ms\n",
      "Speed: 24.9ms preprocess, 533.6ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 cars, 5 trucks, 455.0ms\n",
      "Speed: 8.5ms preprocess, 455.0ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 cars, 5 trucks, 1271.9ms\n",
      "Speed: 7.8ms preprocess, 1271.9ms inference, 7.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 3 cars, 3 trucks, 385.5ms\n",
      "Speed: 8.4ms preprocess, 385.5ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 2 cars, 4 trucks, 396.9ms\n",
      "Speed: 12.6ms preprocess, 396.9ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 cars, 4 trucks, 280.9ms\n",
      "Speed: 7.7ms preprocess, 280.9ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 4 trucks, 808.8ms\n",
      "Speed: 11.6ms preprocess, 808.8ms inference, 6.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 cars, 4 trucks, 824.4ms\n",
      "Speed: 9.6ms preprocess, 824.4ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 4 trucks, 522.3ms\n",
      "Speed: 7.2ms preprocess, 522.3ms inference, 7.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 3 trucks, 461.8ms\n",
      "Speed: 8.9ms preprocess, 461.8ms inference, 16.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 3 trucks, 808.4ms\n",
      "Speed: 22.5ms preprocess, 808.4ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 motorcycle, 1 bus, 2 trucks, 558.7ms\n",
      "Speed: 8.2ms preprocess, 558.7ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 train, 3 trucks, 308.6ms\n",
      "Speed: 8.8ms preprocess, 308.6ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 3 trucks, 339.7ms\n",
      "Speed: 6.8ms preprocess, 339.7ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 motorcycle, 1 train, 1 truck, 463.2ms\n",
      "Speed: 6.4ms preprocess, 463.2ms inference, 8.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 1 motorcycle, 1 truck, 685.8ms\n",
      "Speed: 9.6ms preprocess, 685.8ms inference, 40.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 motorcycle, 1 train, 1 truck, 700.9ms\n",
      "Speed: 26.8ms preprocess, 700.9ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 truck, 680.7ms\n",
      "Speed: 11.1ms preprocess, 680.7ms inference, 8.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 motorcycle, 1 truck, 729.4ms\n",
      "Speed: 19.6ms preprocess, 729.4ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 1 motorcycle, 1 truck, 540.4ms\n",
      "Speed: 7.0ms preprocess, 540.4ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 truck, 432.5ms\n",
      "Speed: 10.2ms preprocess, 432.5ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 motorcycles, 1 truck, 346.6ms\n",
      "Speed: 8.3ms preprocess, 346.6ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 motorcycle, 1 truck, 490.3ms\n",
      "Speed: 10.8ms preprocess, 490.3ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 truck, 686.5ms\n",
      "Speed: 11.8ms preprocess, 686.5ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 motorcycle, 1 truck, 939.4ms\n",
      "Speed: 8.5ms preprocess, 939.4ms inference, 11.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 truck, 531.3ms\n",
      "Speed: 12.2ms preprocess, 531.3ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 motorcycle, 1 truck, 834.7ms\n",
      "Speed: 7.6ms preprocess, 834.7ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 truck, 668.8ms\n",
      "Speed: 85.2ms preprocess, 668.8ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 truck, 563.1ms\n",
      "Speed: 8.9ms preprocess, 563.1ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 1 truck, 468.4ms\n",
      "Speed: 10.9ms preprocess, 468.4ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 truck, 520.5ms\n",
      "Speed: 12.9ms preprocess, 520.5ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 truck, 537.8ms\n",
      "Speed: 10.7ms preprocess, 537.8ms inference, 7.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 truck, 400.6ms\n",
      "Speed: 8.4ms preprocess, 400.6ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 truck, 479.3ms\n",
      "Speed: 9.4ms preprocess, 479.3ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 motorcycles, 1 truck, 359.8ms\n",
      "Speed: 7.8ms preprocess, 359.8ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 motorcycles, 1 truck, 321.5ms\n",
      "Speed: 13.0ms preprocess, 321.5ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 motorcycle, 1 truck, 371.1ms\n",
      "Speed: 9.1ms preprocess, 371.1ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 2 motorcycles, 1 truck, 421.9ms\n",
      "Speed: 10.4ms preprocess, 421.9ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 motorcycles, 1 truck, 494.7ms\n",
      "Speed: 19.8ms preprocess, 494.7ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 2 motorcycles, 1 truck, 451.1ms\n",
      "Speed: 8.5ms preprocess, 451.1ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 2 motorcycles, 1 truck, 354.2ms\n",
      "Speed: 6.9ms preprocess, 354.2ms inference, 7.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 2 motorcycles, 1 truck, 412.4ms\n",
      "Speed: 14.6ms preprocess, 412.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 car, 1 motorcycle, 1 truck, 737.7ms\n",
      "Speed: 8.4ms preprocess, 737.7ms inference, 7.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 car, 1 motorcycle, 1 bus, 1 truck, 692.1ms\n",
      "Speed: 9.8ms preprocess, 692.1ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 car, 1 motorcycle, 1 truck, 369.6ms\n",
      "Speed: 13.4ms preprocess, 369.6ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 car, 1 motorcycle, 1 train, 408.5ms\n",
      "Speed: 10.0ms preprocess, 408.5ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 car, 1 motorcycle, 1 train, 419.7ms\n",
      "Speed: 6.5ms preprocess, 419.7ms inference, 10.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 motorcycle, 1 truck, 569.2ms\n",
      "Speed: 27.6ms preprocess, 569.2ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 motorcycle, 1 bus, 2 trucks, 590.9ms\n",
      "Speed: 157.5ms preprocess, 590.9ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 motorcycle, 1 bus, 2 trucks, 391.9ms\n",
      "Speed: 7.6ms preprocess, 391.9ms inference, 8.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 3 cars, 2 motorcycles, 1 bus, 2 trucks, 554.3ms\n",
      "Speed: 7.6ms preprocess, 554.3ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 2 cars, 2 motorcycles, 1 bus, 2 trucks, 582.5ms\n",
      "Speed: 7.3ms preprocess, 582.5ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 2 cars, 2 motorcycles, 1 bus, 2 trucks, 331.9ms\n",
      "Speed: 9.2ms preprocess, 331.9ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4 cars, 1 motorcycle, 1 bus, 2 trucks, 312.6ms\n",
      "Speed: 7.2ms preprocess, 312.6ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 1 motorcycle, 1 bus, 2 trucks, 492.9ms\n",
      "Speed: 16.6ms preprocess, 492.9ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 motorcycle, 1 bus, 2 trucks, 460.6ms\n",
      "Speed: 11.0ms preprocess, 460.6ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 motorcycle, 2 buss, 1 truck, 416.0ms\n",
      "Speed: 13.2ms preprocess, 416.0ms inference, 7.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 1 motorcycle, 1 bus, 1 truck, 418.5ms\n",
      "Speed: 8.7ms preprocess, 418.5ms inference, 7.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 2 motorcycles, 1 bus, 1 truck, 580.9ms\n",
      "Speed: 9.4ms preprocess, 580.9ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 2 motorcycles, 1 bus, 1 truck, 531.7ms\n",
      "Speed: 29.5ms preprocess, 531.7ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 car, 2 motorcycles, 1 bus, 1 truck, 312.0ms\n",
      "Speed: 9.2ms preprocess, 312.0ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 2 motorcycles, 1 bus, 1 truck, 326.1ms\n",
      "Speed: 11.1ms preprocess, 326.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 1 motorcycle, 1 bus, 1 truck, 319.1ms\n",
      "Speed: 11.3ms preprocess, 319.1ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 car, 3 motorcycles, 372.1ms\n",
      "Speed: 13.4ms preprocess, 372.1ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 3 motorcycles, 1 truck, 414.4ms\n",
      "Speed: 10.2ms preprocess, 414.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 2 motorcycles, 349.8ms\n",
      "Speed: 11.4ms preprocess, 349.8ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 3 motorcycles, 536.0ms\n",
      "Speed: 15.9ms preprocess, 536.0ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 3 motorcycles, 358.3ms\n",
      "Speed: 10.4ms preprocess, 358.3ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 car, 3 motorcycles, 382.5ms\n",
      "Speed: 14.5ms preprocess, 382.5ms inference, 7.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 2 cars, 3 motorcycles, 1 bus, 547.3ms\n",
      "Speed: 10.8ms preprocess, 547.3ms inference, 29.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 cars, 2 motorcycles, 1 bus, 936.6ms\n",
      "Speed: 40.1ms preprocess, 936.6ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 car, 3 motorcycles, 1 bus, 429.1ms\n",
      "Speed: 25.3ms preprocess, 429.1ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 bicycle, 1 car, 3 motorcycles, 417.0ms\n",
      "Speed: 17.9ms preprocess, 417.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 bicycle, 1 car, 2 motorcycles, 342.4ms\n",
      "Speed: 9.0ms preprocess, 342.4ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 bicycle, 1 car, 4 motorcycles, 322.0ms\n",
      "Speed: 11.7ms preprocess, 322.0ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bicycle, 3 motorcycles, 277.2ms\n",
      "Speed: 10.4ms preprocess, 277.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 3 motorcycles, 366.9ms\n",
      "Speed: 12.4ms preprocess, 366.9ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 bicycle, 1 car, 5 motorcycles, 225.9ms\n",
      "Speed: 11.5ms preprocess, 225.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 5 motorcycles, 305.1ms\n",
      "Speed: 10.5ms preprocess, 305.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 car, 4 motorcycles, 1 truck, 331.5ms\n",
      "Speed: 21.3ms preprocess, 331.5ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 car, 4 motorcycles, 320.1ms\n",
      "Speed: 16.3ms preprocess, 320.1ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 3 cars, 4 motorcycles, 699.5ms\n",
      "Speed: 14.6ms preprocess, 699.5ms inference, 7.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 2 motorcycles, 1 truck, 395.1ms\n",
      "Speed: 20.9ms preprocess, 395.1ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 car, 2 motorcycles, 335.8ms\n",
      "Speed: 18.5ms preprocess, 335.8ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 bicycle, 1 car, 2 motorcycles, 281.3ms\n",
      "Speed: 13.9ms preprocess, 281.3ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 bicycle, 2 cars, 2 motorcycles, 271.8ms\n",
      "Speed: 9.0ms preprocess, 271.8ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 bicycle, 3 cars, 1 motorcycle, 338.2ms\n",
      "Speed: 19.9ms preprocess, 338.2ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 bicycle, 1 car, 1 motorcycle, 498.5ms\n",
      "Speed: 10.2ms preprocess, 498.5ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 bicycle, 2 cars, 1 motorcycle, 1 truck, 527.2ms\n",
      "Speed: 17.0ms preprocess, 527.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 bicycle, 1 motorcycle, 1 truck, 521.7ms\n",
      "Speed: 10.6ms preprocess, 521.7ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 bicycle, 1 car, 2 motorcycles, 1 truck, 327.0ms\n",
      "Speed: 8.1ms preprocess, 327.0ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bicycle, 2 cars, 2 motorcycles, 1 truck, 274.8ms\n",
      "Speed: 11.2ms preprocess, 274.8ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 bicycle, 1 car, 1 motorcycle, 1 truck, 416.5ms\n",
      "Speed: 10.9ms preprocess, 416.5ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 bicycle, 1 car, 1 motorcycle, 342.6ms\n",
      "Speed: 21.4ms preprocess, 342.6ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 bicycle, 1 car, 1 motorcycle, 1 bus, 2 trucks, 350.9ms\n",
      "Speed: 10.4ms preprocess, 350.9ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bicycle, 1 car, 1 motorcycle, 1 bus, 1 truck, 285.5ms\n",
      "Speed: 8.6ms preprocess, 285.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 bicycle, 1 car, 1 motorcycle, 1 bus, 2 trucks, 346.1ms\n",
      "Speed: 27.3ms preprocess, 346.1ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 bicycle, 1 car, 1 motorcycle, 2 trucks, 308.4ms\n",
      "Speed: 8.4ms preprocess, 308.4ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 bicycle, 1 car, 1 motorcycle, 1 truck, 365.7ms\n",
      "Speed: 20.3ms preprocess, 365.7ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 bicycle, 1 car, 1 motorcycle, 257.5ms\n",
      "Speed: 6.9ms preprocess, 257.5ms inference, 15.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 bicycle, 1 car, 1 motorcycle, 1 bus, 1 truck, 421.7ms\n",
      "Speed: 14.1ms preprocess, 421.7ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 bicycle, 1 car, 1 motorcycle, 1 bus, 472.9ms\n",
      "Speed: 10.1ms preprocess, 472.9ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 bicycle, 2 cars, 1 motorcycle, 1 bus, 679.3ms\n",
      "Speed: 10.6ms preprocess, 679.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 bicycle, 2 cars, 1 motorcycle, 1 truck, 533.3ms\n",
      "Speed: 13.0ms preprocess, 533.3ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 bicycle, 1 car, 1 motorcycle, 2 trucks, 356.9ms\n",
      "Speed: 16.0ms preprocess, 356.9ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 bicycle, 1 car, 1 motorcycle, 1 truck, 298.9ms\n",
      "Speed: 9.8ms preprocess, 298.9ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 bicycle, 1 car, 1 motorcycle, 1 truck, 386.3ms\n",
      "Speed: 12.6ms preprocess, 386.3ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bicycle, 1 car, 1 motorcycle, 420.9ms\n",
      "Speed: 12.7ms preprocess, 420.9ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 bicycles, 1 car, 1 motorcycle, 1 truck, 579.8ms\n",
      "Speed: 24.5ms preprocess, 579.8ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bicycle, 1 car, 1 motorcycle, 1 truck, 372.8ms\n",
      "Speed: 10.9ms preprocess, 372.8ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 bicycle, 1 car, 1 motorcycle, 1 truck, 429.7ms\n",
      "Speed: 9.8ms preprocess, 429.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 bicycle, 1 car, 1 motorcycle, 1 truck, 282.3ms\n",
      "Speed: 11.5ms preprocess, 282.3ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 bicycle, 1 car, 2 motorcycles, 440.7ms\n",
      "Speed: 9.6ms preprocess, 440.7ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bicycle, 1 car, 1 motorcycle, 2 trucks, 734.8ms\n",
      "Speed: 14.9ms preprocess, 734.8ms inference, 9.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 bicycle, 1 car, 1 motorcycle, 1 truck, 430.1ms\n",
      "Speed: 23.8ms preprocess, 430.1ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 2 bicycles, 2 cars, 1 truck, 372.0ms\n",
      "Speed: 20.4ms preprocess, 372.0ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 2 bicycles, 2 cars, 504.4ms\n",
      "Speed: 15.3ms preprocess, 504.4ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 2 bicycles, 1 car, 1 truck, 417.7ms\n",
      "Speed: 14.8ms preprocess, 417.7ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 2 cars, 1 bus, 1 truck, 382.3ms\n",
      "Speed: 11.4ms preprocess, 382.3ms inference, 8.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 2 cars, 1 truck, 302.8ms\n",
      "Speed: 30.0ms preprocess, 302.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 2 motorcycles, 1 bus, 1 truck, 456.6ms\n",
      "Speed: 8.7ms preprocess, 456.6ms inference, 8.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 car, 1 truck, 396.7ms\n",
      "Speed: 21.9ms preprocess, 396.7ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 car, 2 trucks, 325.6ms\n",
      "Speed: 16.3ms preprocess, 325.6ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 1 truck, 400.6ms\n",
      "Speed: 6.7ms preprocess, 400.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 1 motorcycle, 2 trucks, 1048.7ms\n",
      "Speed: 8.9ms preprocess, 1048.7ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 cars, 2 motorcycles, 1 bus, 1 truck, 348.9ms\n",
      "Speed: 12.1ms preprocess, 348.9ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 2 motorcycles, 1 bus, 1 truck, 241.9ms\n",
      "Speed: 8.7ms preprocess, 241.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 2 cars, 2 motorcycles, 1 bus, 2 trucks, 273.8ms\n",
      "Speed: 10.3ms preprocess, 273.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 2 motorcycles, 1 bus, 317.4ms\n",
      "Speed: 8.8ms preprocess, 317.4ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 1 motorcycle, 2 trucks, 521.6ms\n",
      "Speed: 31.0ms preprocess, 521.6ms inference, 8.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 car, 2 motorcycles, 1 bus, 2 trucks, 405.8ms\n",
      "Speed: 21.2ms preprocess, 405.8ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 2 motorcycles, 1 bus, 2 trucks, 394.3ms\n",
      "Speed: 14.1ms preprocess, 394.3ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 3 motorcycles, 1 bus, 1 truck, 435.7ms\n",
      "Speed: 13.3ms preprocess, 435.7ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 1 motorcycle, 1 bus, 1 truck, 809.7ms\n",
      "Speed: 32.6ms preprocess, 809.7ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 2 motorcycles, 1 bus, 1 truck, 462.0ms\n",
      "Speed: 13.3ms preprocess, 462.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 cars, 1 motorcycle, 1 bus, 1 truck, 1042.7ms\n",
      "Speed: 27.6ms preprocess, 1042.7ms inference, 8.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 cars, 2 motorcycles, 549.0ms\n",
      "Speed: 24.7ms preprocess, 549.0ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 cars, 1 motorcycle, 507.9ms\n",
      "Speed: 20.1ms preprocess, 507.9ms inference, 7.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 cars, 2 motorcycles, 438.4ms\n",
      "Speed: 26.2ms preprocess, 438.4ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 3 motorcycles, 663.7ms\n",
      "Speed: 16.4ms preprocess, 663.7ms inference, 10.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 car, 4 motorcycles, 939.2ms\n",
      "Speed: 27.5ms preprocess, 939.2ms inference, 7.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 bicycle, 1 car, 2 motorcycles, 1 truck, 697.1ms\n",
      "Speed: 20.0ms preprocess, 697.1ms inference, 8.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bicycle, 1 car, 2 motorcycles, 554.1ms\n",
      "Speed: 17.1ms preprocess, 554.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 bicycle, 2 cars, 3 motorcycles, 595.8ms\n",
      "Speed: 13.5ms preprocess, 595.8ms inference, 7.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 bicycle, 2 cars, 1 motorcycle, 522.7ms\n",
      "Speed: 41.2ms preprocess, 522.7ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 bicycle, 3 cars, 4 motorcycles, 332.7ms\n",
      "Speed: 14.9ms preprocess, 332.7ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 bicycle, 2 cars, 2 motorcycles, 345.8ms\n",
      "Speed: 21.3ms preprocess, 345.8ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 bicycles, 1 motorcycle, 342.9ms\n",
      "Speed: 17.3ms preprocess, 342.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 bicycles, 1 car, 1 motorcycle, 262.6ms\n",
      "Speed: 9.0ms preprocess, 262.6ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 bicycle, 2 motorcycles, 373.3ms\n",
      "Speed: 40.8ms preprocess, 373.3ms inference, 7.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 2 bicycles, 2 motorcycles, 519.9ms\n",
      "Speed: 18.0ms preprocess, 519.9ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 bicycle, 2 motorcycles, 443.7ms\n",
      "Speed: 17.4ms preprocess, 443.7ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 bicycle, 2 motorcycles, 456.8ms\n",
      "Speed: 26.9ms preprocess, 456.8ms inference, 7.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 bicycle, 1 car, 2 motorcycles, 619.2ms\n",
      "Speed: 23.3ms preprocess, 619.2ms inference, 8.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 bicycle, 1 car, 2 motorcycles, 441.2ms\n",
      "Speed: 17.0ms preprocess, 441.2ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 bicycle, 2 motorcycles, 1 truck, 356.9ms\n",
      "Speed: 14.0ms preprocess, 356.9ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 bicycle, 2 motorcycles, 320.5ms\n",
      "Speed: 10.1ms preprocess, 320.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 bicycle, 2 motorcycles, 589.0ms\n",
      "Speed: 37.0ms preprocess, 589.0ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 bicycle, 3 cars, 2 motorcycles, 489.5ms\n",
      "Speed: 16.6ms preprocess, 489.5ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 bicycle, 2 cars, 1 motorcycle, 379.7ms\n",
      "Speed: 21.8ms preprocess, 379.7ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bicycle, 2 cars, 1 motorcycle, 429.3ms\n",
      "Speed: 11.3ms preprocess, 429.3ms inference, 8.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 bicycle, 2 cars, 1 motorcycle, 1 truck, 466.6ms\n",
      "Speed: 16.1ms preprocess, 466.6ms inference, 9.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 bicycle, 4 cars, 1 motorcycle, 528.5ms\n",
      "Speed: 17.0ms preprocess, 528.5ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 bicycle, 1 car, 1 motorcycle, 546.7ms\n",
      "Speed: 16.8ms preprocess, 546.7ms inference, 8.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bicycle, 2 cars, 1 motorcycle, 584.6ms\n",
      "Speed: 26.0ms preprocess, 584.6ms inference, 13.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 bicycle, 2 cars, 1 motorcycle, 800.0ms\n",
      "Speed: 13.5ms preprocess, 800.0ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bicycle, 4 cars, 1 motorcycle, 306.0ms\n",
      "Speed: 20.0ms preprocess, 306.0ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 bicycle, 1 car, 1 motorcycle, 312.9ms\n",
      "Speed: 11.9ms preprocess, 312.9ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bicycle, 2 cars, 2 motorcycles, 546.5ms\n",
      "Speed: 15.7ms preprocess, 546.5ms inference, 10.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 bicycle, 1 car, 2 motorcycles, 565.5ms\n",
      "Speed: 24.8ms preprocess, 565.5ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 bicycle, 1 car, 3 motorcycles, 476.1ms\n",
      "Speed: 14.8ms preprocess, 476.1ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bicycle, 2 cars, 2 motorcycles, 442.9ms\n",
      "Speed: 11.5ms preprocess, 442.9ms inference, 11.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bicycle, 1 car, 3 motorcycles, 1 truck, 669.5ms\n",
      "Speed: 14.5ms preprocess, 669.5ms inference, 10.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 bicycle, 1 car, 3 motorcycles, 781.5ms\n",
      "Speed: 43.4ms preprocess, 781.5ms inference, 7.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 bicycle, 1 car, 2 motorcycles, 799.5ms\n",
      "Speed: 9.2ms preprocess, 799.5ms inference, 7.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 bicycle, 1 car, 3 motorcycles, 625.5ms\n",
      "Speed: 15.5ms preprocess, 625.5ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bicycle, 1 car, 2 motorcycles, 1024.7ms\n",
      "Speed: 16.2ms preprocess, 1024.7ms inference, 23.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 bicycles, 1 car, 1 motorcycle, 1 truck, 1248.9ms\n",
      "Speed: 79.6ms preprocess, 1248.9ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 bicycles, 1 car, 1 motorcycle, 1 truck, 683.6ms\n",
      "Speed: 34.0ms preprocess, 683.6ms inference, 9.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 bicycle, 1 motorcycle, 1 truck, 531.1ms\n",
      "Speed: 34.3ms preprocess, 531.1ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 bicycle, 1 motorcycle, 1 truck, 639.5ms\n",
      "Speed: 46.8ms preprocess, 639.5ms inference, 8.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 car, 1 motorcycle, 1 truck, 793.5ms\n",
      "Speed: 20.0ms preprocess, 793.5ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 motorcycle, 1 truck, 848.2ms\n",
      "Speed: 13.7ms preprocess, 848.2ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 1 motorcycle, 1 truck, 707.3ms\n",
      "Speed: 34.9ms preprocess, 707.3ms inference, 10.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 motorcycle, 1 truck, 477.4ms\n",
      "Speed: 23.6ms preprocess, 477.4ms inference, 10.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 1 motorcycle, 1 truck, 529.6ms\n",
      "Speed: 17.1ms preprocess, 529.6ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 motorcycle, 1 truck, 402.9ms\n",
      "Speed: 16.7ms preprocess, 402.9ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 2 motorcycles, 1 truck, 541.6ms\n",
      "Speed: 27.8ms preprocess, 541.6ms inference, 8.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 1 motorcycle, 1 truck, 652.4ms\n",
      "Speed: 17.5ms preprocess, 652.4ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 motorcycle, 1 truck, 566.3ms\n",
      "Speed: 14.6ms preprocess, 566.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 car, 1 motorcycle, 1 truck, 545.3ms\n",
      "Speed: 16.7ms preprocess, 545.3ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 motorcycle, 1 truck, 583.7ms\n",
      "Speed: 92.7ms preprocess, 583.7ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 motorcycle, 1 truck, 434.9ms\n",
      "Speed: 47.6ms preprocess, 434.9ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 motorcycle, 1 truck, 707.0ms\n",
      "Speed: 19.8ms preprocess, 707.0ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 cars, 1 motorcycle, 2 trucks, 510.0ms\n",
      "Speed: 19.5ms preprocess, 510.0ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 3 cars, 1 motorcycle, 2 trucks, 417.8ms\n",
      "Speed: 16.3ms preprocess, 417.8ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 3 cars, 1 motorcycle, 1 truck, 398.3ms\n",
      "Speed: 11.9ms preprocess, 398.3ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 4 cars, 2 motorcycles, 1 truck, 424.1ms\n",
      "Speed: 13.8ms preprocess, 424.1ms inference, 8.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 cars, 2 motorcycles, 1 truck, 458.5ms\n",
      "Speed: 21.6ms preprocess, 458.5ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 cars, 2 motorcycles, 1 truck, 493.4ms\n",
      "Speed: 13.8ms preprocess, 493.4ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 bicycle, 1 car, 1 motorcycle, 1 truck, 596.5ms\n",
      "Speed: 16.7ms preprocess, 596.5ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 car, 3 motorcycles, 386.7ms\n",
      "Speed: 14.6ms preprocess, 386.7ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 3 motorcycles, 2 trucks, 439.8ms\n",
      "Speed: 23.3ms preprocess, 439.8ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 car, 3 motorcycles, 1 truck, 792.1ms\n",
      "Speed: 13.8ms preprocess, 792.1ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 2 motorcycles, 1 truck, 548.2ms\n",
      "Speed: 27.0ms preprocess, 548.2ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 bicycle, 1 car, 1 motorcycle, 1 truck, 449.1ms\n",
      "Speed: 15.6ms preprocess, 449.1ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 bicycle, 1 car, 2 motorcycles, 469.7ms\n",
      "Speed: 22.1ms preprocess, 469.7ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 2 motorcycles, 2 trucks, 390.8ms\n",
      "Speed: 12.9ms preprocess, 390.8ms inference, 7.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 3 motorcycles, 1 truck, 411.3ms\n",
      "Speed: 11.6ms preprocess, 411.3ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 3 motorcycles, 3 trucks, 371.9ms\n",
      "Speed: 19.5ms preprocess, 371.9ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 2 motorcycles, 2 trucks, 312.2ms\n",
      "Speed: 14.4ms preprocess, 312.2ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 motorcycle, 3 trucks, 769.1ms\n",
      "Speed: 79.1ms preprocess, 769.1ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 3 motorcycles, 2 trucks, 447.2ms\n",
      "Speed: 16.0ms preprocess, 447.2ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 cars, 3 motorcycles, 2 trucks, 369.7ms\n",
      "Speed: 14.0ms preprocess, 369.7ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 motorcycle, 2 trucks, 559.4ms\n",
      "Speed: 22.6ms preprocess, 559.4ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 motorcycle, 3 trucks, 367.2ms\n",
      "Speed: 10.6ms preprocess, 367.2ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 1 motorcycle, 1 bus, 3 trucks, 958.0ms\n",
      "Speed: 19.1ms preprocess, 958.0ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 1 motorcycle, 1 bus, 3 trucks, 495.1ms\n",
      "Speed: 18.5ms preprocess, 495.1ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 motorcycle, 4 trucks, 475.1ms\n",
      "Speed: 22.8ms preprocess, 475.1ms inference, 7.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 2 motorcycles, 1 bus, 5 trucks, 466.6ms\n",
      "Speed: 20.5ms preprocess, 466.6ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 motorcycle, 1 bus, 5 trucks, 380.7ms\n",
      "Speed: 15.6ms preprocess, 380.7ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 motorcycle, 2 buss, 2 trucks, 761.4ms\n",
      "Speed: 20.7ms preprocess, 761.4ms inference, 9.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 motorcycles, 3 trucks, 995.0ms\n",
      "Speed: 24.8ms preprocess, 995.0ms inference, 9.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 motorcycles, 2 buss, 2 trucks, 1054.5ms\n",
      "Speed: 19.1ms preprocess, 1054.5ms inference, 8.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 motorcycle, 2 buss, 3 trucks, 676.2ms\n",
      "Speed: 19.7ms preprocess, 676.2ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 motorcycle, 2 buss, 1 train, 2 trucks, 409.2ms\n",
      "Speed: 10.6ms preprocess, 409.2ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 motorcycles, 2 buss, 4 trucks, 432.4ms\n",
      "Speed: 14.5ms preprocess, 432.4ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 motorcycle, 1 bus, 1 train, 4 trucks, 372.5ms\n",
      "Speed: 20.4ms preprocess, 372.5ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 motorcycles, 3 trucks, 435.1ms\n",
      "Speed: 25.4ms preprocess, 435.1ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 motorcycles, 2 trucks, 780.0ms\n",
      "Speed: 13.6ms preprocess, 780.0ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 motorcycle, 2 trucks, 518.3ms\n",
      "Speed: 15.8ms preprocess, 518.3ms inference, 7.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 4 motorcycles, 2 trucks, 845.7ms\n",
      "Speed: 11.8ms preprocess, 845.7ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 4 motorcycles, 2 trucks, 472.4ms\n",
      "Speed: 22.6ms preprocess, 472.4ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 3 motorcycles, 4 trucks, 631.0ms\n",
      "Speed: 15.6ms preprocess, 631.0ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 3 motorcycles, 4 trucks, 456.0ms\n",
      "Speed: 13.9ms preprocess, 456.0ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 2 motorcycles, 4 trucks, 479.0ms\n",
      "Speed: 16.7ms preprocess, 479.0ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 2 motorcycles, 2 trucks, 365.0ms\n",
      "Speed: 11.6ms preprocess, 365.0ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 3 motorcycles, 3 trucks, 369.3ms\n",
      "Speed: 12.2ms preprocess, 369.3ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3 motorcycles, 2 trucks, 301.2ms\n",
      "Speed: 14.1ms preprocess, 301.2ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 2 motorcycles, 2 trucks, 449.4ms\n",
      "Speed: 13.5ms preprocess, 449.4ms inference, 10.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 2 motorcycles, 1 truck, 558.6ms\n",
      "Speed: 34.7ms preprocess, 558.6ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 3 motorcycles, 3 trucks, 510.7ms\n",
      "Speed: 22.3ms preprocess, 510.7ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 2 motorcycles, 4 trucks, 595.4ms\n",
      "Speed: 126.5ms preprocess, 595.4ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 3 motorcycles, 3 trucks, 409.9ms\n",
      "Speed: 18.1ms preprocess, 409.9ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 3 motorcycles, 3 trucks, 598.3ms\n",
      "Speed: 15.5ms preprocess, 598.3ms inference, 6.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 3 motorcycles, 3 trucks, 417.5ms\n",
      "Speed: 16.0ms preprocess, 417.5ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 3 motorcycles, 3 trucks, 419.9ms\n",
      "Speed: 17.4ms preprocess, 419.9ms inference, 10.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 3 motorcycles, 4 trucks, 382.8ms\n",
      "Speed: 10.6ms preprocess, 382.8ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 motorcycles, 4 trucks, 326.4ms\n",
      "Speed: 12.8ms preprocess, 326.4ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 motorcycles, 4 trucks, 355.1ms\n",
      "Speed: 15.2ms preprocess, 355.1ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 3 motorcycles, 4 trucks, 461.6ms\n",
      "Speed: 12.9ms preprocess, 461.6ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 motorcycles, 5 trucks, 1497.5ms\n",
      "Speed: 36.0ms preprocess, 1497.5ms inference, 10.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 2 motorcycles, 4 trucks, 524.3ms\n",
      "Speed: 21.9ms preprocess, 524.3ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 motorcycles, 4 trucks, 425.1ms\n",
      "Speed: 16.6ms preprocess, 425.1ms inference, 7.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 motorcycles, 3 trucks, 661.4ms\n",
      "Speed: 22.4ms preprocess, 661.4ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 motorcycles, 3 trucks, 477.5ms\n",
      "Speed: 21.9ms preprocess, 477.5ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 2 motorcycles, 3 trucks, 476.8ms\n",
      "Speed: 9.7ms preprocess, 476.8ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 2 motorcycles, 2 buss, 2 trucks, 368.4ms\n",
      "Speed: 20.6ms preprocess, 368.4ms inference, 9.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 motorcycle, 1 bus, 1 truck, 421.5ms\n",
      "Speed: 12.5ms preprocess, 421.5ms inference, 7.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 motorcycle, 1 bus, 492.0ms\n",
      "Speed: 15.9ms preprocess, 492.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 1 motorcycle, 1 bus, 1 train, 532.3ms\n",
      "Speed: 16.6ms preprocess, 532.3ms inference, 10.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 motorcycle, 1 bus, 1 train, 1335.2ms\n",
      "Speed: 20.3ms preprocess, 1335.2ms inference, 8.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 motorcycle, 1 train, 502.5ms\n",
      "Speed: 31.6ms preprocess, 502.5ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 motorcycle, 517.8ms\n",
      "Speed: 17.7ms preprocess, 517.8ms inference, 10.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 car, 2 motorcycles, 1 train, 640.3ms\n",
      "Speed: 22.8ms preprocess, 640.3ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 2 cars, 2 motorcycles, 1 bus, 642.0ms\n",
      "Speed: 21.8ms preprocess, 642.0ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3 cars, 1 motorcycle, 700.7ms\n",
      "Speed: 21.0ms preprocess, 700.7ms inference, 9.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3 cars, 2 motorcycles, 454.0ms\n",
      "Speed: 27.4ms preprocess, 454.0ms inference, 9.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 2 cars, 1 motorcycle, 543.5ms\n",
      "Speed: 12.5ms preprocess, 543.5ms inference, 7.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3 cars, 1 motorcycle, 1004.1ms\n",
      "Speed: 16.1ms preprocess, 1004.1ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 3 cars, 895.2ms\n",
      "Speed: 23.1ms preprocess, 895.2ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 4 cars, 1 bus, 1 truck, 516.8ms\n",
      "Speed: 18.8ms preprocess, 516.8ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 1 bus, 351.8ms\n",
      "Speed: 11.3ms preprocess, 351.8ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 cars, 1 train, 597.7ms\n",
      "Speed: 17.5ms preprocess, 597.7ms inference, 9.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 cars, 1 truck, 2016.2ms\n",
      "Speed: 33.0ms preprocess, 2016.2ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 cars, 1 train, 2 trucks, 1542.1ms\n",
      "Speed: 18.5ms preprocess, 1542.1ms inference, 13.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 2 trucks, 1142.7ms\n",
      "Speed: 29.6ms preprocess, 1142.7ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 car, 1 bus, 1 train, 715.8ms\n",
      "Speed: 52.1ms preprocess, 715.8ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 bus, 2 trucks, 439.5ms\n",
      "Speed: 18.6ms preprocess, 439.5ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 bus, 1 truck, 440.0ms\n",
      "Speed: 16.6ms preprocess, 440.0ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 bus, 2 trucks, 444.0ms\n",
      "Speed: 14.5ms preprocess, 444.0ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 bus, 2 trucks, 715.8ms\n",
      "Speed: 15.7ms preprocess, 715.8ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bus, 3 trucks, 551.0ms\n",
      "Speed: 23.5ms preprocess, 551.0ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 bus, 3 trucks, 585.2ms\n",
      "Speed: 16.2ms preprocess, 585.2ms inference, 32.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bus, 3 trucks, 455.9ms\n",
      "Speed: 15.7ms preprocess, 455.9ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bus, 2 trucks, 681.1ms\n",
      "Speed: 19.6ms preprocess, 681.1ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bus, 2 trucks, 2810.4ms\n",
      "Speed: 36.9ms preprocess, 2810.4ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bus, 2 trucks, 2959.9ms\n",
      "Speed: 57.2ms preprocess, 2959.9ms inference, 20.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 bus, 2 trucks, 1223.1ms\n",
      "Speed: 64.0ms preprocess, 1223.1ms inference, 21.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 2 buss, 2 trucks, 1062.2ms\n",
      "Speed: 32.7ms preprocess, 1062.2ms inference, 10.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 2 buss, 2 trucks, 1851.2ms\n",
      "Speed: 60.0ms preprocess, 1851.2ms inference, 10.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 bus, 2 trucks, 1710.6ms\n",
      "Speed: 21.9ms preprocess, 1710.6ms inference, 11.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 bus, 3 trucks, 1084.4ms\n",
      "Speed: 20.3ms preprocess, 1084.4ms inference, 9.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bus, 2 trucks, 695.5ms\n",
      "Speed: 27.4ms preprocess, 695.5ms inference, 14.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 2 trucks, 1855.9ms\n",
      "Speed: 30.5ms preprocess, 1855.9ms inference, 9.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 2 trucks, 1492.9ms\n",
      "Speed: 30.3ms preprocess, 1492.9ms inference, 8.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 2 trucks, 986.3ms\n",
      "Speed: 23.3ms preprocess, 986.3ms inference, 10.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 2 trucks, 1722.9ms\n",
      "Speed: 35.7ms preprocess, 1722.9ms inference, 10.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 3 trucks, 1166.8ms\n",
      "Speed: 32.8ms preprocess, 1166.8ms inference, 24.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 car, 2 trucks, 1019.2ms\n",
      "Speed: 28.0ms preprocess, 1019.2ms inference, 7.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 car, 2 trucks, 667.9ms\n",
      "Speed: 26.3ms preprocess, 667.9ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 car, 2 trucks, 484.7ms\n",
      "Speed: 8.6ms preprocess, 484.7ms inference, 7.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 3 trucks, 804.6ms\n",
      "Speed: 19.8ms preprocess, 804.6ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 3 trucks, 2408.4ms\n",
      "Speed: 44.4ms preprocess, 2408.4ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 3 trucks, 633.7ms\n",
      "Speed: 10.8ms preprocess, 633.7ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 3 trucks, 641.3ms\n",
      "Speed: 20.1ms preprocess, 641.3ms inference, 24.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 bus, 3 trucks, 3392.9ms\n",
      "Speed: 675.8ms preprocess, 3392.9ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 cars, 3 trucks, 425.1ms\n",
      "Speed: 16.0ms preprocess, 425.1ms inference, 7.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 cars, 1 bus, 3 trucks, 461.7ms\n",
      "Speed: 10.7ms preprocess, 461.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 1 bus, 3 trucks, 719.9ms\n",
      "Speed: 24.6ms preprocess, 719.9ms inference, 16.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 car, 1 bus, 3 trucks, 762.5ms\n",
      "Speed: 21.3ms preprocess, 762.5ms inference, 6.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 bus, 3 trucks, 404.9ms\n",
      "Speed: 10.3ms preprocess, 404.9ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bus, 4 trucks, 593.1ms\n",
      "Speed: 15.3ms preprocess, 593.1ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bus, 3 trucks, 612.5ms\n",
      "Speed: 24.0ms preprocess, 612.5ms inference, 9.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 bus, 3 trucks, 403.8ms\n",
      "Speed: 19.7ms preprocess, 403.8ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bus, 3 trucks, 603.7ms\n",
      "Speed: 14.8ms preprocess, 603.7ms inference, 7.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 bus, 4 trucks, 595.1ms\n",
      "Speed: 10.3ms preprocess, 595.1ms inference, 7.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 car, 1 bus, 4 trucks, 1225.8ms\n",
      "Speed: 9.5ms preprocess, 1225.8ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 4 trucks, 531.8ms\n",
      "Speed: 17.6ms preprocess, 531.8ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bus, 2 trucks, 588.0ms\n",
      "Speed: 24.7ms preprocess, 588.0ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 bus, 3 trucks, 449.5ms\n",
      "Speed: 14.4ms preprocess, 449.5ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bus, 4 trucks, 1040.8ms\n",
      "Speed: 23.6ms preprocess, 1040.8ms inference, 25.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 bus, 4 trucks, 1098.2ms\n",
      "Speed: 34.6ms preprocess, 1098.2ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bus, 5 trucks, 813.7ms\n",
      "Speed: 25.8ms preprocess, 813.7ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 1 bus, 4 trucks, 1191.4ms\n",
      "Speed: 19.4ms preprocess, 1191.4ms inference, 11.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 1 bus, 4 trucks, 773.3ms\n",
      "Speed: 73.9ms preprocess, 773.3ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 1 bus, 3 trucks, 394.7ms\n",
      "Speed: 11.1ms preprocess, 394.7ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 1 bus, 4 trucks, 443.6ms\n",
      "Speed: 18.8ms preprocess, 443.6ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 1 bus, 5 trucks, 498.8ms\n",
      "Speed: 11.8ms preprocess, 498.8ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 5 trucks, 647.0ms\n",
      "Speed: 14.6ms preprocess, 647.0ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 car, 1 bus, 6 trucks, 608.0ms\n",
      "Speed: 17.1ms preprocess, 608.0ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 bus, 5 trucks, 443.6ms\n",
      "Speed: 22.0ms preprocess, 443.6ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 3 trucks, 512.0ms\n",
      "Speed: 20.4ms preprocess, 512.0ms inference, 7.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bus, 3 trucks, 613.3ms\n",
      "Speed: 13.9ms preprocess, 613.3ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 trucks, 616.1ms\n",
      "Speed: 29.6ms preprocess, 616.1ms inference, 12.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 2 trucks, 791.8ms\n",
      "Speed: 41.1ms preprocess, 791.8ms inference, 7.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 5 trucks, 660.3ms\n",
      "Speed: 24.5ms preprocess, 660.3ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 trucks, 461.5ms\n",
      "Speed: 11.7ms preprocess, 461.5ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 4 trucks, 582.0ms\n",
      "Speed: 15.1ms preprocess, 582.0ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 4 trucks, 623.8ms\n",
      "Speed: 21.4ms preprocess, 623.8ms inference, 6.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 trucks, 342.2ms\n",
      "Speed: 41.2ms preprocess, 342.2ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 trucks, 458.1ms\n",
      "Speed: 14.1ms preprocess, 458.1ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 trucks, 683.3ms\n",
      "Speed: 15.8ms preprocess, 683.3ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bus, 5 trucks, 1076.4ms\n",
      "Speed: 16.8ms preprocess, 1076.4ms inference, 6.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 buss, 5 trucks, 504.4ms\n",
      "Speed: 26.9ms preprocess, 504.4ms inference, 10.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 buss, 4 trucks, 403.0ms\n",
      "Speed: 12.1ms preprocess, 403.0ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 2 buss, 5 trucks, 416.7ms\n",
      "Speed: 10.2ms preprocess, 416.7ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 cars, 2 buss, 3 trucks, 574.1ms\n",
      "Speed: 23.4ms preprocess, 574.1ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 2 buss, 3 trucks, 419.5ms\n",
      "Speed: 22.5ms preprocess, 419.5ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bus, 3 trucks, 487.1ms\n",
      "Speed: 22.2ms preprocess, 487.1ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 bus, 2 trucks, 472.3ms\n",
      "Speed: 12.8ms preprocess, 472.3ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 bus, 3 trucks, 669.1ms\n",
      "Speed: 15.7ms preprocess, 669.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 2 buss, 3 trucks, 408.4ms\n",
      "Speed: 15.6ms preprocess, 408.4ms inference, 11.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 2 buss, 2 trucks, 1027.5ms\n",
      "Speed: 10.7ms preprocess, 1027.5ms inference, 11.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 2 buss, 2 trucks, 524.9ms\n",
      "Speed: 24.9ms preprocess, 524.9ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 2 buss, 3 trucks, 503.9ms\n",
      "Speed: 11.2ms preprocess, 503.9ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 cars, 2 buss, 3 trucks, 544.5ms\n",
      "Speed: 11.9ms preprocess, 544.5ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 1 bus, 2 trucks, 394.1ms\n",
      "Speed: 15.0ms preprocess, 394.1ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 2 buss, 2 trucks, 335.9ms\n",
      "Speed: 12.9ms preprocess, 335.9ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 cars, 2 buss, 2 trucks, 551.8ms\n",
      "Speed: 17.7ms preprocess, 551.8ms inference, 8.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 cars, 2 buss, 2 trucks, 478.0ms\n",
      "Speed: 15.3ms preprocess, 478.0ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 2 cars, 2 buss, 1 truck, 372.9ms\n",
      "Speed: 11.8ms preprocess, 372.9ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 2 cars, 2 buss, 2 trucks, 607.1ms\n",
      "Speed: 22.4ms preprocess, 607.1ms inference, 9.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 2 cars, 2 buss, 3 trucks, 814.6ms\n",
      "Speed: 12.9ms preprocess, 814.6ms inference, 7.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 2 buss, 3 trucks, 491.7ms\n",
      "Speed: 21.7ms preprocess, 491.7ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 2 buss, 3 trucks, 442.5ms\n",
      "Speed: 25.7ms preprocess, 442.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 buss, 3 trucks, 441.7ms\n",
      "Speed: 17.7ms preprocess, 441.7ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 1 bus, 4 trucks, 599.1ms\n",
      "Speed: 14.7ms preprocess, 599.1ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 buss, 3 trucks, 531.5ms\n",
      "Speed: 13.6ms preprocess, 531.5ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 2 buss, 4 trucks, 1010.6ms\n",
      "Speed: 19.8ms preprocess, 1010.6ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 2 buss, 4 trucks, 428.3ms\n",
      "Speed: 11.6ms preprocess, 428.3ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 2 buss, 6 trucks, 741.1ms\n",
      "Speed: 26.9ms preprocess, 741.1ms inference, 14.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 2 cars, 2 buss, 5 trucks, 821.1ms\n",
      "Speed: 32.6ms preprocess, 821.1ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 2 buss, 5 trucks, 476.7ms\n",
      "Speed: 26.4ms preprocess, 476.7ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 2 buss, 5 trucks, 1075.0ms\n",
      "Speed: 21.3ms preprocess, 1075.0ms inference, 9.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 2 buss, 5 trucks, 812.7ms\n",
      "Speed: 48.4ms preprocess, 812.7ms inference, 11.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 2 buss, 4 trucks, 632.7ms\n",
      "Speed: 18.8ms preprocess, 632.7ms inference, 6.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 2 buss, 5 trucks, 552.6ms\n",
      "Speed: 18.3ms preprocess, 552.6ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 2 buss, 5 trucks, 809.3ms\n",
      "Speed: 18.5ms preprocess, 809.3ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 2 cars, 2 buss, 4 trucks, 1264.4ms\n",
      "Speed: 17.4ms preprocess, 1264.4ms inference, 12.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 2 buss, 2 trucks, 756.2ms\n",
      "Speed: 14.4ms preprocess, 756.2ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 2 buss, 2 trucks, 446.2ms\n",
      "Speed: 18.6ms preprocess, 446.2ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 car, 2 buss, 3 trucks, 409.3ms\n",
      "Speed: 28.5ms preprocess, 409.3ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 car, 2 buss, 5 trucks, 351.5ms\n",
      "Speed: 11.9ms preprocess, 351.5ms inference, 8.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 2 cars, 2 buss, 5 trucks, 450.2ms\n",
      "Speed: 11.6ms preprocess, 450.2ms inference, 6.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 2 cars, 1 bus, 6 trucks, 537.8ms\n",
      "Speed: 13.9ms preprocess, 537.8ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 2 cars, 1 bus, 7 trucks, 417.8ms\n",
      "Speed: 16.2ms preprocess, 417.8ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 3 cars, 1 bus, 6 trucks, 365.2ms\n",
      "Speed: 10.0ms preprocess, 365.2ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 car, 1 bus, 5 trucks, 580.1ms\n",
      "Speed: 11.9ms preprocess, 580.1ms inference, 7.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 6 trucks, 558.6ms\n",
      "Speed: 21.2ms preprocess, 558.6ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 6 trucks, 460.9ms\n",
      "Speed: 17.6ms preprocess, 460.9ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 5 trucks, 399.5ms\n",
      "Speed: 24.8ms preprocess, 399.5ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 bicycle, 1 car, 6 trucks, 339.0ms\n",
      "Speed: 9.3ms preprocess, 339.0ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bicycle, 6 trucks, 454.4ms\n",
      "Speed: 9.4ms preprocess, 454.4ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bicycle, 1 car, 6 trucks, 391.1ms\n",
      "Speed: 12.9ms preprocess, 391.1ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 bicycle, 1 bus, 4 trucks, 617.1ms\n",
      "Speed: 11.9ms preprocess, 617.1ms inference, 9.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bicycle, 1 bus, 4 trucks, 541.1ms\n",
      "Speed: 16.2ms preprocess, 541.1ms inference, 8.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bicycle, 1 bus, 4 trucks, 554.5ms\n",
      "Speed: 67.3ms preprocess, 554.5ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bicycle, 2 trucks, 1934.5ms\n",
      "Speed: 79.3ms preprocess, 1934.5ms inference, 15.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bicycle, 3 trucks, 566.6ms\n",
      "Speed: 21.1ms preprocess, 566.6ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bicycle, 1 truck, 472.4ms\n",
      "Speed: 25.5ms preprocess, 472.4ms inference, 10.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bicycle, 1 truck, 438.0ms\n",
      "Speed: 12.4ms preprocess, 438.0ms inference, 9.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 bicycle, 1 truck, 509.1ms\n",
      "Speed: 18.1ms preprocess, 509.1ms inference, 8.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 bicycle, 1 truck, 752.5ms\n",
      "Speed: 18.0ms preprocess, 752.5ms inference, 9.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 2 bicycles, 1 truck, 498.8ms\n",
      "Speed: 35.9ms preprocess, 498.8ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 bicycle, 3 trucks, 1178.4ms\n",
      "Speed: 16.7ms preprocess, 1178.4ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 bicycle, 1 bus, 2 trucks, 463.9ms\n",
      "Speed: 14.6ms preprocess, 463.9ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 bicycle, 1 bus, 2 trucks, 329.8ms\n",
      "Speed: 10.0ms preprocess, 329.8ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 bicycle, 2 buss, 2 trucks, 328.4ms\n",
      "Speed: 16.7ms preprocess, 328.4ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 bicycle, 1 motorcycle, 2 buss, 2 trucks, 343.2ms\n",
      "Speed: 11.7ms preprocess, 343.2ms inference, 6.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 bicycle, 2 buss, 2 trucks, 540.7ms\n",
      "Speed: 19.5ms preprocess, 540.7ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 bicycle, 1 car, 2 trucks, 343.5ms\n",
      "Speed: 10.0ms preprocess, 343.5ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 bicycle, 1 bus, 1 truck, 437.3ms\n",
      "Speed: 10.9ms preprocess, 437.3ms inference, 8.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 2 trucks, 549.3ms\n",
      "Speed: 26.4ms preprocess, 549.3ms inference, 7.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 1 bus, 2 trucks, 677.0ms\n",
      "Speed: 28.6ms preprocess, 677.0ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 bicycle, 1 bus, 2 trucks, 506.7ms\n",
      "Speed: 13.0ms preprocess, 506.7ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 2 trucks, 395.5ms\n",
      "Speed: 18.3ms preprocess, 395.5ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 2 trucks, 529.6ms\n",
      "Speed: 15.4ms preprocess, 529.6ms inference, 8.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 2 trucks, 575.2ms\n",
      "Speed: 15.2ms preprocess, 575.2ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 1 car, 2 trucks, 438.1ms\n",
      "Speed: 14.8ms preprocess, 438.1ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 2 bicycles, 1 bus, 2 trucks, 577.6ms\n",
      "Speed: 12.5ms preprocess, 577.6ms inference, 9.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 1 car, 2 trucks, 929.1ms\n",
      "Speed: 39.6ms preprocess, 929.1ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 1 car, 2 trucks, 658.8ms\n",
      "Speed: 18.9ms preprocess, 658.8ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 1 bus, 2 trucks, 453.3ms\n",
      "Speed: 12.5ms preprocess, 453.3ms inference, 10.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 3 trucks, 842.3ms\n",
      "Speed: 26.3ms preprocess, 842.3ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 1 bus, 3 trucks, 379.0ms\n",
      "Speed: 17.3ms preprocess, 379.0ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 1 motorcycle, 2 trucks, 390.4ms\n",
      "Speed: 14.2ms preprocess, 390.4ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 2 trucks, 514.7ms\n",
      "Speed: 21.9ms preprocess, 514.7ms inference, 8.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 2 trucks, 372.5ms\n",
      "Speed: 18.8ms preprocess, 372.5ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 bicycle, 2 trucks, 366.4ms\n",
      "Speed: 16.6ms preprocess, 366.4ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 bicycle, 1 bus, 1 train, 2 trucks, 561.5ms\n",
      "Speed: 16.1ms preprocess, 561.5ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 bicycle, 1 bus, 1 truck, 623.5ms\n",
      "Speed: 36.9ms preprocess, 623.5ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 1 motorcycle, 2 trucks, 485.0ms\n",
      "Speed: 20.6ms preprocess, 485.0ms inference, 34.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 1 car, 1 motorcycle, 1 bus, 1 truck, 554.4ms\n",
      "Speed: 24.0ms preprocess, 554.4ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 1 motorcycle, 2 buss, 2 trucks, 609.6ms\n",
      "Speed: 24.0ms preprocess, 609.6ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 1 car, 1 bus, 1 truck, 439.6ms\n",
      "Speed: 12.4ms preprocess, 439.6ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 1 car, 1 motorcycle, 2 buss, 1 train, 416.2ms\n",
      "Speed: 15.6ms preprocess, 416.2ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 bicycle, 2 cars, 2 buss, 2 trucks, 351.6ms\n",
      "Speed: 12.0ms preprocess, 351.6ms inference, 8.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 1 car, 1 motorcycle, 1 bus, 2 trucks, 355.1ms\n",
      "Speed: 12.9ms preprocess, 355.1ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 2 cars, 1 bus, 2 trucks, 490.6ms\n",
      "Speed: 10.9ms preprocess, 490.6ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 2 trucks, 417.5ms\n",
      "Speed: 10.2ms preprocess, 417.5ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 2 trucks, 400.3ms\n",
      "Speed: 23.4ms preprocess, 400.3ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 2 cars, 2 trucks, 368.2ms\n",
      "Speed: 8.5ms preprocess, 368.2ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bus, 2 trucks, 343.1ms\n",
      "Speed: 11.2ms preprocess, 343.1ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bus, 2 trucks, 424.3ms\n",
      "Speed: 14.2ms preprocess, 424.3ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 2 trucks, 550.5ms\n",
      "Speed: 9.2ms preprocess, 550.5ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 2 trucks, 453.2ms\n",
      "Speed: 10.9ms preprocess, 453.2ms inference, 7.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bus, 1 truck, 389.6ms\n",
      "Speed: 14.5ms preprocess, 389.6ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 2 buss, 1 truck, 341.0ms\n",
      "Speed: 12.8ms preprocess, 341.0ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 motorcycle, 1 bus, 1 truck, 340.4ms\n",
      "Speed: 12.4ms preprocess, 340.4ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 motorcycle, 1 bus, 1 train, 1 truck, 681.0ms\n",
      "Speed: 18.9ms preprocess, 681.0ms inference, 14.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 1 bus, 1 truck, 1206.9ms\n",
      "Speed: 18.2ms preprocess, 1206.9ms inference, 18.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 train, 1 truck, 811.8ms\n",
      "Speed: 55.1ms preprocess, 811.8ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 motorcycle, 1 train, 1 truck, 508.4ms\n",
      "Speed: 35.4ms preprocess, 508.4ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 motorcycle, 1 train, 1 truck, 667.6ms\n",
      "Speed: 13.2ms preprocess, 667.6ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 1 motorcycle, 1 train, 1 truck, 1267.8ms\n",
      "Speed: 28.9ms preprocess, 1267.8ms inference, 10.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 1 motorcycle, 1 train, 1 truck, 566.2ms\n",
      "Speed: 18.2ms preprocess, 566.2ms inference, 10.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 1 motorcycle, 1 train, 1 truck, 560.0ms\n",
      "Speed: 16.5ms preprocess, 560.0ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 car, 1 motorcycle, 1 train, 1 truck, 475.8ms\n",
      "Speed: 11.1ms preprocess, 475.8ms inference, 8.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 car, 1 motorcycle, 1 train, 1 truck, 1554.0ms\n",
      "Speed: 21.7ms preprocess, 1554.0ms inference, 7.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 car, 1 motorcycle, 1 truck, 468.3ms\n",
      "Speed: 25.2ms preprocess, 468.3ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 motorcycle, 1 truck, 710.6ms\n",
      "Speed: 17.2ms preprocess, 710.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 1 motorcycle, 2 trucks, 484.9ms\n",
      "Speed: 26.8ms preprocess, 484.9ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 1 motorcycle, 1 truck, 444.9ms\n",
      "Speed: 11.7ms preprocess, 444.9ms inference, 13.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 car, 1 motorcycle, 1 truck, 391.2ms\n",
      "Speed: 10.0ms preprocess, 391.2ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 motorcycle, 1 truck, 484.1ms\n",
      "Speed: 10.8ms preprocess, 484.1ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 cars, 1 motorcycle, 2 trucks, 414.6ms\n",
      "Speed: 16.8ms preprocess, 414.6ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 1 motorcycle, 1 bus, 1 truck, 403.4ms\n",
      "Speed: 10.5ms preprocess, 403.4ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 1 motorcycle, 1 truck, 432.6ms\n",
      "Speed: 14.0ms preprocess, 432.6ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 motorcycle, 1 truck, 529.1ms\n",
      "Speed: 12.4ms preprocess, 529.1ms inference, 18.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 cars, 1 motorcycle, 1 truck, 812.1ms\n",
      "Speed: 49.2ms preprocess, 812.1ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 1 motorcycle, 1 truck, 917.3ms\n",
      "Speed: 8.6ms preprocess, 917.3ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 cars, 1 motorcycle, 1 truck, 336.5ms\n",
      "Speed: 58.7ms preprocess, 336.5ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 1 motorcycle, 1 truck, 950.5ms\n",
      "Speed: 7.1ms preprocess, 950.5ms inference, 8.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 cars, 1 motorcycle, 1 truck, 764.6ms\n",
      "Speed: 24.1ms preprocess, 764.6ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 cars, 1 motorcycle, 1 truck, 353.8ms\n",
      "Speed: 21.2ms preprocess, 353.8ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 3 cars, 1 motorcycle, 2 trucks, 317.8ms\n",
      "Speed: 9.0ms preprocess, 317.8ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 cars, 1 motorcycle, 3 trucks, 419.9ms\n",
      "Speed: 37.0ms preprocess, 419.9ms inference, 8.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 cars, 2 motorcycles, 3 trucks, 413.3ms\n",
      "Speed: 24.1ms preprocess, 413.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 car, 1 motorcycle, 2 trucks, 419.4ms\n",
      "Speed: 10.8ms preprocess, 419.4ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 2 motorcycles, 2 trucks, 536.1ms\n",
      "Speed: 29.8ms preprocess, 536.1ms inference, 11.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 2 motorcycles, 3 trucks, 390.2ms\n",
      "Speed: 12.5ms preprocess, 390.2ms inference, 6.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 motorcycles, 2 trucks, 443.9ms\n",
      "Speed: 9.3ms preprocess, 443.9ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 motorcycle, 3 trucks, 316.2ms\n",
      "Speed: 13.5ms preprocess, 316.2ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 motorcycle, 3 trucks, 386.8ms\n",
      "Speed: 42.5ms preprocess, 386.8ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 motorcycle, 1 bus, 3 trucks, 697.7ms\n",
      "Speed: 11.0ms preprocess, 697.7ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 motorcycle, 1 bus, 3 trucks, 343.3ms\n",
      "Speed: 12.2ms preprocess, 343.3ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bicycle, 2 motorcycles, 3 trucks, 405.7ms\n",
      "Speed: 8.6ms preprocess, 405.7ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 motorcycle, 1 bus, 3 trucks, 675.3ms\n",
      "Speed: 31.4ms preprocess, 675.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 motorcycle, 1 bus, 2 trucks, 386.3ms\n",
      "Speed: 14.3ms preprocess, 386.3ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 motorcycle, 1 bus, 3 trucks, 351.8ms\n",
      "Speed: 14.3ms preprocess, 351.8ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 motorcycles, 3 trucks, 614.0ms\n",
      "Speed: 13.9ms preprocess, 614.0ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 motorcycle, 1 bus, 3 trucks, 552.2ms\n",
      "Speed: 11.7ms preprocess, 552.2ms inference, 7.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 1 motorcycle, 2 trucks, 390.6ms\n",
      "Speed: 8.8ms preprocess, 390.6ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 1 motorcycle, 2 trucks, 433.8ms\n",
      "Speed: 12.7ms preprocess, 433.8ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 motorcycle, 2 trucks, 699.9ms\n",
      "Speed: 19.9ms preprocess, 699.9ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 motorcycle, 2 trucks, 876.0ms\n",
      "Speed: 15.3ms preprocess, 876.0ms inference, 24.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 motorcycle, 2 trucks, 1334.3ms\n",
      "Speed: 126.9ms preprocess, 1334.3ms inference, 58.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 cars, 2 motorcycles, 2 trucks, 1534.3ms\n",
      "Speed: 56.2ms preprocess, 1534.3ms inference, 7.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 cars, 1 motorcycle, 3 trucks, 787.8ms\n",
      "Speed: 20.1ms preprocess, 787.8ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 cars, 1 motorcycle, 3 trucks, 633.5ms\n",
      "Speed: 25.7ms preprocess, 633.5ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 3 cars, 1 motorcycle, 2 trucks, 492.1ms\n",
      "Speed: 15.6ms preprocess, 492.1ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 3 cars, 1 motorcycle, 3 trucks, 931.1ms\n",
      "Speed: 46.9ms preprocess, 931.1ms inference, 16.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 cars, 2 motorcycles, 2 trucks, 591.1ms\n",
      "Speed: 13.8ms preprocess, 591.1ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 motorcycle, 3 trucks, 1631.4ms\n",
      "Speed: 8.7ms preprocess, 1631.4ms inference, 7.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 2 motorcycles, 3 trucks, 569.7ms\n",
      "Speed: 37.6ms preprocess, 569.7ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 motorcycles, 3 trucks, 479.3ms\n",
      "Speed: 16.5ms preprocess, 479.3ms inference, 10.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 motorcycle, 3 trucks, 446.1ms\n",
      "Speed: 12.7ms preprocess, 446.1ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 4 motorcycles, 2 trucks, 474.6ms\n",
      "Speed: 13.0ms preprocess, 474.6ms inference, 10.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 motorcycles, 2 trucks, 649.7ms\n",
      "Speed: 17.8ms preprocess, 649.7ms inference, 8.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 2 motorcycles, 2 trucks, 588.1ms\n",
      "Speed: 27.6ms preprocess, 588.1ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 car, 4 motorcycles, 2 trucks, 1230.4ms\n",
      "Speed: 43.5ms preprocess, 1230.4ms inference, 15.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 car, 3 motorcycles, 2 trucks, 853.0ms\n",
      "Speed: 30.3ms preprocess, 853.0ms inference, 12.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 car, 3 motorcycles, 2 trucks, 693.6ms\n",
      "Speed: 16.4ms preprocess, 693.6ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 motorcycles, 3 trucks, 498.8ms\n",
      "Speed: 14.7ms preprocess, 498.8ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 2 motorcycles, 3 trucks, 512.6ms\n",
      "Speed: 14.5ms preprocess, 512.6ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 car, 2 motorcycles, 3 trucks, 389.4ms\n",
      "Speed: 19.1ms preprocess, 389.4ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 motorcycles, 3 trucks, 437.1ms\n",
      "Speed: 16.6ms preprocess, 437.1ms inference, 8.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 2 motorcycles, 2 trucks, 500.3ms\n",
      "Speed: 8.7ms preprocess, 500.3ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 2 motorcycles, 2 trucks, 381.7ms\n",
      "Speed: 13.9ms preprocess, 381.7ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 motorcycles, 2 trucks, 333.9ms\n",
      "Speed: 14.0ms preprocess, 333.9ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 motorcycles, 3 trucks, 448.1ms\n",
      "Speed: 21.6ms preprocess, 448.1ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 car, 2 motorcycles, 3 trucks, 575.9ms\n",
      "Speed: 16.1ms preprocess, 575.9ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 motorcycles, 3 trucks, 868.1ms\n",
      "Speed: 17.2ms preprocess, 868.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 motorcycles, 3 trucks, 426.0ms\n",
      "Speed: 21.3ms preprocess, 426.0ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 1 motorcycle, 4 trucks, 337.0ms\n",
      "Speed: 14.3ms preprocess, 337.0ms inference, 7.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 2 cars, 1 motorcycle, 4 trucks, 385.4ms\n",
      "Speed: 18.3ms preprocess, 385.4ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 cars, 1 motorcycle, 4 trucks, 614.4ms\n",
      "Speed: 16.2ms preprocess, 614.4ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 2 cars, 2 motorcycles, 5 trucks, 553.0ms\n",
      "Speed: 12.6ms preprocess, 553.0ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 2 cars, 2 motorcycles, 5 trucks, 539.2ms\n",
      "Speed: 30.3ms preprocess, 539.2ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 2 motorcycles, 4 trucks, 544.9ms\n",
      "Speed: 10.3ms preprocess, 544.9ms inference, 11.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 2 motorcycles, 4 trucks, 498.7ms\n",
      "Speed: 16.4ms preprocess, 498.7ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 2 motorcycles, 6 trucks, 515.8ms\n",
      "Speed: 22.8ms preprocess, 515.8ms inference, 11.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 2 motorcycles, 5 trucks, 527.9ms\n",
      "Speed: 27.0ms preprocess, 527.9ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 2 motorcycles, 5 trucks, 576.0ms\n",
      "Speed: 13.2ms preprocess, 576.0ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 2 motorcycles, 4 trucks, 468.2ms\n",
      "Speed: 17.8ms preprocess, 468.2ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 3 motorcycles, 5 trucks, 391.4ms\n",
      "Speed: 24.3ms preprocess, 391.4ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 cars, 2 motorcycles, 4 trucks, 384.0ms\n",
      "Speed: 15.6ms preprocess, 384.0ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 cars, 2 motorcycles, 4 trucks, 339.8ms\n",
      "Speed: 12.9ms preprocess, 339.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 3 motorcycles, 4 trucks, 385.7ms\n",
      "Speed: 17.5ms preprocess, 385.7ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 car, 2 motorcycles, 3 trucks, 464.1ms\n",
      "Speed: 25.5ms preprocess, 464.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 2 motorcycles, 3 trucks, 724.6ms\n",
      "Speed: 15.0ms preprocess, 724.6ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 2 motorcycles, 3 trucks, 453.0ms\n",
      "Speed: 9.5ms preprocess, 453.0ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 2 motorcycles, 3 trucks, 390.4ms\n",
      "Speed: 13.1ms preprocess, 390.4ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 motorcycles, 3 trucks, 314.1ms\n",
      "Speed: 10.5ms preprocess, 314.1ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 motorcycles, 4 trucks, 426.7ms\n",
      "Speed: 19.1ms preprocess, 426.7ms inference, 7.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 2 motorcycles, 4 trucks, 417.8ms\n",
      "Speed: 13.9ms preprocess, 417.8ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 car, 2 motorcycles, 2 trucks, 428.0ms\n",
      "Speed: 16.0ms preprocess, 428.0ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 car, 2 motorcycles, 3 trucks, 394.6ms\n",
      "Speed: 15.6ms preprocess, 394.6ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 bicycle, 2 cars, 2 motorcycles, 3 trucks, 407.3ms\n",
      "Speed: 22.9ms preprocess, 407.3ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 4 motorcycles, 3 trucks, 451.1ms\n",
      "Speed: 9.1ms preprocess, 451.1ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 bicycle, 2 cars, 3 motorcycles, 1 bus, 3 trucks, 391.9ms\n",
      "Speed: 15.3ms preprocess, 391.9ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 cars, 2 motorcycles, 1 bus, 2 trucks, 356.4ms\n",
      "Speed: 11.9ms preprocess, 356.4ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 cars, 3 motorcycles, 1 bus, 2 trucks, 368.7ms\n",
      "Speed: 11.4ms preprocess, 368.7ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 3 cars, 2 motorcycles, 1 bus, 2 trucks, 319.5ms\n",
      "Speed: 14.8ms preprocess, 319.5ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 3 cars, 3 motorcycles, 1 bus, 4 trucks, 495.1ms\n",
      "Speed: 16.6ms preprocess, 495.1ms inference, 10.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 cars, 3 motorcycles, 3 trucks, 529.8ms\n",
      "Speed: 57.4ms preprocess, 529.8ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 cars, 3 motorcycles, 1 bus, 3 trucks, 373.4ms\n",
      "Speed: 11.8ms preprocess, 373.4ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 cars, 4 motorcycles, 2 buss, 4 trucks, 369.9ms\n",
      "Speed: 20.0ms preprocess, 369.9ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 3 cars, 3 motorcycles, 3 trucks, 383.7ms\n",
      "Speed: 14.0ms preprocess, 383.7ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 cars, 3 motorcycles, 1 bus, 2 trucks, 374.6ms\n",
      "Speed: 12.1ms preprocess, 374.6ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 4 motorcycles, 2 trucks, 338.9ms\n",
      "Speed: 10.2ms preprocess, 338.9ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 2 motorcycles, 2 buss, 3 trucks, 361.2ms\n",
      "Speed: 14.3ms preprocess, 361.2ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 2 cars, 1 motorcycle, 2 buss, 2 trucks, 241.5ms\n",
      "Speed: 10.6ms preprocess, 241.5ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 3 cars, 1 motorcycle, 1 bus, 2 trucks, 270.8ms\n",
      "Speed: 9.0ms preprocess, 270.8ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 cars, 2 motorcycles, 1 bus, 2 trucks, 262.0ms\n",
      "Speed: 7.8ms preprocess, 262.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 3 cars, 1 bus, 2 trucks, 369.0ms\n",
      "Speed: 13.3ms preprocess, 369.0ms inference, 7.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 cars, 1 motorcycle, 2 buss, 2 trucks, 547.7ms\n",
      "Speed: 11.9ms preprocess, 547.7ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 bus, 2 trucks, 505.9ms\n",
      "Speed: 11.8ms preprocess, 505.9ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 2 cars, 2 buss, 2 trucks, 414.8ms\n",
      "Speed: 15.4ms preprocess, 414.8ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 4 cars, 2 buss, 2 trucks, 455.3ms\n",
      "Speed: 14.6ms preprocess, 455.3ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 2 cars, 2 trucks, 403.0ms\n",
      "Speed: 9.9ms preprocess, 403.0ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 2 cars, 2 buss, 3 trucks, 345.7ms\n",
      "Speed: 10.2ms preprocess, 345.7ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3 cars, 2 trucks, 1 handbag, 330.9ms\n",
      "Speed: 13.4ms preprocess, 330.9ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 car, 3 trucks, 374.2ms\n",
      "Speed: 8.0ms preprocess, 374.2ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 1 train, 4 trucks, 579.3ms\n",
      "Speed: 39.3ms preprocess, 579.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 1 bus, 1 train, 3 trucks, 331.9ms\n",
      "Speed: 21.1ms preprocess, 331.9ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 2 cars, 3 trucks, 391.3ms\n",
      "Speed: 17.9ms preprocess, 391.3ms inference, 11.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 cars, 1 train, 4 trucks, 779.0ms\n",
      "Speed: 21.1ms preprocess, 779.0ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 cars, 1 train, 3 trucks, 522.2ms\n",
      "Speed: 29.4ms preprocess, 522.2ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 cars, 3 trucks, 573.6ms\n",
      "Speed: 15.7ms preprocess, 573.6ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 1 train, 3 trucks, 350.7ms\n",
      "Speed: 14.8ms preprocess, 350.7ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 1 train, 2 trucks, 316.0ms\n",
      "Speed: 9.8ms preprocess, 316.0ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 train, 3 trucks, 379.6ms\n",
      "Speed: 18.1ms preprocess, 379.6ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 car, 3 trucks, 562.8ms\n",
      "Speed: 14.3ms preprocess, 562.8ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 3 trucks, 376.5ms\n",
      "Speed: 19.0ms preprocess, 376.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 bicycle, 2 trucks, 604.4ms\n",
      "Speed: 11.6ms preprocess, 604.4ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 bicycle, 1 car, 2 trucks, 646.6ms\n",
      "Speed: 10.3ms preprocess, 646.6ms inference, 8.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 trucks, 649.8ms\n",
      "Speed: 18.2ms preprocess, 649.8ms inference, 8.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 2 trucks, 631.9ms\n",
      "Speed: 28.1ms preprocess, 631.9ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 2 trucks, 482.3ms\n",
      "Speed: 21.4ms preprocess, 482.3ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 bicycle, 2 trucks, 452.4ms\n",
      "Speed: 24.9ms preprocess, 452.4ms inference, 10.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 car, 2 trucks, 387.2ms\n",
      "Speed: 22.8ms preprocess, 387.2ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 1 truck, 535.8ms\n",
      "Speed: 17.3ms preprocess, 535.8ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 1 motorcycle, 1 truck, 359.1ms\n",
      "Speed: 19.0ms preprocess, 359.1ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 1 motorcycle, 2 trucks, 317.9ms\n",
      "Speed: 15.1ms preprocess, 317.9ms inference, 7.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 1 motorcycle, 1 truck, 408.4ms\n",
      "Speed: 11.8ms preprocess, 408.4ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 car, 1 motorcycle, 1 truck, 465.9ms\n",
      "Speed: 14.4ms preprocess, 465.9ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 cars, 1 motorcycle, 1 truck, 534.3ms\n",
      "Speed: 15.1ms preprocess, 534.3ms inference, 6.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 car, 1 motorcycle, 1 truck, 661.9ms\n",
      "Speed: 20.9ms preprocess, 661.9ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 motorcycle, 1 truck, 351.1ms\n",
      "Speed: 17.4ms preprocess, 351.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 motorcycle, 1 truck, 367.8ms\n",
      "Speed: 9.7ms preprocess, 367.8ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 car, 1 motorcycle, 2 trucks, 329.6ms\n",
      "Speed: 17.8ms preprocess, 329.6ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 motorcycle, 2 trucks, 370.0ms\n",
      "Speed: 17.8ms preprocess, 370.0ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 1 motorcycle, 2 trucks, 416.8ms\n",
      "Speed: 22.5ms preprocess, 416.8ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 car, 1 motorcycle, 3 trucks, 334.0ms\n",
      "Speed: 12.0ms preprocess, 334.0ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 motorcycle, 3 trucks, 598.4ms\n",
      "Speed: 29.2ms preprocess, 598.4ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 car, 1 motorcycle, 3 trucks, 429.8ms\n",
      "Speed: 20.6ms preprocess, 429.8ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 motorcycle, 3 trucks, 417.9ms\n",
      "Speed: 14.6ms preprocess, 417.9ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 motorcycle, 3 trucks, 470.5ms\n",
      "Speed: 7.6ms preprocess, 470.5ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 2 motorcycles, 3 trucks, 415.0ms\n",
      "Speed: 20.1ms preprocess, 415.0ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 motorcycles, 3 trucks, 418.9ms\n",
      "Speed: 9.9ms preprocess, 418.9ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 2 motorcycles, 3 trucks, 279.1ms\n",
      "Speed: 7.6ms preprocess, 279.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 motorcycles, 3 trucks, 336.3ms\n",
      "Speed: 12.3ms preprocess, 336.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 motorcycles, 3 trucks, 354.8ms\n",
      "Speed: 13.7ms preprocess, 354.8ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 motorcycles, 3 trucks, 353.1ms\n",
      "Speed: 19.7ms preprocess, 353.1ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 3 motorcycles, 3 trucks, 462.0ms\n",
      "Speed: 11.8ms preprocess, 462.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 4 motorcycles, 3 trucks, 389.7ms\n",
      "Speed: 15.3ms preprocess, 389.7ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 4 motorcycles, 2 trucks, 360.6ms\n",
      "Speed: 19.1ms preprocess, 360.6ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 4 motorcycles, 2 trucks, 277.4ms\n",
      "Speed: 13.2ms preprocess, 277.4ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 4 motorcycles, 2 trucks, 330.9ms\n",
      "Speed: 12.5ms preprocess, 330.9ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 3 motorcycles, 2 trucks, 324.5ms\n",
      "Speed: 10.3ms preprocess, 324.5ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 4 motorcycles, 2 trucks, 308.7ms\n",
      "Speed: 10.7ms preprocess, 308.7ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 3 motorcycles, 1 train, 1 truck, 399.7ms\n",
      "Speed: 17.3ms preprocess, 399.7ms inference, 10.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 3 motorcycles, 1 train, 1 truck, 367.0ms\n",
      "Speed: 19.9ms preprocess, 367.0ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 3 motorcycles, 1 train, 1 truck, 372.9ms\n",
      "Speed: 17.1ms preprocess, 372.9ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 4 motorcycles, 1 truck, 435.5ms\n",
      "Speed: 12.3ms preprocess, 435.5ms inference, 27.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 cars, 3 motorcycles, 2 trucks, 395.5ms\n",
      "Speed: 8.4ms preprocess, 395.5ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 2 cars, 3 motorcycles, 2 trucks, 351.3ms\n",
      "Speed: 12.1ms preprocess, 351.3ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 car, 3 motorcycles, 2 trucks, 365.2ms\n",
      "Speed: 16.6ms preprocess, 365.2ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 3 motorcycles, 2 trucks, 481.4ms\n",
      "Speed: 38.5ms preprocess, 481.4ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 3 cars, 3 motorcycles, 2 trucks, 587.5ms\n",
      "Speed: 13.2ms preprocess, 587.5ms inference, 15.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 cars, 3 motorcycles, 1 truck, 652.3ms\n",
      "Speed: 18.9ms preprocess, 652.3ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 3 motorcycles, 1 truck, 624.6ms\n",
      "Speed: 16.5ms preprocess, 624.6ms inference, 24.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 3 motorcycles, 1 truck, 464.3ms\n",
      "Speed: 60.4ms preprocess, 464.3ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 3 motorcycles, 1 truck, 547.6ms\n",
      "Speed: 17.2ms preprocess, 547.6ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 car, 3 motorcycles, 1 bus, 1 truck, 808.1ms\n",
      "Speed: 20.3ms preprocess, 808.1ms inference, 11.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 cars, 3 motorcycles, 2 trucks, 388.3ms\n",
      "Speed: 14.4ms preprocess, 388.3ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 4 cars, 3 motorcycles, 2 trucks, 427.9ms\n",
      "Speed: 17.6ms preprocess, 427.9ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 cars, 3 motorcycles, 2 trucks, 360.1ms\n",
      "Speed: 20.4ms preprocess, 360.1ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 cars, 3 motorcycles, 2 trucks, 352.5ms\n",
      "Speed: 8.2ms preprocess, 352.5ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 cars, 3 motorcycles, 1 bus, 1 truck, 710.2ms\n",
      "Speed: 15.9ms preprocess, 710.2ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 cars, 4 motorcycles, 2 trucks, 590.9ms\n",
      "Speed: 18.3ms preprocess, 590.9ms inference, 16.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 2 cars, 4 motorcycles, 2 trucks, 1280.7ms\n",
      "Speed: 18.5ms preprocess, 1280.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 cars, 3 motorcycles, 2 trucks, 503.8ms\n",
      "Speed: 18.3ms preprocess, 503.8ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 cars, 3 motorcycles, 2 trucks, 537.7ms\n",
      "Speed: 27.8ms preprocess, 537.7ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 cars, 3 motorcycles, 2 trucks, 384.4ms\n",
      "Speed: 19.6ms preprocess, 384.4ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 3 cars, 3 motorcycles, 2 trucks, 464.9ms\n",
      "Speed: 16.4ms preprocess, 464.9ms inference, 13.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 3 cars, 3 motorcycles, 3 trucks, 521.3ms\n",
      "Speed: 17.1ms preprocess, 521.3ms inference, 6.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 3 cars, 3 motorcycles, 3 trucks, 1047.1ms\n",
      "Speed: 16.9ms preprocess, 1047.1ms inference, 9.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 3 cars, 3 motorcycles, 3 trucks, 985.0ms\n",
      "Speed: 58.2ms preprocess, 985.0ms inference, 9.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 cars, 4 motorcycles, 3 trucks, 665.0ms\n",
      "Speed: 32.3ms preprocess, 665.0ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 4 motorcycles, 3 trucks, 653.3ms\n",
      "Speed: 27.1ms preprocess, 653.3ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 cars, 3 motorcycles, 3 trucks, 976.5ms\n",
      "Speed: 13.4ms preprocess, 976.5ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 3 cars, 2 motorcycles, 3 trucks, 423.9ms\n",
      "Speed: 13.8ms preprocess, 423.9ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 4 cars, 2 motorcycles, 2 trucks, 555.2ms\n",
      "Speed: 16.0ms preprocess, 555.2ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 3 cars, 3 motorcycles, 2 trucks, 782.9ms\n",
      "Speed: 19.7ms preprocess, 782.9ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 3 cars, 2 motorcycles, 3 trucks, 821.4ms\n",
      "Speed: 15.0ms preprocess, 821.4ms inference, 11.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 3 cars, 2 motorcycles, 3 trucks, 1413.3ms\n",
      "Speed: 12.7ms preprocess, 1413.3ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 3 cars, 3 motorcycles, 2 trucks, 583.4ms\n",
      "Speed: 13.0ms preprocess, 583.4ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 cars, 2 motorcycles, 3 trucks, 377.1ms\n",
      "Speed: 13.3ms preprocess, 377.1ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 3 cars, 4 motorcycles, 2 trucks, 521.4ms\n",
      "Speed: 35.4ms preprocess, 521.4ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 3 cars, 3 motorcycles, 2 trucks, 560.4ms\n",
      "Speed: 14.8ms preprocess, 560.4ms inference, 22.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 3 cars, 5 motorcycles, 2 trucks, 443.4ms\n",
      "Speed: 19.4ms preprocess, 443.4ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 4 cars, 3 motorcycles, 2 trucks, 396.4ms\n",
      "Speed: 10.0ms preprocess, 396.4ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 4 cars, 3 motorcycles, 1 truck, 358.8ms\n",
      "Speed: 12.8ms preprocess, 358.8ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 4 cars, 3 motorcycles, 1 truck, 783.6ms\n",
      "Speed: 17.6ms preprocess, 783.6ms inference, 7.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 4 cars, 4 motorcycles, 1 truck, 576.1ms\n",
      "Speed: 12.4ms preprocess, 576.1ms inference, 14.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 cars, 4 motorcycles, 1 truck, 782.9ms\n",
      "Speed: 63.0ms preprocess, 782.9ms inference, 14.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 cars, 4 motorcycles, 1 truck, 469.5ms\n",
      "Speed: 15.7ms preprocess, 469.5ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 cars, 4 motorcycles, 1 truck, 337.5ms\n",
      "Speed: 8.7ms preprocess, 337.5ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 cars, 3 motorcycles, 1 truck, 582.0ms\n",
      "Speed: 36.7ms preprocess, 582.0ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 cars, 4 motorcycles, 1 truck, 732.8ms\n",
      "Speed: 13.3ms preprocess, 732.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 3 cars, 3 motorcycles, 1 truck, 397.4ms\n",
      "Speed: 20.0ms preprocess, 397.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 cars, 3 motorcycles, 1 truck, 363.0ms\n",
      "Speed: 17.4ms preprocess, 363.0ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 3 cars, 3 motorcycles, 1 truck, 1026.8ms\n",
      "Speed: 9.7ms preprocess, 1026.8ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 car, 2 motorcycles, 1 truck, 812.9ms\n",
      "Speed: 56.9ms preprocess, 812.9ms inference, 8.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 car, 2 motorcycles, 1 truck, 564.1ms\n",
      "Speed: 23.6ms preprocess, 564.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 2 motorcycles, 1 truck, 336.5ms\n",
      "Speed: 44.4ms preprocess, 336.5ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 2 motorcycles, 1 truck, 373.7ms\n",
      "Speed: 14.4ms preprocess, 373.7ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 car, 2 motorcycles, 2 trucks, 504.2ms\n",
      "Speed: 23.7ms preprocess, 504.2ms inference, 12.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 2 motorcycles, 1 truck, 703.2ms\n",
      "Speed: 17.4ms preprocess, 703.2ms inference, 7.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 2 motorcycles, 1 truck, 499.6ms\n",
      "Speed: 15.5ms preprocess, 499.6ms inference, 7.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 cars, 2 motorcycles, 1 truck, 897.6ms\n",
      "Speed: 20.7ms preprocess, 897.6ms inference, 8.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 2 motorcycles, 1 truck, 1223.4ms\n",
      "Speed: 21.8ms preprocess, 1223.4ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 cars, 2 motorcycles, 1 truck, 657.3ms\n",
      "Speed: 22.2ms preprocess, 657.3ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 cars, 2 motorcycles, 1 truck, 573.2ms\n",
      "Speed: 10.9ms preprocess, 573.2ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 car, 3 motorcycles, 2 trucks, 433.7ms\n",
      "Speed: 9.4ms preprocess, 433.7ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 car, 3 motorcycles, 2 trucks, 616.8ms\n",
      "Speed: 61.6ms preprocess, 616.8ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 3 motorcycles, 2 trucks, 406.1ms\n",
      "Speed: 10.4ms preprocess, 406.1ms inference, 7.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 4 motorcycles, 2 trucks, 582.0ms\n",
      "Speed: 7.5ms preprocess, 582.0ms inference, 18.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 car, 3 motorcycles, 1 truck, 762.0ms\n",
      "Speed: 10.1ms preprocess, 762.0ms inference, 8.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 3 motorcycles, 1 truck, 754.8ms\n",
      "Speed: 21.2ms preprocess, 754.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 3 motorcycles, 1 truck, 569.7ms\n",
      "Speed: 9.7ms preprocess, 569.7ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 car, 3 motorcycles, 1 truck, 362.0ms\n",
      "Speed: 27.3ms preprocess, 362.0ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 car, 4 motorcycles, 1 truck, 1139.5ms\n",
      "Speed: 24.3ms preprocess, 1139.5ms inference, 11.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 car, 3 motorcycles, 1 truck, 426.4ms\n",
      "Speed: 31.0ms preprocess, 426.4ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 4 motorcycles, 1 truck, 380.3ms\n",
      "Speed: 14.3ms preprocess, 380.3ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 2 motorcycles, 1 truck, 468.5ms\n",
      "Speed: 18.0ms preprocess, 468.5ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 3 motorcycles, 1 truck, 760.5ms\n",
      "Speed: 13.4ms preprocess, 760.5ms inference, 6.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 3 motorcycles, 2 trucks, 751.1ms\n",
      "Speed: 22.0ms preprocess, 751.1ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 3 motorcycles, 555.2ms\n",
      "Speed: 17.1ms preprocess, 555.2ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 4 motorcycles, 2 trucks, 568.2ms\n",
      "Speed: 36.6ms preprocess, 568.2ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 3 motorcycles, 1 truck, 393.6ms\n",
      "Speed: 15.3ms preprocess, 393.6ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 car, 3 motorcycles, 1 truck, 388.3ms\n",
      "Speed: 10.8ms preprocess, 388.3ms inference, 9.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 cars, 3 motorcycles, 1 truck, 614.7ms\n",
      "Speed: 10.1ms preprocess, 614.7ms inference, 8.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 cars, 3 motorcycles, 1 truck, 487.1ms\n",
      "Speed: 19.8ms preprocess, 487.1ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 3 motorcycles, 1 truck, 376.8ms\n",
      "Speed: 13.1ms preprocess, 376.8ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 3 motorcycles, 1 truck, 561.3ms\n",
      "Speed: 21.6ms preprocess, 561.3ms inference, 10.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 3 motorcycles, 1 truck, 613.5ms\n",
      "Speed: 24.3ms preprocess, 613.5ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 4 motorcycles, 1 truck, 577.5ms\n",
      "Speed: 22.8ms preprocess, 577.5ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 car, 2 motorcycles, 1 truck, 364.4ms\n",
      "Speed: 13.4ms preprocess, 364.4ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 4 motorcycles, 409.3ms\n",
      "Speed: 8.8ms preprocess, 409.3ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 5 motorcycles, 1 truck, 421.2ms\n",
      "Speed: 15.0ms preprocess, 421.2ms inference, 12.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 3 motorcycles, 577.7ms\n",
      "Speed: 18.2ms preprocess, 577.7ms inference, 8.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 3 motorcycles, 637.7ms\n",
      "Speed: 23.2ms preprocess, 637.7ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 4 motorcycles, 547.7ms\n",
      "Speed: 10.0ms preprocess, 547.7ms inference, 8.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 3 motorcycles, 701.1ms\n",
      "Speed: 27.7ms preprocess, 701.1ms inference, 7.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 car, 4 motorcycles, 608.6ms\n",
      "Speed: 27.4ms preprocess, 608.6ms inference, 7.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 car, 3 motorcycles, 834.9ms\n",
      "Speed: 10.3ms preprocess, 834.9ms inference, 8.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 3 motorcycles, 359.4ms\n",
      "Speed: 15.8ms preprocess, 359.4ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 car, 3 motorcycles, 1 truck, 327.9ms\n",
      "Speed: 9.8ms preprocess, 327.9ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 cars, 3 motorcycles, 1 truck, 343.2ms\n",
      "Speed: 12.6ms preprocess, 343.2ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 3 motorcycles, 515.7ms\n",
      "Speed: 15.5ms preprocess, 515.7ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 3 motorcycles, 1 truck, 866.6ms\n",
      "Speed: 26.9ms preprocess, 866.6ms inference, 8.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 2 motorcycles, 1 truck, 946.7ms\n",
      "Speed: 15.8ms preprocess, 946.7ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 cars, 2 motorcycles, 1 truck, 1031.0ms\n",
      "Speed: 32.9ms preprocess, 1031.0ms inference, 33.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 3 cars, 2 motorcycles, 731.0ms\n",
      "Speed: 26.3ms preprocess, 731.0ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 3 cars, 2 motorcycles, 495.1ms\n",
      "Speed: 14.1ms preprocess, 495.1ms inference, 6.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 3 cars, 2 motorcycles, 455.1ms\n",
      "Speed: 14.5ms preprocess, 455.1ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 3 cars, 2 motorcycles, 475.5ms\n",
      "Speed: 22.3ms preprocess, 475.5ms inference, 11.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 motorcycles, 1 truck, 732.4ms\n",
      "Speed: 22.7ms preprocess, 732.4ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 2 motorcycles, 1 truck, 563.2ms\n",
      "Speed: 20.3ms preprocess, 563.2ms inference, 11.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 cars, 2 motorcycles, 1 bus, 1 truck, 1901.1ms\n",
      "Speed: 21.3ms preprocess, 1901.1ms inference, 41.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 cars, 2 motorcycles, 1 truck, 816.0ms\n",
      "Speed: 25.6ms preprocess, 816.0ms inference, 9.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 cars, 2 motorcycles, 1 truck, 1182.0ms\n",
      "Speed: 36.1ms preprocess, 1182.0ms inference, 15.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 cars, 2 motorcycles, 1237.6ms\n",
      "Speed: 14.8ms preprocess, 1237.6ms inference, 13.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 cars, 2 motorcycles, 988.1ms\n",
      "Speed: 29.4ms preprocess, 988.1ms inference, 8.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 3 cars, 2 motorcycles, 532.7ms\n",
      "Speed: 17.3ms preprocess, 532.7ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 3 cars, 2 motorcycles, 458.9ms\n",
      "Speed: 8.4ms preprocess, 458.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 cars, 2 motorcycles, 1227.8ms\n",
      "Speed: 8.6ms preprocess, 1227.8ms inference, 18.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 3 cars, 1 motorcycle, 1410.3ms\n",
      "Speed: 66.5ms preprocess, 1410.3ms inference, 9.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 4 cars, 2 motorcycles, 682.1ms\n",
      "Speed: 13.0ms preprocess, 682.1ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 3 cars, 2 motorcycles, 549.4ms\n",
      "Speed: 24.1ms preprocess, 549.4ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 3 cars, 2 motorcycles, 828.7ms\n",
      "Speed: 14.8ms preprocess, 828.7ms inference, 11.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 3 cars, 2 motorcycles, 440.6ms\n",
      "Speed: 44.3ms preprocess, 440.6ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 3 cars, 2 motorcycles, 562.7ms\n",
      "Speed: 20.5ms preprocess, 562.7ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 cars, 2 motorcycles, 500.5ms\n",
      "Speed: 15.8ms preprocess, 500.5ms inference, 9.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 cars, 2 motorcycles, 597.0ms\n",
      "Speed: 10.5ms preprocess, 597.0ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 cars, 2 motorcycles, 829.4ms\n",
      "Speed: 8.9ms preprocess, 829.4ms inference, 17.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 cars, 2 motorcycles, 302.8ms\n",
      "Speed: 7.1ms preprocess, 302.8ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 cars, 2 motorcycles, 292.8ms\n",
      "Speed: 7.5ms preprocess, 292.8ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 3 cars, 2 motorcycles, 1 truck, 365.7ms\n",
      "Speed: 9.6ms preprocess, 365.7ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 3 cars, 2 motorcycles, 2 trucks, 338.3ms\n",
      "Speed: 10.8ms preprocess, 338.3ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 cars, 2 motorcycles, 2 trucks, 300.8ms\n",
      "Speed: 6.5ms preprocess, 300.8ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 cars, 2 motorcycles, 2 trucks, 390.9ms\n",
      "Speed: 12.6ms preprocess, 390.9ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 cars, 2 motorcycles, 1 bus, 2 trucks, 493.9ms\n",
      "Speed: 6.4ms preprocess, 493.9ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 3 cars, 2 motorcycles, 1 truck, 413.7ms\n",
      "Speed: 9.7ms preprocess, 413.7ms inference, 10.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 3 cars, 2 motorcycles, 1 truck, 678.6ms\n",
      "Speed: 12.4ms preprocess, 678.6ms inference, 65.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 cars, 2 motorcycles, 1 truck, 843.6ms\n",
      "Speed: 73.6ms preprocess, 843.6ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 2 motorcycles, 1 truck, 323.0ms\n",
      "Speed: 7.2ms preprocess, 323.0ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 cars, 2 motorcycles, 1 truck, 392.9ms\n",
      "Speed: 12.3ms preprocess, 392.9ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 motorcycles, 1 truck, 431.0ms\n",
      "Speed: 9.8ms preprocess, 431.0ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 2 motorcycles, 2 trucks, 357.2ms\n",
      "Speed: 10.9ms preprocess, 357.2ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 2 motorcycles, 2 trucks, 358.6ms\n",
      "Speed: 14.0ms preprocess, 358.6ms inference, 6.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 2 motorcycles, 1 truck, 401.7ms\n",
      "Speed: 7.8ms preprocess, 401.7ms inference, 16.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 2 motorcycles, 2 trucks, 634.8ms\n",
      "Speed: 8.1ms preprocess, 634.8ms inference, 10.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 cars, 2 motorcycles, 2 trucks, 689.7ms\n",
      "Speed: 9.7ms preprocess, 689.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 motorcycles, 1 bus, 1 truck, 453.0ms\n",
      "Speed: 11.4ms preprocess, 453.0ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 motorcycles, 1 bus, 2 trucks, 581.1ms\n",
      "Speed: 10.1ms preprocess, 581.1ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 motorcycles, 3 trucks, 316.4ms\n",
      "Speed: 8.5ms preprocess, 316.4ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 motorcycles, 3 trucks, 345.3ms\n",
      "Speed: 8.7ms preprocess, 345.3ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 motorcycles, 1 bus, 3 trucks, 310.2ms\n",
      "Speed: 7.5ms preprocess, 310.2ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 motorcycles, 3 trucks, 463.7ms\n",
      "Speed: 13.3ms preprocess, 463.7ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 2 motorcycles, 3 trucks, 342.5ms\n",
      "Speed: 16.6ms preprocess, 342.5ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 3 motorcycles, 3 trucks, 329.7ms\n",
      "Speed: 8.5ms preprocess, 329.7ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 car, 2 motorcycles, 354.6ms\n",
      "Speed: 9.7ms preprocess, 354.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 2 cars, 2 motorcycles, 1 truck, 571.3ms\n",
      "Speed: 17.2ms preprocess, 571.3ms inference, 11.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 cars, 2 motorcycles, 1 truck, 772.5ms\n",
      "Speed: 19.3ms preprocess, 772.5ms inference, 11.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 2 cars, 2 motorcycles, 2 trucks, 479.7ms\n",
      "Speed: 11.3ms preprocess, 479.7ms inference, 23.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 3 cars, 3 motorcycles, 1 truck, 437.5ms\n",
      "Speed: 24.0ms preprocess, 437.5ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 2 cars, 5 motorcycles, 770.1ms\n",
      "Speed: 8.0ms preprocess, 770.1ms inference, 66.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 2 cars, 4 motorcycles, 450.2ms\n",
      "Speed: 15.8ms preprocess, 450.2ms inference, 7.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 cars, 3 motorcycles, 2 trucks, 515.4ms\n",
      "Speed: 7.1ms preprocess, 515.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 cars, 4 motorcycles, 2 trucks, 305.8ms\n",
      "Speed: 8.9ms preprocess, 305.8ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 cars, 4 motorcycles, 391.0ms\n",
      "Speed: 9.7ms preprocess, 391.0ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 cars, 4 motorcycles, 1 truck, 419.0ms\n",
      "Speed: 8.7ms preprocess, 419.0ms inference, 10.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 3 motorcycles, 1 truck, 924.2ms\n",
      "Speed: 22.4ms preprocess, 924.2ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 cars, 4 motorcycles, 585.1ms\n",
      "Speed: 36.7ms preprocess, 585.1ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 cars, 2 motorcycles, 378.8ms\n",
      "Speed: 7.8ms preprocess, 378.8ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 3 cars, 2 motorcycles, 331.3ms\n",
      "Speed: 35.3ms preprocess, 331.3ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 3 cars, 3 motorcycles, 405.6ms\n",
      "Speed: 14.9ms preprocess, 405.6ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 5 cars, 3 motorcycles, 465.5ms\n",
      "Speed: 41.2ms preprocess, 465.5ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 6 cars, 6 motorcycles, 446.9ms\n",
      "Speed: 7.3ms preprocess, 446.9ms inference, 7.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 5 cars, 6 motorcycles, 1 truck, 563.1ms\n",
      "Speed: 25.1ms preprocess, 563.1ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 bicycle, 4 cars, 2 motorcycles, 818.3ms\n",
      "Speed: 10.1ms preprocess, 818.3ms inference, 7.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 bicycle, 7 cars, 3 motorcycles, 627.7ms\n",
      "Speed: 12.0ms preprocess, 627.7ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 bicycle, 8 cars, 2 motorcycles, 724.4ms\n",
      "Speed: 14.2ms preprocess, 724.4ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 bicycle, 8 cars, 3 motorcycles, 384.0ms\n",
      "Speed: 7.0ms preprocess, 384.0ms inference, 7.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bicycle, 6 cars, 4 motorcycles, 1 train, 589.8ms\n",
      "Speed: 41.0ms preprocess, 589.8ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 bicycle, 5 cars, 4 motorcycles, 1 train, 614.7ms\n",
      "Speed: 11.6ms preprocess, 614.7ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 bicycle, 5 cars, 4 motorcycles, 1 train, 380.7ms\n",
      "Speed: 10.6ms preprocess, 380.7ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 3 cars, 3 motorcycles, 1 train, 599.1ms\n",
      "Speed: 9.5ms preprocess, 599.1ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 cars, 3 motorcycles, 1 truck, 500.0ms\n",
      "Speed: 8.3ms preprocess, 500.0ms inference, 7.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 bicycle, 2 cars, 3 motorcycles, 1 train, 579.6ms\n",
      "Speed: 29.9ms preprocess, 579.6ms inference, 18.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 5 motorcycles, 657.6ms\n",
      "Speed: 21.6ms preprocess, 657.6ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 4 cars, 5 motorcycles, 1 train, 505.1ms\n",
      "Speed: 13.7ms preprocess, 505.1ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 3 cars, 2 motorcycles, 1 truck, 368.6ms\n",
      "Speed: 7.8ms preprocess, 368.6ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 cars, 3 motorcycles, 1 bus, 362.5ms\n",
      "Speed: 8.8ms preprocess, 362.5ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 3 cars, 4 motorcycles, 1 truck, 351.7ms\n",
      "Speed: 7.9ms preprocess, 351.7ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 3 cars, 4 motorcycles, 1 truck, 684.7ms\n",
      "Speed: 12.8ms preprocess, 684.7ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 4 cars, 6 motorcycles, 1 bus, 1 truck, 453.9ms\n",
      "Speed: 14.5ms preprocess, 453.9ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 cars, 7 motorcycles, 729.2ms\n",
      "Speed: 15.2ms preprocess, 729.2ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 5 cars, 5 motorcycles, 1 bus, 845.6ms\n",
      "Speed: 9.1ms preprocess, 845.6ms inference, 24.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 bicycle, 3 cars, 5 motorcycles, 1 bus, 1680.5ms\n",
      "Speed: 7.9ms preprocess, 1680.5ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 bicycle, 4 cars, 5 motorcycles, 1 bus, 642.7ms\n",
      "Speed: 9.6ms preprocess, 642.7ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 bicycle, 4 cars, 4 motorcycles, 1 truck, 431.9ms\n",
      "Speed: 9.4ms preprocess, 431.9ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 4 cars, 3 motorcycles, 1 bus, 1 truck, 417.0ms\n",
      "Speed: 8.4ms preprocess, 417.0ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 4 cars, 4 motorcycles, 373.4ms\n",
      "Speed: 10.6ms preprocess, 373.4ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bicycle, 5 cars, 5 motorcycles, 1 bus, 2 trucks, 399.7ms\n",
      "Speed: 10.2ms preprocess, 399.7ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 bicycle, 3 cars, 5 motorcycles, 1 bus, 444.5ms\n",
      "Speed: 11.6ms preprocess, 444.5ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 bicycle, 3 cars, 3 motorcycles, 1 bus, 605.7ms\n",
      "Speed: 10.5ms preprocess, 605.7ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 bicycle, 5 cars, 2 motorcycles, 766.2ms\n",
      "Speed: 14.6ms preprocess, 766.2ms inference, 61.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 bicycle, 3 cars, 3 motorcycles, 1020.2ms\n",
      "Speed: 20.6ms preprocess, 1020.2ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 bicycle, 4 cars, 2 motorcycles, 870.6ms\n",
      "Speed: 13.0ms preprocess, 870.6ms inference, 8.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bicycle, 3 cars, 3 motorcycles, 1 truck, 478.8ms\n",
      "Speed: 10.7ms preprocess, 478.8ms inference, 9.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 bicycle, 3 cars, 3 motorcycles, 501.6ms\n",
      "Speed: 8.6ms preprocess, 501.6ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 bicycle, 4 cars, 3 motorcycles, 615.7ms\n",
      "Speed: 9.3ms preprocess, 615.7ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 bicycle, 2 cars, 4 motorcycles, 347.5ms\n",
      "Speed: 10.5ms preprocess, 347.5ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 4 cars, 4 motorcycles, 395.7ms\n",
      "Speed: 20.5ms preprocess, 395.7ms inference, 12.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 4 cars, 3 motorcycles, 451.5ms\n",
      "Speed: 6.6ms preprocess, 451.5ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 5 cars, 3 motorcycles, 1 truck, 508.9ms\n",
      "Speed: 11.1ms preprocess, 508.9ms inference, 10.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 5 cars, 4 motorcycles, 1 truck, 620.4ms\n",
      "Speed: 14.8ms preprocess, 620.4ms inference, 11.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 4 cars, 4 motorcycles, 396.5ms\n",
      "Speed: 7.6ms preprocess, 396.5ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 5 cars, 4 motorcycles, 1 truck, 542.0ms\n",
      "Speed: 7.9ms preprocess, 542.0ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 6 cars, 4 motorcycles, 412.9ms\n",
      "Speed: 7.6ms preprocess, 412.9ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 5 cars, 4 motorcycles, 1 truck, 296.2ms\n",
      "Speed: 6.6ms preprocess, 296.2ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 4 cars, 4 motorcycles, 1 truck, 392.8ms\n",
      "Speed: 8.3ms preprocess, 392.8ms inference, 9.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 4 cars, 4 motorcycles, 1 truck, 562.4ms\n",
      "Speed: 10.2ms preprocess, 562.4ms inference, 10.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 3 cars, 4 motorcycles, 1 truck, 414.5ms\n",
      "Speed: 41.1ms preprocess, 414.5ms inference, 14.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 3 cars, 4 motorcycles, 342.4ms\n",
      "Speed: 11.4ms preprocess, 342.4ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 3 cars, 3 motorcycles, 2 trucks, 519.2ms\n",
      "Speed: 7.8ms preprocess, 519.2ms inference, 11.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 6 cars, 4 motorcycles, 3 buss, 1 truck, 620.5ms\n",
      "Speed: 17.3ms preprocess, 620.5ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 bicycle, 5 cars, 3 motorcycles, 1 bus, 1 truck, 818.5ms\n",
      "Speed: 7.5ms preprocess, 818.5ms inference, 10.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 bicycle, 7 cars, 3 motorcycles, 2 trucks, 951.7ms\n",
      "Speed: 11.6ms preprocess, 951.7ms inference, 7.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 5 cars, 6 motorcycles, 1 truck, 752.1ms\n",
      "Speed: 7.8ms preprocess, 752.1ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 bicycle, 5 cars, 5 motorcycles, 1 bus, 1 truck, 583.4ms\n",
      "Speed: 9.3ms preprocess, 583.4ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 5 cars, 4 motorcycles, 2 buss, 1 truck, 382.8ms\n",
      "Speed: 7.5ms preprocess, 382.8ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 bicycle, 5 cars, 4 motorcycles, 2 buss, 1 truck, 385.7ms\n",
      "Speed: 31.7ms preprocess, 385.7ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 bicycle, 7 cars, 3 motorcycles, 2 buss, 1 truck, 347.0ms\n",
      "Speed: 15.3ms preprocess, 347.0ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 4 cars, 3 motorcycles, 2 buss, 1 truck, 378.7ms\n",
      "Speed: 8.2ms preprocess, 378.7ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 bicycle, 4 cars, 3 motorcycles, 2 buss, 1 truck, 443.8ms\n",
      "Speed: 54.4ms preprocess, 443.8ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 bicycle, 4 cars, 3 motorcycles, 2 buss, 1 truck, 627.7ms\n",
      "Speed: 44.7ms preprocess, 627.7ms inference, 15.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 bicycle, 5 cars, 3 motorcycles, 2 buss, 1 truck, 683.6ms\n",
      "Speed: 12.4ms preprocess, 683.6ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 bicycle, 4 cars, 2 motorcycles, 2 buss, 1 truck, 421.8ms\n",
      "Speed: 8.8ms preprocess, 421.8ms inference, 7.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from collections import deque\n",
    "\n",
    "class TrafficManagementSystem:\n",
    "    def __init__(self, model_path='yolov8n.pt', video_source=0):\n",
    "        \"\"\"\n",
    "        Initialize the Traffic Management System\n",
    "        \n",
    "        Args:\n",
    "            model_path: Path to the YOLOv8 model weights\n",
    "            video_source: Camera ID or video file path\n",
    "        \"\"\"\n",
    "        # Load the YOLOv8 model\n",
    "        self.model = YOLO(model_path)\n",
    "        \n",
    "        # Initialize video capture\n",
    "        self.cap = cv2.VideoCapture(video_source)\n",
    "        if not self.cap.isOpened():\n",
    "            raise ValueError(f\"Could not open video source {video_source}\")\n",
    "            \n",
    "        # Get video properties\n",
    "        self.frame_width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        self.frame_height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        \n",
    "        # Define regions of interest for each lane (adjust these based on camera view)\n",
    "        # Format: [x1, y1, x2, y2] for each lane\n",
    "        self.lanes = {\n",
    "            \"north\": [int(self.frame_width*0.4), 0, int(self.frame_width*0.6), int(self.frame_height*0.3)],\n",
    "            \"south\": [int(self.frame_width*0.4), int(self.frame_height*0.7), int(self.frame_width*0.6), self.frame_height],\n",
    "            \"east\": [int(self.frame_width*0.7), int(self.frame_height*0.4), self.frame_width, int(self.frame_height*0.6)],\n",
    "            \"west\": [0, int(self.frame_height*0.4), int(self.frame_width*0.3), int(self.frame_height*0.6)]\n",
    "        }\n",
    "        \n",
    "        # Traffic signal parameters\n",
    "        self.min_green_time = 10  # seconds\n",
    "        self.max_green_time = 60  # seconds\n",
    "        self.yellow_time = 3  # seconds\n",
    "        \n",
    "        # Current signal state\n",
    "        self.current_signal = \"north\"\n",
    "        self.signal_state = {\n",
    "            \"north\": \"green\",\n",
    "            \"south\": \"red\",\n",
    "            \"east\": \"red\",\n",
    "            \"west\": \"red\"\n",
    "        }\n",
    "        \n",
    "        # Time tracking\n",
    "        self.signal_start_time = time.time()\n",
    "        self.elapsed_time = 0\n",
    "        \n",
    "        # Vehicle count history (for simulation)\n",
    "        self.vehicle_history = {lane: deque(maxlen=50) for lane in self.lanes}\n",
    "        \n",
    "        # Vehicle classes to detect (from COCO dataset)\n",
    "        self.vehicle_classes = [2, 3, 5, 7]  # car, motorcycle, bus, truck\n",
    "        \n",
    "    def detect_vehicles(self, frame):\n",
    "        \"\"\"\n",
    "        Detect vehicles in each lane using YOLOv8\n",
    "        \n",
    "        Args:\n",
    "            frame: Video frame to process\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with vehicle counts for each lane\n",
    "        \"\"\"\n",
    "        results = self.model(frame)\n",
    "        vehicle_counts = {lane: 0 for lane in self.lanes}\n",
    "        \n",
    "        # Process detections\n",
    "        for r in results:\n",
    "            boxes = r.boxes\n",
    "            \n",
    "            for box in boxes:\n",
    "                # Check if detection is a vehicle\n",
    "                cls = int(box.cls[0].item())\n",
    "                if cls in self.vehicle_classes:\n",
    "                    # Get box coordinates\n",
    "                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)\n",
    "                    \n",
    "                    # Check which lane the vehicle belongs to\n",
    "                    for lane, roi in self.lanes.items():\n",
    "                        roi_x1, roi_y1, roi_x2, roi_y2 = roi\n",
    "                        # Check if center of the box is in the lane ROI\n",
    "                        center_x = (x1 + x2) // 2\n",
    "                        center_y = (y1 + y2) // 2\n",
    "                        if (roi_x1 <= center_x <= roi_x2 and roi_y1 <= center_y <= roi_y2):\n",
    "                            vehicle_counts[lane] += 1\n",
    "                            \n",
    "        # Update vehicle history for simulation\n",
    "        for lane, count in vehicle_counts.items():\n",
    "            self.vehicle_history[lane].append(count)\n",
    "                            \n",
    "        return vehicle_counts\n",
    "    \n",
    "    def calculate_green_time(self, vehicle_counts):\n",
    "        \"\"\"\n",
    "        Calculate appropriate green time based on vehicle density\n",
    "        \n",
    "        Args:\n",
    "            vehicle_counts: Dictionary with vehicle counts for each lane\n",
    "            \n",
    "        Returns:\n",
    "            Recommended green time in seconds for each lane\n",
    "        \"\"\"\n",
    "        total_vehicles = sum(vehicle_counts.values())\n",
    "        if total_vehicles == 0:\n",
    "            return {lane: self.min_green_time for lane in self.lanes}\n",
    "        \n",
    "        green_times = {}\n",
    "        for lane, count in vehicle_counts.items():\n",
    "            # Base calculation: ratio of vehicles in this lane to total, scaled to time range\n",
    "            lane_ratio = count / total_vehicles if total_vehicles > 0 else 0\n",
    "            green_time = self.min_green_time + lane_ratio * (self.max_green_time - self.min_green_time)\n",
    "            green_times[lane] = max(self.min_green_time, min(self.max_green_time, green_time))\n",
    "            \n",
    "        return green_times\n",
    "    \n",
    "    def update_traffic_signals(self, vehicle_counts):\n",
    "        \"\"\"\n",
    "        Update traffic signal states based on elapsed time and vehicle counts\n",
    "        \n",
    "        Args:\n",
    "            vehicle_counts: Dictionary with vehicle counts for each lane\n",
    "        \"\"\"\n",
    "        current_time = time.time()\n",
    "        self.elapsed_time = current_time - self.signal_start_time\n",
    "        \n",
    "        # Calculate green times\n",
    "        green_times = self.calculate_green_time(vehicle_counts)\n",
    "        \n",
    "        # Check if current signal has been green long enough\n",
    "        if self.signal_state[self.current_signal] == \"green\" and self.elapsed_time >= green_times[self.current_signal]:\n",
    "            # Change to yellow\n",
    "            self.signal_state[self.current_signal] = \"yellow\"\n",
    "            self.signal_start_time = current_time\n",
    "            \n",
    "        # Check if yellow time has elapsed\n",
    "        elif self.signal_state[self.current_signal] == \"yellow\" and self.elapsed_time >= self.yellow_time:\n",
    "            # Change to red and select next lane\n",
    "            self.signal_state[self.current_signal] = \"red\"\n",
    "            \n",
    "            # Find the lane with highest vehicle count\n",
    "            next_signal = max(vehicle_counts, key=vehicle_counts.get)\n",
    "            \n",
    "            # If current signal has highest count, move to next in cycle\n",
    "            if next_signal == self.current_signal or vehicle_counts[next_signal] == 0:\n",
    "                lanes = list(self.lanes.keys())\n",
    "                next_index = (lanes.index(self.current_signal) + 1) % len(lanes)\n",
    "                next_signal = lanes[next_index]\n",
    "                \n",
    "            self.current_signal = next_signal\n",
    "            self.signal_state[self.current_signal] = \"green\"\n",
    "            self.signal_start_time = current_time\n",
    "    \n",
    "    def process_frame(self, frame):\n",
    "        \"\"\"\n",
    "        Process a single frame from the video source\n",
    "        \n",
    "        Args:\n",
    "            frame: Video frame to process\n",
    "        \n",
    "        Returns:\n",
    "            Processed frame with annotations\n",
    "        \"\"\"\n",
    "        # Detect vehicles\n",
    "        vehicle_counts = self.detect_vehicles(frame)\n",
    "        \n",
    "        # Update traffic signals\n",
    "        self.update_traffic_signals(vehicle_counts)\n",
    "        \n",
    "        # Draw lane ROIs and vehicle counts\n",
    "        for lane, roi in self.lanes.items():\n",
    "            x1, y1, x2, y2 = roi\n",
    "            color = (0, 255, 0) if self.signal_state[lane] == \"green\" else /\n",
    "                   (0, 255, 255) if self.signal_state[lane] == \"yellow\" else (0, 0, 255)\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "            cv2.putText(frame, f\"{lane}: {vehicle_counts[lane]} vehicles\", \n",
    "                        (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "        # Draw current signal state\n",
    "        green_times = self.calculate_green_time(vehicle_counts)\n",
    "        cv2.putText(frame, f\"Current: {self.current_signal} ({self.signal_state[self.current_signal]})\", \n",
    "                    (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        cv2.putText(frame, f\"Time: {int(self.elapsed_time)}s / {int(green_times[self.current_signal])}s\", \n",
    "                    (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "            \n",
    "        return frame\n",
    "    \n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Main loop to process video frames and display results\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            ret, frame = self.cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "                \n",
    "            processed_frame = self.process_frame(frame)\n",
    "            \n",
    "            cv2.imshow(\"Traffic Management System\", processed_frame)\n",
    "            \n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "                \n",
    "        self.cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "    \n",
    "    def simulate_traffic_flow(self):\n",
    "        \"\"\"\n",
    "        Create a simulation of traffic flow based on historical data\n",
    "        \"\"\"\n",
    "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8))\n",
    "        \n",
    "        # Lane density plot\n",
    "        density_lines = {}\n",
    "        for lane in self.lanes:\n",
    "            line, = ax1.plot([], [], label=lane)\n",
    "            density_lines[lane] = line\n",
    "        ax1.set_xlim(0, 50)\n",
    "        ax1.set_ylim(0, 20)\n",
    "        ax1.set_title('Vehicle Density by Lane')\n",
    "        ax1.set_xlabel('Time')\n",
    "        ax1.set_ylabel('Vehicle Count')\n",
    "        ax1.legend()\n",
    "        \n",
    "        # Traffic light status plot\n",
    "        light_bars = ax2.bar(self.lanes.keys(), [0, 0, 0, 0], color='red')\n",
    "        ax2.set_ylim(0, 1.2)\n",
    "        ax2.set_title('Current Signal Status')\n",
    "        ax2.set_ylabel('Status (0=Red, 0.5=Yellow, 1=Green)')\n",
    "        \n",
    "        x_data = list(range(50))\n",
    "        \n",
    "        def update(frame):\n",
    "            # Update density plot\n",
    "            for i, lane in enumerate(self.lanes):\n",
    "                data = list(self.vehicle_history[lane])\n",
    "                while len(data) < 50:\n",
    "                    data.insert(0, 0)\n",
    "                density_lines[lane].set_data(x_data[:len(data)], data)\n",
    "            \n",
    "            # Update signal status bars\n",
    "            for i, lane in enumerate(self.lanes):\n",
    "                if self.signal_state[lane] == \"green\":\n",
    "                    light_bars[i].set_height(1)\n",
    "                    light_bars[i].set_color('green')\n",
    "                elif self.signal_state[lane] == \"yellow\":\n",
    "                    light_bars[i].set_height(0.5)\n",
    "                    light_bars[i].set_color('yellow')\n",
    "                else:\n",
    "                    light_bars[i].set_height(0)\n",
    "                    light_bars[i].set_color('red')\n",
    "            \n",
    "            return list(density_lines.values()) + [light_bars]\n",
    "        \n",
    "        ani = FuncAnimation(fig, update, interval=500)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    def run_with_simulation(self):\n",
    "        \"\"\"\n",
    "        Run the system with real-time simulation\n",
    "        \"\"\"\n",
    "        import threading\n",
    "        \n",
    "        # Start the video processing in a separate thread\n",
    "        video_thread = threading.Thread(target=self.run)\n",
    "        video_thread.daemon = True\n",
    "        video_thread.start()\n",
    "        \n",
    "        # Run the simulation\n",
    "        self.simulate_traffic_flow()\n",
    "\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace with path to your video or camera index\n",
    "    video_source = \"static/videos/agra-india-november-17-2012-traffic-on-indian-street-in-agra-india-17-nov-2012-SBV-347430175-preview.mp4\"  # or 0 for webcam\n",
    "    \n",
    "    # Use a trained YOLOv8 model (download if needed)\n",
    "    model_path = \"yolov8n.pt\"  # Use pretrained YOLOv8 nano\n",
    "    \n",
    "    # Create and run the traffic management system\n",
    "    traffic_system = TrafficManagementSystem(model_path, video_source)\n",
    "    traffic_system.run_with_simulation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switching to Lane 1 with priority 0.00\n",
      "Dynamic green time: 10.0 seconds\n",
      "\n",
      "0: 480x640 2 cars, 919.4ms\n",
      "Speed: 37.4ms preprocess, 919.4ms inference, 24.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 3 motorcycles, 1 truck, 220.4ms\n",
      "Speed: 3.8ms preprocess, 220.4ms inference, 5.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 23 persons, 4 cars, 1 motorcycle, 224.9ms\n",
      "Speed: 3.4ms preprocess, 224.9ms inference, 4.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Switching to Lane 4 with priority 25.64\n",
      "Dynamic green time: 24.0 seconds\n",
      "0: 480x640 5 persons, 1 bicycle, 1 car, 2 motorcycles, 1 truck, 4878.3ms\n",
      "Speed: 9.7ms preprocess, 4878.3ms inference, 98.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 cars, 5942.1ms\n",
      "Speed: 47.0ms preprocess, 5942.1ms inference, 61.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 1 bicycle, 1 car, 2 motorcycles, 1 bus, 3 trucks, 6387.7ms\n",
      "Speed: 25.4ms preprocess, 6387.7ms inference, 4.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 14 persons, 4 cars, 1 bus, 2 trucks, 4531.8ms\n",
      "Speed: 5.9ms preprocess, 4531.8ms inference, 41.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 car, 2 trucks, 5712.6ms\n",
      "Speed: 8.7ms preprocess, 5712.6ms inference, 20.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Switching to Lane 3 with priority 60.62\n",
      "Dynamic green time: 29.7 seconds\n",
      "0: 480x640 4 cars, 4905.7ms\n",
      "Speed: 88.2ms preprocess, 4905.7ms inference, 3.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 1 bicycle, 1 car, 1 motorcycle, 243.1ms\n",
      "Speed: 5.2ms preprocess, 243.1ms inference, 3.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 27 persons, 5 cars, 1 bus, 1 truck, 225.8ms\n",
      "Speed: 4.2ms preprocess, 225.8ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "import threading\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "from PIL import Image, ImageTk\n",
    "from ultralytics import YOLO\n",
    "import random\n",
    "import os\n",
    "import datetime\n",
    "from collections import deque\n",
    "\n",
    "# Import our modules\n",
    "from lane import LaneProcessor\n",
    "from traffic_control import TrafficController\n",
    "from gui_components import SystemGUI\n",
    "\n",
    "class TrafficManagementSystem:\n",
    "    def __init__(self, video_sources):\n",
    "        # Initialize video sources (paths or camera indices)\n",
    "        self.video_sources = video_sources\n",
    "        self.lane_count = len(video_sources)\n",
    "        \n",
    "        # Initialize video captures\n",
    "        self.captures = [cv2.VideoCapture(src) for src in video_sources]\n",
    "        \n",
    "        # System control flags\n",
    "        self.is_running = False\n",
    "        \n",
    "        # Create directories for frame storage\n",
    "        self.frame_dirs = []\n",
    "        for i in range(self.lane_count):\n",
    "            dir_path = f\"lane_{i}_frames\"\n",
    "            os.makedirs(dir_path, exist_ok=True)\n",
    "            self.frame_dirs.append(dir_path)\n",
    "        \n",
    "        # Initialize components\n",
    "        self.lane_processor = LaneProcessor(self.lane_count)\n",
    "        self.traffic_controller = TrafficController(self.lane_count)\n",
    "        \n",
    "        # Pre-processed frames for each lane\n",
    "        self.processed_frames = [deque() for _ in range(self.lane_count)]\n",
    "        self.latest_frames = [None] * self.lane_count\n",
    "        \n",
    "        # Create GUI\n",
    "        self.gui = SystemGUI(self)\n",
    "        self.root = self.gui.root\n",
    "        \n",
    "        # Thread management\n",
    "        self.preprocess_threads = []\n",
    "        self.detection_thread = None\n",
    "        self.traffic_control_thread = None\n",
    "        self.display_thread = None\n",
    "    \n",
    "    def initialize_threads(self):\n",
    "        \"\"\"Initialize all processing threads\"\"\"\n",
    "        # Clear existing threads\n",
    "        self.preprocess_threads = []\n",
    "        \n",
    "        # Create preprocessing threads\n",
    "        for i in range(self.lane_count):\n",
    "            thread = threading.Thread(target=self.preprocess_video, args=(i,))\n",
    "            thread.daemon = True\n",
    "            self.preprocess_threads.append(thread)\n",
    "        \n",
    "        # Create other system threads\n",
    "        self.detection_thread = threading.Thread(target=self.process_frames)\n",
    "        self.detection_thread.daemon = True\n",
    "        \n",
    "        self.traffic_control_thread = threading.Thread(target=self.traffic_controller.control_traffic_lights,\n",
    "                                                      args=(self,))  # Pass self reference\n",
    "        self.traffic_control_thread.daemon = True\n",
    "        \n",
    "        self.display_thread = threading.Thread(target=self.update_display)\n",
    "        self.display_thread.daemon = True\n",
    "    \n",
    "    def toggle_system(self):\n",
    "        \"\"\"Start or stop the system\"\"\"\n",
    "        if self.is_running:\n",
    "            self.is_running = False\n",
    "            self.gui.update_system_status(\"System Stopped\", \"Start System\")\n",
    "        else:\n",
    "            self.is_running = True\n",
    "            self.gui.update_system_status(\"System Running\", \"Stop System\")\n",
    "            \n",
    "            # Initialize threads if needed\n",
    "            self.initialize_threads()\n",
    "            \n",
    "            # Start all threads\n",
    "            for i, thread in enumerate(self.preprocess_threads):\n",
    "                if not thread.is_alive():\n",
    "                    self.preprocess_threads[i].start()\n",
    "            \n",
    "            if not self.detection_thread.is_alive():\n",
    "                self.detection_thread.start()\n",
    "            \n",
    "            if not self.traffic_control_thread.is_alive():\n",
    "                self.traffic_control_thread.start()\n",
    "                \n",
    "            if not self.display_thread.is_alive():\n",
    "                self.display_thread.start()\n",
    "\n",
    "    def preprocess_video(self, lane_idx):\n",
    "        \"\"\"Preprocess video for a specific lane by extracting frames at regular intervals\"\"\"\n",
    "        cap = self.captures[lane_idx]\n",
    "        \n",
    "        while self.is_running:\n",
    "            if not cap.isOpened():\n",
    "                time.sleep(1)\n",
    "                continue\n",
    "            \n",
    "            # Get video properties\n",
    "            fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "            frame_interval = int(fps / self.lane_processor.frame_rate)\n",
    "            chunk_frames = int(fps * self.lane_processor.chunk_size)\n",
    "            \n",
    "            # Process chunk by chunk\n",
    "            start_frame = 0\n",
    "            \n",
    "            while self.is_running:\n",
    "                # Set video position to start of chunk\n",
    "                cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "                \n",
    "                # Extract frames from chunk\n",
    "                chunk_images = []\n",
    "                for i in range(chunk_frames):\n",
    "                    # Only capture frames at specified interval\n",
    "                    if i % frame_interval == 0:\n",
    "                        ret, frame = cap.read()\n",
    "                        if not ret:\n",
    "                            break\n",
    "                        chunk_images.append(frame)\n",
    "                \n",
    "                # If we reached the end of video, loop back\n",
    "                if len(chunk_images) == 0:\n",
    "                    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "                    start_frame = 0\n",
    "                    continue\n",
    "                \n",
    "                # Select a random frame from the chunk\n",
    "                if chunk_images:\n",
    "                    selected_frame = random.choice(chunk_images)\n",
    "                    selected_frame = cv2.resize(selected_frame, (640, 480))\n",
    "                    \n",
    "                    # Add to processing queue\n",
    "                    if len(self.processed_frames[lane_idx]) >= 5:\n",
    "                        self.processed_frames[lane_idx].popleft()\n",
    "                    self.processed_frames[lane_idx].append(selected_frame)\n",
    "                    \n",
    "                    # Update latest frame\n",
    "                    self.latest_frames[lane_idx] = selected_frame.copy()\n",
    "                \n",
    "                # Move to next chunk\n",
    "                start_frame += chunk_frames\n",
    "                \n",
    "                # Wait before processing next chunk\n",
    "                time.sleep(0.1)\n",
    "    \n",
    "    def process_frames(self):\n",
    "        \"\"\"Process frames from all lanes simultaneously\"\"\"\n",
    "        while self.is_running:\n",
    "            for lane_idx in range(self.lane_count):\n",
    "                # Skip if no frames available\n",
    "                if not self.processed_frames[lane_idx]:\n",
    "                    continue\n",
    "                \n",
    "                # Get a frame from the queue\n",
    "                frame = self.processed_frames[lane_idx].popleft()\n",
    "                \n",
    "                # Process frame with vehicle detection\n",
    "                processed_frame, vehicle_counts, priority = self.lane_processor.process_lane_frame(frame)\n",
    "                \n",
    "                # Update controller with new vehicle data\n",
    "                self.traffic_controller.lane_vehicle_counts[lane_idx] = vehicle_counts\n",
    "                self.traffic_controller.lane_priorities[lane_idx] = priority\n",
    "                \n",
    "                # Update latest frame with detection results\n",
    "                self.latest_frames[lane_idx] = processed_frame\n",
    "            \n",
    "            # Sleep to reduce CPU usage\n",
    "            time.sleep(0.1)\n",
    "    \n",
    "    def update_display(self):\n",
    "        \"\"\"Update the GUI display with the latest frames and information\"\"\"\n",
    "        while self.is_running:\n",
    "            # Update all lane displays\n",
    "            for lane_idx in range(self.lane_count):\n",
    "                # Skip if no frame available\n",
    "                if self.latest_frames[lane_idx] is None:\n",
    "                    continue\n",
    "                \n",
    "                # Get current frame\n",
    "                frame = self.latest_frames[lane_idx].copy()\n",
    "                \n",
    "                # Add traffic light status overlay to frame\n",
    "                status = self.traffic_controller.traffic_states[lane_idx].upper()\n",
    "                color = (0, 0, 255)  # Red\n",
    "                if status == \"GREEN\":\n",
    "                    color = (0, 255, 0)  # Green\n",
    "                elif status == \"YELLOW\":\n",
    "                    color = (0, 255, 255)  # Yellow\n",
    "                \n",
    "                # Draw signal status on the frame\n",
    "                cv2.rectangle(frame, (10, 10), (150, 50), (0, 0, 0), -1)\n",
    "                cv2.putText(frame, f\"Signal: {status}\", (15, 35), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                            0.7, color, 2)\n",
    "                \n",
    "                # Draw priority score on the frame\n",
    "                priority = self.traffic_controller.lane_priorities[lane_idx]\n",
    "                cv2.rectangle(frame, (10, 60), (150, 100), (0, 0, 0), -1)\n",
    "                cv2.putText(frame, f\"Priority: {priority}\", (15, 85), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                            0.7, (255, 255, 255), 2)\n",
    "                \n",
    "                # Update GUI with new frame and information\n",
    "                self.gui.update_lane_display(lane_idx, frame, \n",
    "                                         self.traffic_controller.traffic_states[lane_idx],\n",
    "                                         self.traffic_controller.lane_priorities[lane_idx],\n",
    "                                         self.traffic_controller.lane_vehicle_counts[lane_idx])\n",
    "            \n",
    "            # Update GUI periodically\n",
    "            time.sleep(0.1)\n",
    "            \n",
    "    def run(self):\n",
    "        \"\"\"Run the traffic management system\"\"\"\n",
    "        # Start GUI main loop\n",
    "        self.root.mainloop()\n",
    "        \n",
    "        # Clean up when GUI closes\n",
    "        self.is_running = False\n",
    "        for cap in self.captures:\n",
    "            cap.release()\n",
    "\n",
    "def main():\n",
    "    # Replace with your video sources\n",
    "    # Could be camera indices (0, 1, 2, 3) or video file paths\n",
    "    video_sources = [\n",
    "        'static/videos/udaipur-india-november-24-2012-traffic-on-indian-street-in-udaipur-SBV-347557199-preview.mp4',\n",
    "        'static/videos/27260-362770008_small.mp4',\n",
    "        'static/videos/agra-india-november-17-2012-traffic-on-indian-street-in-agra-india-17-nov-2012-SBV-347430175-preview.mp4', \n",
    "        'static/videos/traffic-congestion-and-street-life-in-the-city-of-jaipur-pink-gate-city-walls--SBV-300214180-preview.mp4'\n",
    "    ]\n",
    "    \n",
    "    # Create and run the system\n",
    "    system = TrafficManagementSystem(video_sources)\n",
    "    system.run()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trimmed video saved: trimmed_videos\\lane1_trimmed.mp4\n",
      "Trimmed video saved: trimmed_videos\\lane2_trimmed.mp4\n",
      "Trimmed video saved: trimmed_videos\\lane3_trimmed.mp4\n",
      "Trimmed video saved: trimmed_videos\\lane4_trimmed.mp4\n",
      " All 4 videos trimmed to 5 seconds successfully!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Input video paths (change these paths to your actual video files)\n",
    "video_paths = [\n",
    "    \"static/videos/27260-362770008_small.mp4\",\n",
    "    \"static/videos/agra-india-november-17-2012-traffic-on-indian-street-in-agra-india-17-nov-2012-SBV-347430175-preview.mp4\",\n",
    "    \"static/videos/traffic-congestion-and-street-life-in-the-city-of-jaipur-pink-gate-city-walls--SBV-300214180-preview.mp4\",\n",
    "    \"static/videos/udaipur-india-november-24-2012-traffic-on-indian-street-in-udaipur-SBV-347557199-preview.mp4\"\n",
    "]\n",
    "\n",
    "# Directory to save trimmed videos\n",
    "output_dir = \"trimmed_videos\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Trim duration in seconds\n",
    "trim_duration = 5\n",
    "\n",
    "for idx, video_path in enumerate(video_paths):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Get video properties\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # Define the number of frames to keep (5 seconds)\n",
    "    max_frames = fps * trim_duration\n",
    "\n",
    "    # Output file path\n",
    "    output_path = os.path.join(output_dir, f\"lane{idx+1}_trimmed.mp4\")\n",
    "\n",
    "    # Video writer setup\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "    frame_count = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret or frame_count >= max_frames:\n",
    "            break\n",
    "\n",
    "        out.write(frame)\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(f\"Trimmed video saved: {output_path}\")\n",
    "\n",
    "print(\" All 4 videos trimmed to 5 seconds successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading from Camera 1\n",
      "\n",
      "0: 480x640 2 persons, 61.1ms\n",
      "Speed: 2.6ms preprocess, 61.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 48.2ms\n",
      "Speed: 1.3ms preprocess, 48.2ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 43.7ms\n",
      "Speed: 1.0ms preprocess, 43.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 42.5ms\n",
      "Speed: 1.1ms preprocess, 42.5ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 42.7ms\n",
      "Speed: 1.1ms preprocess, 42.7ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 44.3ms\n",
      "Speed: 1.2ms preprocess, 44.3ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 42.4ms\n",
      "Speed: 1.0ms preprocess, 42.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 43.7ms\n",
      "Speed: 1.2ms preprocess, 43.7ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 44.1ms\n",
      "Speed: 1.0ms preprocess, 44.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 46.8ms\n",
      "Speed: 1.1ms preprocess, 46.8ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 50.3ms\n",
      "Speed: 1.2ms preprocess, 50.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 42.3ms\n",
      "Speed: 1.0ms preprocess, 42.3ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 45.9ms\n",
      "Speed: 1.1ms preprocess, 45.9ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 44.1ms\n",
      "Speed: 1.1ms preprocess, 44.1ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 46.3ms\n",
      "Speed: 1.2ms preprocess, 46.3ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 44.1ms\n",
      "Speed: 1.1ms preprocess, 44.1ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 48.9ms\n",
      "Speed: 1.1ms preprocess, 48.9ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 43.8ms\n",
      "Speed: 1.3ms preprocess, 43.8ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 43.2ms\n",
      "Speed: 1.0ms preprocess, 43.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 46.4ms\n",
      "Speed: 1.0ms preprocess, 46.4ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 45.7ms\n",
      "Speed: 1.3ms preprocess, 45.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 51.4ms\n",
      "Speed: 2.1ms preprocess, 51.4ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 39.4ms\n",
      "Speed: 1.1ms preprocess, 39.4ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 44.4ms\n",
      "Speed: 1.0ms preprocess, 44.4ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 45.1ms\n",
      "Speed: 1.1ms preprocess, 45.1ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 42.4ms\n",
      "Speed: 1.0ms preprocess, 42.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 42.0ms\n",
      "Speed: 1.1ms preprocess, 42.0ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 43.4ms\n",
      "Speed: 1.1ms preprocess, 43.4ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 40.3ms\n",
      "Speed: 1.0ms preprocess, 40.3ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 40.3ms\n",
      "Speed: 1.2ms preprocess, 40.3ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 43.3ms\n",
      "Speed: 1.0ms preprocess, 43.3ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 42.6ms\n",
      "Speed: 1.0ms preprocess, 42.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 43.2ms\n",
      "Speed: 1.1ms preprocess, 43.2ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 44.5ms\n",
      "Speed: 1.0ms preprocess, 44.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 43.3ms\n",
      "Speed: 4.2ms preprocess, 43.3ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 42.1ms\n",
      "Speed: 1.0ms preprocess, 42.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 44.0ms\n",
      "Speed: 1.1ms preprocess, 44.0ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 40.7ms\n",
      "Speed: 1.0ms preprocess, 40.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 41.1ms\n",
      "Speed: 1.2ms preprocess, 41.1ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 41.1ms\n",
      "Speed: 1.1ms preprocess, 41.1ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 45.1ms\n",
      "Speed: 1.1ms preprocess, 45.1ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 41.9ms\n",
      "Speed: 1.0ms preprocess, 41.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 41.0ms\n",
      "Speed: 1.0ms preprocess, 41.0ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 41.3ms\n",
      "Speed: 1.0ms preprocess, 41.3ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 40.2ms\n",
      "Speed: 1.0ms preprocess, 40.2ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 40.8ms\n",
      "Speed: 1.0ms preprocess, 40.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 45.9ms\n",
      "Speed: 1.0ms preprocess, 45.9ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 55.7ms\n",
      "Speed: 1.1ms preprocess, 55.7ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 43.6ms\n",
      "Speed: 0.9ms preprocess, 43.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 43.8ms\n",
      "Speed: 1.2ms preprocess, 43.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 41.4ms\n",
      "Speed: 1.1ms preprocess, 41.4ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 43.2ms\n",
      "Speed: 1.2ms preprocess, 43.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 42.3ms\n",
      "Speed: 0.9ms preprocess, 42.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 43.9ms\n",
      "Speed: 1.2ms preprocess, 43.9ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 47.1ms\n",
      "Speed: 1.0ms preprocess, 47.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 43.8ms\n",
      "Speed: 1.2ms preprocess, 43.8ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 41.3ms\n",
      "Speed: 1.3ms preprocess, 41.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 41.6ms\n",
      "Speed: 1.3ms preprocess, 41.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 43.6ms\n",
      "Speed: 1.3ms preprocess, 43.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 41.2ms\n",
      "Speed: 0.9ms preprocess, 41.2ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 41.1ms\n",
      "Speed: 1.3ms preprocess, 41.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 46.4ms\n",
      "Speed: 1.0ms preprocess, 46.4ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 44.9ms\n",
      "Speed: 1.0ms preprocess, 44.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 43.9ms\n",
      "Speed: 1.0ms preprocess, 43.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 43.0ms\n",
      "Speed: 1.1ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 45.3ms\n",
      "Speed: 1.1ms preprocess, 45.3ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 45.5ms\n",
      "Speed: 1.2ms preprocess, 45.5ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 46.2ms\n",
      "Speed: 1.0ms preprocess, 46.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 46.0ms\n",
      "Speed: 1.3ms preprocess, 46.0ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 45.6ms\n",
      "Speed: 1.1ms preprocess, 45.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 44.3ms\n",
      "Speed: 1.0ms preprocess, 44.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 45.1ms\n",
      "Speed: 1.0ms preprocess, 45.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 44.5ms\n",
      "Speed: 0.9ms preprocess, 44.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 50.4ms\n",
      "Speed: 4.1ms preprocess, 50.4ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 76.4ms\n",
      "Speed: 1.1ms preprocess, 76.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 44.2ms\n",
      "Speed: 1.2ms preprocess, 44.2ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 42.1ms\n",
      "Speed: 1.0ms preprocess, 42.1ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 46.1ms\n",
      "Speed: 1.0ms preprocess, 46.1ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 41.8ms\n",
      "Speed: 0.9ms preprocess, 41.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 46.2ms\n",
      "Speed: 1.1ms preprocess, 46.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 40.9ms\n",
      "Speed: 0.9ms preprocess, 40.9ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 44.0ms\n",
      "Speed: 0.9ms preprocess, 44.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 40.9ms\n",
      "Speed: 1.2ms preprocess, 40.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 40.9ms\n",
      "Speed: 1.0ms preprocess, 40.9ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 42.3ms\n",
      "Speed: 1.1ms preprocess, 42.3ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 40.9ms\n",
      "Speed: 1.0ms preprocess, 40.9ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 40.5ms\n",
      "Speed: 0.9ms preprocess, 40.5ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 42.1ms\n",
      "Speed: 1.0ms preprocess, 42.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 42.3ms\n",
      "Speed: 1.0ms preprocess, 42.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import threading\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load YOLOv8 model\n",
    "model = YOLO(\"yolov8n.pt\")  # Use your trained model path\n",
    "\n",
    "# Camera sources\n",
    "laptop_cam = 0  # Default webcam\n",
    "mobile_cam = \"http://172.16.252.87:4747/mjpeg\"  # DroidCam MJPEG URL\n",
    "\n",
    "# Open video feeds\n",
    "caps = {0: cv2.VideoCapture(laptop_cam), 1: cv2.VideoCapture(mobile_cam)}\n",
    "\n",
    "# Function to process each camera feed\n",
    "def process_camera(cam_id):\n",
    "    while True:\n",
    "        ret, frame = caps[cam_id].read()\n",
    "        if not ret:\n",
    "            print(f\"Error reading from Camera {cam_id}\")\n",
    "            break\n",
    "\n",
    "        # Run YOLO detection\n",
    "        results = model(frame)\n",
    "        annotated_frame = results[0].plot()\n",
    "\n",
    "        # Display feed\n",
    "        cv2.imshow(f\"Camera {cam_id}\", annotated_frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# Create and start threads\n",
    "threads = []\n",
    "for cam_id in caps:\n",
    "    t = threading.Thread(target=process_camera, args=(cam_id,))\n",
    "    t.start()\n",
    "    threads.append(t)\n",
    "\n",
    "# Wait for all threads to finish\n",
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "# Release resources\n",
    "for cap in caps.values():\n",
    "    cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.11.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "print(cv2.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.3.99-py3-none-any.whl.metadata (37 kB)\n",
      "Collecting numpy<=2.1.1,>=1.23.0 (from ultralytics)\n",
      "  Downloading numpy-2.1.1-cp311-cp311-win_amd64.whl.metadata (59 kB)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\prati\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (3.9.2)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\prati\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (4.11.0.86)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\prati\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (10.4.0)\n",
      "Collecting pyyaml>=5.3.1 (from ultralytics)\n",
      "  Downloading PyYAML-6.0.2-cp311-cp311-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\prati\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\prati\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (1.14.1)\n",
      "Collecting torch>=1.8.0 (from ultralytics)\n",
      "  Downloading torch-2.6.0-cp311-cp311-win_amd64.whl.metadata (28 kB)\n",
      "Collecting torchvision>=0.9.0 (from ultralytics)\n",
      "  Downloading torchvision-0.21.0-cp311-cp311-win_amd64.whl.metadata (6.3 kB)\n",
      "Collecting tqdm>=4.64.0 (from ultralytics)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: psutil in c:\\users\\prati\\appdata\\roaming\\python\\python311\\site-packages (from ultralytics) (6.1.0)\n",
      "Collecting py-cpuinfo (from ultralytics)\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\prati\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (2.2.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\prati\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (0.13.2)\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
      "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\prati\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\prati\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\prati\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\prati\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\prati\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\prati\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\prati\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\prati\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\prati\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\prati\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\prati\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\prati\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\prati\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
      "Collecting filelock (from torch>=1.8.0->ultralytics)\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\prati\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Collecting networkx (from torch>=1.8.0->ultralytics)\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\prati\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Collecting fsspec (from torch>=1.8.0->ultralytics)\n",
      "  Downloading fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting sympy==1.13.1 (from torch>=1.8.0->ultralytics)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch>=1.8.0->ultralytics)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\prati\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\prati\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\prati\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.1)\n",
      "Downloading ultralytics-8.3.99-py3-none-any.whl (976 kB)\n",
      "   ---------------------------------------- 0.0/976.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 976.9/976.9 kB 6.5 MB/s eta 0:00:00\n",
      "Downloading numpy-2.1.1-cp311-cp311-win_amd64.whl (12.9 MB)\n",
      "   ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 2.1/12.9 MB 10.7 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 4.5/12.9 MB 10.7 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 6.3/12.9 MB 10.4 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 8.4/12.9 MB 10.0 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 8.9/12.9 MB 9.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 10.0/12.9 MB 8.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.7/12.9 MB 7.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.3/12.9 MB 7.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.9/12.9 MB 7.0 MB/s eta 0:00:00\n",
      "Downloading PyYAML-6.0.2-cp311-cp311-win_amd64.whl (161 kB)\n",
      "Downloading torch-2.6.0-cp311-cp311-win_amd64.whl (204.2 MB)\n",
      "   ---------------------------------------- 0.0/204.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.8/204.2 MB 11.2 MB/s eta 0:00:19\n",
      "    --------------------------------------- 3.9/204.2 MB 9.4 MB/s eta 0:00:22\n",
      "   - -------------------------------------- 5.8/204.2 MB 9.0 MB/s eta 0:00:22\n",
      "   - -------------------------------------- 7.9/204.2 MB 9.4 MB/s eta 0:00:21\n",
      "   - -------------------------------------- 9.7/204.2 MB 9.4 MB/s eta 0:00:21\n",
      "   -- ------------------------------------- 11.8/204.2 MB 9.5 MB/s eta 0:00:21\n",
      "   -- ------------------------------------- 13.9/204.2 MB 9.5 MB/s eta 0:00:21\n",
      "   --- ------------------------------------ 16.3/204.2 MB 9.7 MB/s eta 0:00:20\n",
      "   --- ------------------------------------ 18.4/204.2 MB 9.7 MB/s eta 0:00:20\n",
      "   ---- ----------------------------------- 20.4/204.2 MB 9.8 MB/s eta 0:00:19\n",
      "   ---- ----------------------------------- 22.3/204.2 MB 9.8 MB/s eta 0:00:19\n",
      "   ---- ----------------------------------- 23.3/204.2 MB 9.3 MB/s eta 0:00:20\n",
      "   ---- ----------------------------------- 24.4/204.2 MB 9.1 MB/s eta 0:00:20\n",
      "   ----- ---------------------------------- 26.0/204.2 MB 8.9 MB/s eta 0:00:20\n",
      "   ----- ---------------------------------- 27.0/204.2 MB 8.6 MB/s eta 0:00:21\n",
      "   ----- ---------------------------------- 28.6/204.2 MB 8.5 MB/s eta 0:00:21\n",
      "   ----- ---------------------------------- 30.1/204.2 MB 8.5 MB/s eta 0:00:21\n",
      "   ------ --------------------------------- 32.2/204.2 MB 8.5 MB/s eta 0:00:21\n",
      "   ------ --------------------------------- 33.8/204.2 MB 8.5 MB/s eta 0:00:21\n",
      "   ------ --------------------------------- 35.7/204.2 MB 8.5 MB/s eta 0:00:20\n",
      "   ------- -------------------------------- 38.0/204.2 MB 8.6 MB/s eta 0:00:20\n",
      "   ------- -------------------------------- 39.8/204.2 MB 8.6 MB/s eta 0:00:20\n",
      "   -------- ------------------------------- 41.9/204.2 MB 8.7 MB/s eta 0:00:19\n",
      "   -------- ------------------------------- 44.3/204.2 MB 8.8 MB/s eta 0:00:19\n",
      "   --------- ------------------------------ 46.7/204.2 MB 8.9 MB/s eta 0:00:18\n",
      "   --------- ------------------------------ 48.5/204.2 MB 8.9 MB/s eta 0:00:18\n",
      "   --------- ------------------------------ 50.9/204.2 MB 9.0 MB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 53.0/204.2 MB 9.0 MB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 54.5/204.2 MB 9.0 MB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 56.1/204.2 MB 8.9 MB/s eta 0:00:17\n",
      "   ----------- ---------------------------- 56.9/204.2 MB 8.8 MB/s eta 0:00:17\n",
      "   ----------- ---------------------------- 58.5/204.2 MB 8.7 MB/s eta 0:00:17\n",
      "   ----------- ---------------------------- 59.5/204.2 MB 8.6 MB/s eta 0:00:17\n",
      "   ----------- ---------------------------- 60.6/204.2 MB 8.5 MB/s eta 0:00:17\n",
      "   ------------ --------------------------- 61.9/204.2 MB 8.4 MB/s eta 0:00:17\n",
      "   ------------ --------------------------- 62.9/204.2 MB 8.4 MB/s eta 0:00:17\n",
      "   ------------ --------------------------- 64.0/204.2 MB 8.3 MB/s eta 0:00:17\n",
      "   ------------ --------------------------- 64.2/204.2 MB 8.2 MB/s eta 0:00:18\n",
      "   ------------ --------------------------- 64.7/204.2 MB 8.0 MB/s eta 0:00:18\n",
      "   ------------ --------------------------- 65.5/204.2 MB 7.8 MB/s eta 0:00:18\n",
      "   ------------ --------------------------- 65.8/204.2 MB 7.7 MB/s eta 0:00:18\n",
      "   ------------- -------------------------- 66.6/204.2 MB 7.5 MB/s eta 0:00:19\n",
      "   ------------- -------------------------- 66.8/204.2 MB 7.5 MB/s eta 0:00:19\n",
      "   ------------- -------------------------- 67.4/204.2 MB 7.3 MB/s eta 0:00:19\n",
      "   ------------- -------------------------- 67.6/204.2 MB 7.2 MB/s eta 0:00:19\n",
      "   ------------- -------------------------- 67.9/204.2 MB 7.1 MB/s eta 0:00:20\n",
      "   ------------- -------------------------- 68.4/204.2 MB 6.9 MB/s eta 0:00:20\n",
      "   ------------- -------------------------- 68.7/204.2 MB 6.8 MB/s eta 0:00:20\n",
      "   ------------- -------------------------- 70.0/204.2 MB 6.8 MB/s eta 0:00:20\n",
      "   ------------- -------------------------- 70.8/204.2 MB 6.7 MB/s eta 0:00:20\n",
      "   -------------- ------------------------- 71.8/204.2 MB 6.7 MB/s eta 0:00:20\n",
      "   -------------- ------------------------- 72.4/204.2 MB 6.6 MB/s eta 0:00:20\n",
      "   -------------- ------------------------- 73.4/204.2 MB 6.6 MB/s eta 0:00:20\n",
      "   -------------- ------------------------- 74.4/204.2 MB 6.6 MB/s eta 0:00:20\n",
      "   -------------- ------------------------- 75.8/204.2 MB 6.5 MB/s eta 0:00:20\n",
      "   --------------- ------------------------ 77.1/204.2 MB 6.5 MB/s eta 0:00:20\n",
      "   --------------- ------------------------ 78.6/204.2 MB 6.6 MB/s eta 0:00:20\n",
      "   --------------- ------------------------ 79.7/204.2 MB 6.5 MB/s eta 0:00:20\n",
      "   --------------- ------------------------ 81.3/204.2 MB 6.6 MB/s eta 0:00:19\n",
      "   ---------------- ----------------------- 82.8/204.2 MB 6.6 MB/s eta 0:00:19\n",
      "   ---------------- ----------------------- 85.2/204.2 MB 6.6 MB/s eta 0:00:18\n",
      "   ----------------- ---------------------- 87.3/204.2 MB 6.7 MB/s eta 0:00:18\n",
      "   ----------------- ---------------------- 89.4/204.2 MB 6.7 MB/s eta 0:00:18\n",
      "   ------------------ --------------------- 92.0/204.2 MB 6.8 MB/s eta 0:00:17\n",
      "   ------------------ --------------------- 94.1/204.2 MB 6.9 MB/s eta 0:00:16\n",
      "   ------------------ --------------------- 96.5/204.2 MB 6.9 MB/s eta 0:00:16\n",
      "   ------------------- -------------------- 98.8/204.2 MB 7.0 MB/s eta 0:00:16\n",
      "   ------------------- -------------------- 100.9/204.2 MB 7.1 MB/s eta 0:00:15\n",
      "   -------------------- ------------------- 102.8/204.2 MB 7.1 MB/s eta 0:00:15\n",
      "   -------------------- ------------------- 105.1/204.2 MB 7.1 MB/s eta 0:00:14\n",
      "   --------------------- ------------------ 107.5/204.2 MB 7.2 MB/s eta 0:00:14\n",
      "   --------------------- ------------------ 109.8/204.2 MB 7.3 MB/s eta 0:00:13\n",
      "   --------------------- ------------------ 111.9/204.2 MB 7.3 MB/s eta 0:00:13\n",
      "   ---------------------- ----------------- 113.8/204.2 MB 7.3 MB/s eta 0:00:13\n",
      "   ---------------------- ----------------- 115.3/204.2 MB 7.4 MB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 117.7/204.2 MB 7.4 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 120.3/204.2 MB 7.4 MB/s eta 0:00:12\n",
      "   ------------------------ --------------- 122.7/204.2 MB 7.5 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 125.0/204.2 MB 7.5 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 126.6/204.2 MB 7.5 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 128.7/204.2 MB 7.6 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 131.1/204.2 MB 7.6 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 133.2/204.2 MB 7.6 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 135.5/204.2 MB 7.7 MB/s eta 0:00:09\n",
      "   -------------------------- ------------- 137.6/204.2 MB 7.7 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 140.0/204.2 MB 7.7 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 142.3/204.2 MB 7.8 MB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 144.7/204.2 MB 7.8 MB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 147.1/204.2 MB 7.9 MB/s eta 0:00:08\n",
      "   ----------------------------- ---------- 149.2/204.2 MB 7.9 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 151.5/204.2 MB 7.9 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 153.4/204.2 MB 7.9 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 155.7/204.2 MB 8.0 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 158.1/204.2 MB 8.0 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 160.4/204.2 MB 8.0 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 161.7/204.2 MB 8.0 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 163.3/204.2 MB 8.0 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 165.2/204.2 MB 8.0 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 166.7/204.2 MB 8.0 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 168.0/204.2 MB 8.0 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 170.1/204.2 MB 8.0 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 171.7/204.2 MB 8.0 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 173.5/204.2 MB 8.0 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 175.4/204.2 MB 8.0 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 177.5/204.2 MB 8.0 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 179.3/204.2 MB 8.1 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 180.6/204.2 MB 8.0 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 182.2/204.2 MB 8.0 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 183.0/204.2 MB 8.0 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 184.3/204.2 MB 8.0 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 185.9/204.2 MB 8.0 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 186.9/204.2 MB 8.0 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 188.7/204.2 MB 7.9 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 190.6/204.2 MB 7.9 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 192.9/204.2 MB 8.0 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 195.0/204.2 MB 8.0 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 196.3/204.2 MB 8.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 196.9/204.2 MB 7.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 197.1/204.2 MB 7.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 197.7/204.2 MB 7.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 197.9/204.2 MB 7.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 199.0/204.2 MB 7.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  199.2/204.2 MB 7.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  199.8/204.2 MB 7.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  200.0/204.2 MB 7.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  200.3/204.2 MB 7.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  201.1/204.2 MB 7.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  201.6/204.2 MB 7.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  202.4/204.2 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  202.9/204.2 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  203.4/204.2 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  203.9/204.2 MB 7.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  203.9/204.2 MB 7.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  203.9/204.2 MB 7.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 204.2/204.2 MB 7.2 MB/s eta 0:00:00\n",
      "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.5/6.2 MB 2.1 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 1.3/6.2 MB 3.2 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 2.4/6.2 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 2.6/6.2 MB 3.2 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 3.4/6.2 MB 3.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 4.2/6.2 MB 3.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 5.0/6.2 MB 3.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 5.5/6.2 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.2/6.2 MB 3.3 MB/s eta 0:00:00\n",
      "Downloading torchvision-0.21.0-cp311-cp311-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 0.8/1.6 MB 4.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.3/1.6 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.6/1.6 MB 3.1 MB/s eta 0:00:00\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
      "Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Downloading fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
      "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 0.8/1.7 MB 2.8 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.3/1.7 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.6/1.7 MB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 2.2 MB/s eta 0:00:00\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ------------------- -------------------- 262.1/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 536.2/536.2 kB 1.4 MB/s eta 0:00:00\n",
      "Installing collected packages: py-cpuinfo, mpmath, tqdm, sympy, pyyaml, numpy, networkx, fsspec, filelock, torch, ultralytics-thop, torchvision, ultralytics\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.2\n",
      "    Uninstalling numpy-2.1.2:\n",
      "      Successfully uninstalled numpy-2.1.2\n",
      "Successfully installed filelock-3.18.0 fsspec-2025.3.2 mpmath-1.3.0 networkx-3.4.2 numpy-2.1.1 py-cpuinfo-9.0.0 pyyaml-6.0.2 sympy-1.13.1 torch-2.6.0 torchvision-0.21.0 tqdm-4.67.1 ultralytics-8.3.99 ultralytics-thop-2.0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\prati\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\~umpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\prati\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\~umpy'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\prati\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (23.2.1)\n",
      "Collecting pip\n",
      "  Obtaining dependency information for pip from https://files.pythonhosted.org/packages/c9/bc/b7db44f5f39f9d0494071bddae6880eb645970366d0a200022a1a93d57f5/pip-25.0.1-py3-none-any.whl.metadata\n",
      "  Downloading pip-25.0.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Downloading pip-25.0.1-py3-none-any.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.2/1.8 MB 4.8 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.6/1.8 MB 6.3 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.1/1.8 MB 7.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.6/1.8 MB 8.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.8/1.8 MB 8.4 MB/s eta 0:00:00\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 23.2.1\n",
      "    Uninstalling pip-23.2.1:\n",
      "      Successfully uninstalled pip-23.2.1\n",
      "Successfully installed pip-25.0.1\n"
     ]
    }
   ],
   "source": [
    "!python.exe -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
